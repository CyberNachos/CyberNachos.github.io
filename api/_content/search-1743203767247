{"documentCount":49,"nextId":49,"documentIds":{"0":"/cybernachos","1":"/cybernachos#our-three-step-strategic-plan","2":"/cybernachos#step-1-develop-robust-secure-and-intelligent-robotic-algorithms","3":"/cybernachos#step-2-establish-robot-led-business-operations","4":"/cybernachos#step-3-realize-fully-autonomous-robotic-enterprises","5":"/cybernachos#license","6":"/cybernachos#team-members","7":"/published/cybernachos-gpt","8":"/published/cybernachos-gpt#tutorial-of-creating-custom-gpts","9":"/tutorial-isaaclab/introduction","10":"/tutorial-isaaclab/installation","11":"/tutorial-isaaclab/installation#installing-isaac-sim","12":"/tutorial-isaaclab/installation#verifying-the-isaac-sim-installation","13":"/tutorial-isaaclab/installation#installing-isaac-sim-1","14":"/tutorial-isaaclab/installation#cloning-isaac-lab","15":"/tutorial-isaaclab/installation#installation","16":"/tutorial-isaaclab/installation#verifying-the-isaac-lab-installation","17":"/tutorial-isaaclab/getting-started","18":"/tutorial-isaaclab/getting-started#installation-and-deployment-of-isaaclabmanipulation","19":"/tutorial-isaaclab/enable-fluid","20":"/tutorial-isaaclab/enable-fluid#the-code","21":"/tutorial-isaaclab/enable-fluid#the-code-explained","22":"/published-research/real-time-dexterous","23":"/published-research/real-time-dexterous#real-time-dexterous-telemanipulation-with-an-end-effect-oriented-learning-based-approach","24":"/published-research/hallucination","25":"/published-research/hallucination#zero-resource-hallucination-prevention-for-large-language-models","26":"/model-dataset-comp/robotics-datasets","27":"/model-dataset-comp/robotics-datasets#summary-table","28":"/model-dataset-comp/robotics-datasets#detailed-comparison","29":"/model-dataset-comp/robotics-datasets#_1-lerobot","30":"/model-dataset-comp/robotics-datasets#_2-open-x-embodiment","31":"/model-dataset-comp/robotics-datasets#_3-droid","32":"/model-dataset-comp/robotics-datasets#_4-roboturk","33":"/model-dataset-comp/robotics-datasets#_5-mime","34":"/model-dataset-comp/robotics-datasets#_6-meta-world","35":"/model-dataset-comp/robotics-datasets#_7-robonet","36":"/model-dataset-comp/robotics-datasets#_8-roboset","37":"/model-dataset-comp/robotics-datasets#_9-bridgedata-v2","38":"/model-dataset-comp/robotics-datasets#_10-rt-1","39":"/model-dataset-comp/robotics-datasets#_11-dobbe","40":"/model-dataset-comp/robotics-datasets#_12-rh20t","41":"/model-dataset-comp/robotics-datasets#_13-bc-z","42":"/model-dataset-comp/robotics-datasets#_14-mt-opt","43":"/model-dataset-comp/robotics-datasets#_15-vima","44":"/model-dataset-comp/robotics-datasets#_16-spoc","45":"/model-dataset-comp/robotics-models","46":"/model-dataset-comp/robotics-models#comparison-of-robot-models","47":"/model-dataset-comp/robotics-models#hardware-and-time-requirements-for-training-fine-tuning-or-distillation","48":"/"},"fieldIds":{"title":0,"content":1,"titles":2},"fieldLength":{"0":[2,43,1],"1":[5,1,2],"2":[9,54,7],"3":[7,55,7],"4":[7,53,7],"5":[1,1,2],"6":[2,63,2],"7":[3,93,1],"8":[5,214,3],"9":[1,120,1],"10":[2,12,1],"11":[3,104,2],"12":[5,124,5],"13":[3,1,5],"14":[3,9,5],"15":[1,60,5],"16":[5,50,5],"17":[2,38,1],"18":[6,97,2],"19":[3,143,1],"20":[2,12,3],"21":[3,143,3],"22":[4,12,1],"23":[12,263,4],"24":[4,8,1],"25":[8,211,4],"26":[3,76,1],"27":[2,432,3],"28":[2,1,3],"29":[2,88,4],"30":[4,66,4],"31":[2,76,4],"32":[2,72,4],"33":[2,57,4],"34":[3,59,4],"35":[2,57,4],"36":[2,58,4],"37":[3,64,4],"38":[3,71,4],"39":[3,85,4],"40":[2,77,4],"41":[3,60,4],"42":[3,71,4],"43":[2,80,4],"44":[2,83,4],"45":[5,55,1],"46":[4,331,5],"47":[10,261,5],"48":[1,19,1]},"averageFieldLength":[3.571428571428572,87.40816326530613,3.3469387755102042],"storedFields":{"0":{"title":"Cyber Nachos","content":"A pioneering initiative committed to advancing the field of modern robotics, Artificial Intelligence (AI), and Cybersecurity. Welcome to Cyber Nachos , a pioneering initiative committed to advancing the field of modern robotics, Artificial Intelligence (AI), and Cybersecurity.\nOur mission is to create practical, intelligent, and safe robotic systems that drive innovation, streamline business operations, and shape the future of industries such as healthcare and beyond.","titles":[]},"1":{"title":"Our Three-Step Strategic Plan","content":"","titles":["Cyber Nachos"]},"2":{"title":"Step 1: Develop Robust, Secure and Intelligent Robotic Algorithms","content":"We begin by creating practical, secure, and intelligent control and interaction algorithms for robots. Our focus is on: Safety and Robustness: Prioritizing algorithms that ensure secure and reliable robot operations.Scalability and Adaptability: Designing modular algorithms that can be applied to various robotic systems and tasks.Self-Diagnostic Mechanisms: Implementing multi-layered self-detection and fault-recovery features to guarantee continuous operation and system integrity.","titles":["Cyber Nachos","Our Three-Step Strategic Plan"]},"3":{"title":"Step 2: Establish Robot-Led Business Operations","content":"Transitioning from human-robot collaboration to robot-led models involves: Pilot Projects: Launching in industries with low human labor demands but stable operations, such as warehousing or simple manufacturing.Intelligent Monitoring Systems: Developing systems that track and adjust robotic operations in real-time to ensure reliability and consistency.Learning Robots: Introducing robots capable of self-optimization and adaptation to evolving business needs.","titles":["Cyber Nachos","Our Three-Step Strategic Plan"]},"4":{"title":"Step 3: Realize Fully Autonomous Robotic Enterprises","content":"To achieve a fully robot-operated business entity, we will: Define Roles and Collaboration: Establish clear role assignments and task collaboration mechanisms for each robot within the business process.AI-Based Management Platform: Develop a platform to coordinate robots and manage task distribution for efficient workflow.Integrate Advanced Technologies: Utilize blockchain and other technologies to record robot statuses and business processes, enhancing transparency and trustworthiness.","titles":["Cyber Nachos","Our Three-Step Strategic Plan"]},"5":{"title":"License","content":"MIT","titles":["Cyber Nachos"]},"6":{"title":"Team Members","content":"Dr. Yidan Hu, Rochester Institute of Technology Dr. Jiu Lu, University of Georgia Dr. Mingjie Li, Zhejiang University Dr. Zheshuo Li, University of Colorado Denver Dr. Fenglong Ma, Pennsylvania State University Dr. Chenhan Xu, North Carolina State University Dr. Huining Li, North Carolina State University Dr. Hailu Xu, California State University, Long Beach Dr. Wenbo Ding, Tsinghua University Dr. Xi Wang, Southeast University Dr. Yang Gao, East China Normal University Haoyang Wang, Oklahoma State University Haoran Guo, Oklahoma State University Xingyu Chen, University of California, San Diego Baicheng Chen, University of California, San Diego Xiaoyu Zhang, University at Buffalo, SUNY Jiayuan Chen Mengmeng Jiang Shuting Zhang Jinpu Tao Ruoxu Wang Shaoyu Chen","titles":["Cyber Nachos"]},"7":{"title":"Cyber Nachos GPT","content":"An AI model specializing in intelligent robotics, crafted by Cyber Nachos on OpenAI's platform. Cyber Nachos GPT is an AI model specializing in intelligent robotics, crafted by Cyber Nachos on OpenAI's platform.\nWhether you're building groundbreaking robotic systems or solving advanced automation challenges, Cyber Nachos GPT is here to inspire, guide, and elevate your projects. Key Features: Comprehensive Robotics Expertise: Covers a wide range of topics, from dexterous telemanipulation and reinforcement learning to simulations for robotic systems.Code and Practical Solutions: Provides reusable code snippets, actionable implementation guides, and cutting-edge recommendations.Real-World Applications: Focuses on applications like telesurgery, industrial automation, and remote exploration, making your robotics vision tangible. Explore More Learn how Cyber Nachos GPT can transform your robotics initiatives. Click Cyber Nachos GPT to start your journey!","titles":[]},"8":{"title":"Tutorial of Creating Custom GPTs","content":"Follow these steps to create a customized GPT in the ChatGPT interface: Access the ChatGPT Platform Make sure you are logged in to the OpenAI ChatGPT platform (https://chat.openai.com). Navigate to the Custom GPT Creation ToolClick on “Explore GPTs” or a Similar OptionLook for the “Explore GPTs” option in the left-hand menu.This section allows you to explore custom GPTs created by others and also provides the tools to create your own.Select “Create a New GPT”Inside the “Explore GPTs” section, find and click the button labeled “Create a New GPT” or something similar. Configure Your Custom GPT Once you begin creating your GPT, you'll be prompted to configure several aspects: Set a Name and DescriptionProvide a unique name for your GPT to identify it.Add a brief description of its intended purpose or functionality.Define System BehaviorCustomize the GPT's instructions using a System Prompt.Example:This prompt will guide how the GPT behaves in conversations.Enable Plugins or Extensions (Optional)If supported, you can enable plugins or connect APIs to extend your GPT's functionality.For example, integrate real-time data fetching or third-party tools.Fine-Tune SettingsAdjust other available parameters to refine your GPT's responses, tone, and level of detail. Save and TestOnce you've configured the settings, click Save.Interact with your custom GPT to ensure it behaves as intended.If needed, return to the configuration tool to make adjustments. Use Your Custom GPTAfter saving, your custom GPT will appear in the left-hand menu of the ChatGPT interface.Select it whenever you want to chat using your customized assistant. Optional Advanced FeaturesPlugins Integration: Add third-party tools to expand functionality.API Connections: Integrate with external APIs for advanced capabilities.Live Data Access: Allow the GPT to connect to real-time data sources or databases. Notes and Best PracticesVersion Access: Some features may only be available for paid users (e.g., ChatGPT Plus or Enterprise).Data Security: Avoid including sensitive or private information in system instructions.Iterative Refinement: Test and adjust the behavior iteratively to ensure your GPT meets your needs. Now you're ready to create and deploy your own custom GPT! The Instructions and Schema of Cyber Nachos GPT are openly available on Cyber Nachos GPT's GitHub repository.","titles":["Cyber Nachos GPT"]},"9":{"title":"Introduction","content":"A unified and modular framework for robot learning that aims to simplify common workflows in robotics research. Isaac Lab is a unified and modular framework for robot learning that aims to simplify common workflows in robotics research (such as reinforcement learning, learning from demonstrations, and motion planning).\nIt is built upon NVIDIA Isaac Sim to leverage the latest simulation capabilities for photo-realistic scenes, and fast and efficient simulation. The core objectives of the framework are: Modularity: Easily customize and add new environments, robots, and sensors.Agility: Adapt to the changing needs of the community.Openness: Remain open-sourced to allow the community to contribute and extend the framework.Battery-included: Include a number of environments, sensors, and tasks that are ready to use. Key features available in Isaac Lab include fast and accurate physics simulation provided by PhysX, tiled rendering APIs for vectorized rendering, domain randomization for improving robustness and adaptability, and support for running in the cloud. Additionally, Isaac Lab provides over 26 environments, and we are actively working on adding more environments to the list.\nThese include classic control tasks, fixed-arm and dexterous manipulation tasks, legged locomotion tasks, and navigation tasks. A complete list is available in the environments section.","titles":[]},"10":{"title":"Installation Guide","content":"Learn how to install Isaac Lab and Isaac Sim on your system.","titles":[]},"11":{"title":"Installing Isaac Sim","content":"From Isaac Sim 4.0 release, it is possible to install Isaac Sim using pip. This approach is experimental and may have compatibility issues with some Linux distributions. Installing Isaac Sim with pip requires GLIBC 2.34+ version compatibility. To check the GLIBC version on your system, use command ldd --version.This may pose compatibility issues with some Linux distributions.\nFor instance, Ubuntu 20.04 LTS has GLIBC 2.31 by default. If you encounter compatibility issues, we recommend following the Isaac Sim Binaries Installation approach. On Windows with CUDA 12, the GPU driver version 552.86 is required. To use the pip installation approach for Isaac Sim, we recommend first creating a virtual environment. Ensure that the Python version of the virtual environment is Python 3.10. Next, install a CUDA-enabled PyTorch 2.4.0 build based on the CUDA version available on your system. This step is optional for Linux, but required for Windows to ensure a CUDA-compatible version of PyTorch is installed. Before installing Isaac Sim, ensure the latest pip version is installed. To update pip, run Then, install the Isaac Sim packages necessary for running Isaac Lab:","titles":["Installation Guide"]},"12":{"title":"Verifying the Isaac Sim installation","content":"Make sure that your virtual environment is activated (if applicable)Check that the simulator runs as expected: By default, this will launch an empty mini Kit window. To run with a specific experience file, run: When running Isaac Sim for the first time, all dependent extensions will be pulled from the registry.\nThis process can take upwards of 10 minutes and is required on the first run of each experience file.\nOnce the extensions are pulled, consecutive runs using the same experience file will use the cached extensions.In addition, the first run will prompt users to accept the Nvidia Omniverse License Agreement.\nTo accept the EULA, reply Yes when prompted with the below message:By installing or using Isaac Sim, I agree to the terms of NVIDIA OMNIVERSE LICENSE AGREEMENT (EULA)\nin https://docs.omniverse.nvidia.com/isaacsim/latest/common/NVIDIA_Omniverse_License_Agreement.htmlDo you accept the EULA? (Yes/No): Yes If the simulator does not run or crashes while following the above instructions, it means that something is incorrectly configured.\nTo debug and troubleshoot, please check Isaac Sim documentation and the forums.","titles":["Installation Guide","Installing Isaac Sim"]},"13":{"title":"Installing Isaac Sim","content":"","titles":["Installation Guide","Installing Isaac Sim"]},"14":{"title":"Cloning Isaac Lab","content":"Clone the Isaac Lab repository into your workspace:","titles":["Installation Guide","Installing Isaac Sim","Installing Isaac Sim"]},"15":{"title":"Installation","content":"Install dependencies using apt (on Ubuntu):Run the install command that iterates over all the extensions in source/extensions directory and installs them using pip (with --editable flag): By default, this will install all the learning frameworks.\nIf you want to install only a specific framework, you can pass the name of the framework as an argument.\nFor example, to install only the rl_games framework, you can runThe valid options are rl_games, rsl_rl, sb3, skrl, robomimic, none.","titles":["Installation Guide","Installing Isaac Sim","Installing Isaac Sim"]},"16":{"title":"Verifying the Isaac Lab installation","content":"To verify that the installation was successful, run the following command from the top of the repository: The above command should launch the simulator and display a window with a black ground plane. You can exit the script by pressing Ctrl+C on your terminal.\nOn Windows machines, please terminate the process from Command Prompt using Ctrl+Break or Ctrl+fn+B.","titles":["Installation Guide","Installing Isaac Sim","Installing Isaac Sim"]},"17":{"title":"Getting Started","content":"A template to demonstrate how to use Isaac Lab for reinforcement learning training. We have provided a template to demonstrate how to use Isaac Lab.\nThis template leverages a robotic arm and hand for reinforcement learning (RL) training.\nThe template is open-sourced and available at: https://github.com/CyberNachos/isaacLab.manipulation/tree/main.","titles":[]},"18":{"title":"Installation and Deployment of IsaacLab.manipulation","content":"Clone repository and install:Install RSL_RL in the isaacLab repository: You can design your own RL Algorithm by editing \"modules\" and \"algorithms\" in RSL-RL After completing the installation, you should be able to run the following examples: The --task parameter specifies which task to execute. These tasks are registered in the environment using gym.register. You can use Ctrl+F to locate where they are registered or modify the task name during registration if needed.The --headless mode disables the graphical interface. This is particularly useful when running a large number of parallel environments (envs). If you accidentally enable it, you can turn off the graphical interface by pressing the V key. If you are running only a few environments, you may choose to keep the graphical interface enabled. It is generally recommended to keep the graphical interface on (by omitting --headless) during testing.","titles":["Getting Started"]},"19":{"title":"Enabling fluid simulation","content":"A guide to enable fluid simulation in Isaac Lab for reinforcement learning training. Since Isaac Lab's support for fluid simulation in reinforcement learning (RL) is currently limited, we need to make some modifications to enable fluid simulation during RL training.\nTo the best of our knowledge (by 11/2024), no one has yet proposed a complete solution for conducting fluid simulation in Isaac Lab. The implementation steps are as follows: Run simulation with cpu mode using --device cpu.\nAfter extensive testing, we found that fluid motion is visible in the GUI only when Isaac Sim is running in CPU mode, regardless of whether the fabric extension is enabled.\nAdditionally, it is possible to retrieve the positions and velocities of fluid particles using Python code in this configuration.When running RL in CPU mode, some parts of the rsl_rl code may not function correctly.\nTo address this, you need to add the following line to line 114 of the on_policy_runner.py file located in rsl_rl\\rsl_rl\\runners:When running Isaac Lab in headless mode, the simulator settings differ from those in GUI mode, which prevents us from retrieving the positions of fluid particles.\nTo resolve this, modify lines 213-214 in the file IsaacLab\\source\\apps\\isaaclab.python.headless.kit as follows:The Manager-based workflow does not support fluid creation and reset, so we use the Direct workflow instead. Examples of the Direct workflow can be found in the directory:","titles":[]},"20":{"title":"The Code","content":"This is a sample code of RL training with fluid simulation:","titles":["Enabling fluid simulation"]},"21":{"title":"The Code Explained","content":"This section covers the implementation of fluid simulation in Isaac Lab. In Isaac Lab, when creating a scene, we typically only need to create one env, and the other envs are duplicated by Isaac Lab based on the first one.\nHowever, since Isaac Lab does not support duplicating particle objects, we need to create individual particle objects for each env. We use particleUtils.add_physx_particle_system to create the particle system and the CreateMdlMaterialPrim command to bind the physical and surface materials of the particles. It is important to note that the CreateAndBindMdlMaterialFromLibrary command is not available in headless mode, so we need to use the CreateMdlMaterialPrim command instead. Next, we configure the physical properties of the particle system. We use particleUtils.add_physx_particleset_points to create a particle set, which belongs to the particle system and contains the actual particles.\nIn an RL environment, only one particle system is needed, but a separate particle set must be created for each environment. Currently, there doesn't seem to be a direct way to retrieve the positions and velocities of particles from Isaac Lab's backend.\nAs a workaround, we use the UsdGeom Points API to obtain the particle states. This is also why it's necessary to enable UpdateToUsd and UpdateParticlesToUsd. Directly converting particle states into tensors is very slow, significantly impacting RL training efficiency. However, converting them into NumPy arrays is much faster.\nTherefore, we convert the particle positions into a NumPy array and record the minimum value along the z-axis for each group of particles, as this is the only data we need.","titles":["Enabling fluid simulation"]},"22":{"title":"Real-time Dexterous Telemanipulation","content":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach","titles":[]},"23":{"title":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach","content":"This paper presents the End-Effects-Oriented Learning-Based Dexterous Telemanipulation (EFOLD) Framework,\nwhich aims to overcome the challenges faced in robotic telemanipulation by focusing on outcomes rather than mimicking human hand motions.\nTraditional approaches to telemanipulation usually map human hand gestures onto a robotic hand, often neglecting the complex physical interactions involved.\nEFOLD addresses these shortcomings by utilizing Deep Reinforcement Learning (DRL) and focusing on end effects—key features that represent the physical consequences of manipulation, such as force, tactile feedback, and movement. This paper was presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),\na prestigious international conference that gathers top researchers and practitioners from across the globe to discuss advances in robotics, automation, and intelligent systems.\nIROS is widely recognized as one of the most influential conferences in the field of robotics, showcasing cutting-edge research and serving as a platform for sharing groundbreaking ideas. Key Highlights of the EFOLD Framework: End-Effect Modeling: EFOLD redefines the telemanipulation process by treating the task as a Markov Game, where the human operator and robot are considered separate agents.\nThe goal is to interpret the human operator's actions in terms of end effects that the robot must recreate.Deep Reinforcement Learning: By using a learning-based approach, EFOLD enables the robotic hand to autonomously recreate the necessary interactions with objects,\nleading to precise and efficient manipulation without overburdening the human operator.Human-Offline Training & Human-Online Testing: The framework adopts an innovative strategy where the DRL policy is trained offline,\nreducing the need for human input during training, and allowing humans to focus only on the testing phase. The framework was evaluated using a virtual Shadow Robot Hand to perform dexterous manipulation tasks. Results show that EFOLD can achieve real-time control with low latency and high precision. During testing,\nEFOLD demonstrated its capability to replicate end effects efficiently, achieving a command-following latency of less than 0.11s and highly accurate tracking with an MSE of less than 0.084 rad. Research Contributions: Markov Game Model: The telemanipulation problem was formulated as a Markov Game, allowing for the integration of human and robotic agents under a unified mathematical model.End Effect Categorization: Two categories of end effect extraction methods were proposed—internal and external—to enhance the interpretability and applicability of human commands.Efficient Training Approach: The human-offline training strategy significantly saves time and reduces human effort during the training process. This work sets a new benchmark for robot-assisted manipulation in environments where precision and real-time response are critical, such as telesurgery and remote exploration. The paper and related materials, including implementation code, are available on GitHub.","titles":["Real-time Dexterous Telemanipulation"]},"24":{"title":"Hallucination Prevention in LLMs","content":"Zero-Resource Hallucination Prevention for Large Language Models","titles":[]},"25":{"title":"Zero-Resource Hallucination Prevention for Large Language Models","content":"The paper \"Zero-Resource Hallucination Prevention for Large Language Models\", published in the Findings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024 Findings),\nheld from November 12–16 in Miami, Florida, introduces a novel approach to mitigating hallucinations—instances where large language models (LLMs)\nproduce inaccurate or ungrounded information. EMNLP, organized by the Association for Computational Linguistics (ACL), is one of the premier conferences in\nthe field of natural language processing (NLP). It provides a leading platform for presenting groundbreaking research in NLP and computational linguistics,\nattracting researchers, practitioners, and industry leaders worldwide. The Findings of EMNLP serves as an associated venue for high-quality papers, ensuring a broader platform for innovative contributions. This paper proposes SELF-FAMILIARITY, a zero-resource pre-detection mechanism that evaluates the model's\nfamiliarity with the concepts in a given instruction and refrains from generating responses if the concepts are unfamiliar. Key Contributions: Self-Familiarity Mechanism: This approach mimics human self-assessment, analyzing concept familiarity to prevent hallucinations proactively rather than correcting them post hoc.Three-Step Framework:Concept Extraction: Identifies key entities within an instruction.Concept Guessing: Assesses the familiarity of extracted concepts using prompt engineering.Aggregation: Combines familiarity scores of all concepts to determine the overall instruction familiarity.Robustness and Versatility: Unlike previous methods, SELF-FAMILIARITY achieves consistent performance across different LLMs and instruction styles without requiring external knowledge or resources.Empirical Validation: Evaluated across four LLMs using the proposed Concept-7 dataset, SELF-FAMILIARITY outperforms existing methods in detecting hallucinatory instructions, showcasing higher accuracy, consistency, and interpretability. This work marks a shift toward proactive and preventative strategies for hallucination mitigation in LLMs, enhancing their reliability and usability in real-world applications. The paper and related materials, including the implementation code, are available on GitHub and AccessData.","titles":["Hallucination Prevention in LLMs"]},"26":{"title":"Robotics Dataset Comparison","content":"A comprehensive overview and comparative analysis of 16 mainstream robotics datasets and frameworks, including LeRobot, Open X-Embodiment, DROID, RoboTurk, MIME, Meta-World, RoboNet, RoboSet, BridgeData V2, RT-1, Dobb·E, RH20T, BC-Z, MT-Opt, VIMA, and SPOC. Below is a comprehensive overview and comparative analysis of 16 mainstream robotics datasets and frameworks. The report is organized into two parts: first, a summary table that highlights key characteristics, and second, detailed descriptions of each dataset's scope, technical features, advantages, and disadvantages. Note: This analysis is accurate as of the last modified date, \"Mar 28, 2025.\"","titles":[]},"27":{"title":"Summary Table","content":"Dataset / FrameworkScope & ApplicationScale & ModalitiesKey AdvantagesKey Disadvantages1. LeRobot  (GitHub)Real-world robotics for imitation and reinforcement learning; supports both simulation and physical robots.Pretrained models and demo datasets; primarily visual and robot state data with temporal (multi-frame) context.End-to-end learning with community support; integrated simulation environments.Complex setup; may require substantial computing and sensor calibration.2. Open X-Embodiment  (Website)Large-scale, multi-embodiment robotic manipulation; pooling data from many institutions.1M+ trajectories spanning 22 robot embodiments; heterogeneous real-world data.Massive diversity enabling cross-robot transfer and positive knowledge sharing.Heterogeneous quality and potential standardization issues across varied sources.3. DROID  (Website)In-the-wild robot manipulation for robust imitation learning.76K demonstration trajectories (~350 hours) recorded with Franka Panda arms; multiple camera viewpoints.Diverse, large-scale manipulation data that improves policy robustness.Mostly limited to manipulation with a specific hardware setup; less diversity in task types.4. RoboTurk  (Website)Crowdsourced robotic skill learning via teleoperation; real-world demonstration collection.Pilot and real-world datasets (hundreds to thousands of demos, several hours of data) from teleoperated sessions.Leverages non-expert, scalable human demonstrations; supports collaborative tasks.Variation in demonstration quality and potential limits in scale compared to fully automated data collection.5. MIME  (Google Sites)Imitation learning for robot manipulation using human demonstrations.Multi-modal data (visual, robot states, actions) collected via teleoperation; moderate number of trajectories.Focus on high-quality manipulation trajectories; well-suited for imitation learning.May be smaller in scale and less diverse than some large-scale multi-robot datasets.6. Meta-World  (Website)Benchmark for multi-task and meta-reinforcement learning in simulation.50 distinct simulated manipulation environments; task variations with visual observations.Standardized benchmark for meta-RL; structured for evaluating generalization.Limited to simulation and may not capture the full variability of real-world settings.7. RoboNet  (Website)Open database of real robotic experience for manipulation tasks across multiple platforms.~15M video frames, collected from 7 robot platforms with diverse camera viewpoints.Large-scale, multi-platform real-world data that facilitates cross-robot generalization.Very high storage and processing requirements; complex data integration.8. RoboSet  (Website)Multi-task dataset for household (kitchen) manipulation tasks, including language instructions.28,500 trajectories (mix of ~9.5K teleop and ~19K kinesthetic demos), recorded with 4 camera views per frame.Rich, multi-modal data in realistic home environments; supports language-guided sequencing.Domain-specific (largely kitchens); may not generalize to non-domestic scenarios.9. BridgeData V2  (Website)Large-scale robotic manipulation across diverse environments and skills with language annotations.~60K trajectories, 24 environments, 13 skills; includes multi-view (fixed, wrist, randomized) RGB (and depth) data plus natural language.Very diverse and large-scale, ideal for cross-domain generalization and multi-modal learning.Often collected with a specific robot (e.g. WidowX); complex setup and annotation consistency challenges.10. RT-1  (Website)Real-world imitation learning for multi-task manipulation using transformer architectures.Over 130K episodes covering 700+ tasks from 13 robots; uses visual and language inputs for closed-loop control.Outstanding generalization and performance on diverse tasks; scalable transformer model.High training and computational requirements; system complexity may be a barrier.11. Dobb·E  (Website)Framework for home robotics: learning household manipulation tasks quickly in real homes.“HoNY” dataset: 13 hours from 22 NYC homes, 5,620 trajectories, RGB and depth at 30 fps; also includes hardware (the “Stick”) for data collection.Cost-effective, rapid task learning with real household data; designed for generalist home robots.Domain-specific to domestic settings; quality and consistency can vary with non-expert demonstrations.12. RH20T  (Website)Comprehensive dataset for contact-rich, multi-modal robot manipulation tasks in the real world.Millions of human-robot demonstration pairs; modalities include high-resolution RGB, depth, force/torque, audio, tactile, and high-frequency joint data.Extremely rich multi-modal data enabling detailed analysis and one-shot imitation learning.Very large and complex; requires significant computational and storage resources; complex data processing pipeline.13. BC-Z  (Website)Large-scale behavior cloning for robotic manipulation.(Details are sparser online but BC-Z is designed to support imitation learning with a large number of trajectories.)Provides a standardized dataset specifically aimed at behavior cloning; useful for benchmarking imitation algorithms.May offer less diversity outside manipulation tasks and less extensive documentation compared to other datasets.14. MT-Opt  (Website)Multi-task reinforcement learning at scale across many manipulation skills.Data collected from 7 robots over 9,600 robot hours spanning 12 tasks; continuous multi-task RL framework.Enables simultaneous learning across tasks; improves performance especially on underrepresented skills through shared experience.Demands large-scale infrastructure and careful task specification; complexity in multi-task coordination.15. VIMA  (Website)General robot manipulation via multimodal prompts (combining language and vision) for unified task specification.Benchmark with thousands of procedurally generated tabletop task instances; uses imitation learning data alongside transformer-based models.Unified formulation that “prompts” the robot to perform diverse tasks; highly scalable and sample-efficient.Primarily demonstrated in benchmark/simulated settings; real-world transfer may require additional adaptation.16. SPOC  (Website)Imitation learning for long-horizon navigation and manipulation using shortest path imitation (trained in simulation, deployed in the real world).Trained with RGB-only inputs in simulation; demonstrated on real robots for tasks such as object fetching and navigation.Robust long-horizon planning; effective sim-to-real transfer with minimal sensing (RGB only); no need for depth or privileged info.RGB-only perception can limit object recognition; some failure cases persist in challenging real-world scenarios.","titles":["Robotics Dataset Comparison"]},"28":{"title":"Detailed Comparison","content":"","titles":["Robotics Dataset Comparison"]},"29":{"title":"1. LeRobot","content":"Scope & Application:\nLeRobot is designed to lower the barrier for robotics research by providing an end-to-end learning framework with integrated pretrained models, diverse datasets, and simulation environments. It is well suited for imitation and reinforcement learning research on both simulated and real robots. Technical Features: Built in PyTorch with modular dataset classes that support multi-frame temporal sampling.Offers pretrained policies (e.g. ACT, Diffusion, TDMPC) and supports various robot platforms and environments. Advantages: Community-driven with active contributions and hosted on Hugging Face.Facilitates rapid prototyping in robotics with an accessible codebase. Disadvantages: Complexity in data handling (various sensor streams and temporal dynamics) can demand significant compute and expertise.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"30":{"title":"2. Open X-Embodiment","content":"Scope & Application:\nA collaborative effort pooling robot data from 21 institutions, it is aimed at training “generalist” policies across 22 different robot embodiments. Technical Features: Aggregates 1M+ trajectories from diverse robots and tasks.Supports learning via transformer-based architectures that can generalize across different embodiments. Advantages: Unmatched diversity, which is ideal for studying cross-robot transfer.Large scale increases the potential for generalization. Disadvantages: The heterogeneity of data can introduce inconsistencies; standardizing varied datasets is challenging.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"31":{"title":"3. DROID","content":"Scope & Application:\nFocused on in-the-wild robot manipulation, DROID offers a vast dataset for robust imitation learning using Franka Panda robots. Technical Features: Contains 76K trajectories (~350 hours) across 564 scenes and 86 tasks.Multi-camera views (including wrist and exterior images) enable rich visual inputs. Advantages: Large, diverse dataset that significantly boosts policy performance and robustness.Extensive coverage of real-world scenarios. Disadvantages: Being collected with a specific hardware platform, its applicability to other robots may be limited.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"32":{"title":"4. RoboTurk","content":"Scope & Application:\nRoboTurk is a crowdsourcing platform that leverages teleoperation for collecting human demonstrations on both simulated and real robotic tasks. Technical Features: Provides datasets with hundreds to thousands of successful demonstrations (e.g. pilot dataset and real-world dataset).Includes system features for low-latency teleoperation and human-in-the-loop interventions. Advantages: Enables scalable data collection from non-experts, lowering the cost of obtaining rich demonstrations.Proven effectiveness in enabling imitation learning on challenging tasks. Disadvantages: The quality of demonstrations may vary due to differences in human teleoperation skills.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"33":{"title":"5. MIME","content":"Scope & Application:\nMIME targets imitation learning for manipulation, offering human demonstrations that capture complex manipulation behaviors. Technical Features: Multi-modal data including visual inputs and robot state/action trajectories collected through teleoperation. Advantages: Focused on detailed manipulation tasks, making it ideal for imitation learning studies. Disadvantages: Generally smaller in scale compared to some of the largest datasets; might offer limited diversity.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"34":{"title":"6. Meta-World","content":"Scope & Application:\nA simulation benchmark intended for meta-reinforcement learning and multi-task learning, Meta-World comprises 50 distinct manipulation environments. Technical Features: Structured environments with varying goal positions and task variations to test generalization. Advantages: Standardized and well-documented benchmark that is widely used for evaluating meta-RL algorithms. Disadvantages: Limited to simulated settings; real-world complexities (e.g. sensor noise, dynamics variations) are not fully captured.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"35":{"title":"7. RoboNet","content":"Scope & Application:\nRoboNet is an open database of robotic experience collected from 7 different robot platforms, with an emphasis on visual data for manipulation. Technical Features: Contains over 15M video frames and data from multiple camera viewpoints. Advantages: Offers vast amounts of real-world data to study generalization across different robot hardware. Disadvantages: Requires heavy storage and processing; integrating multi-platform data can be challenging.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"36":{"title":"8. RoboSet","content":"Scope & Application:\nA dataset focused on household (kitchen) manipulation tasks, RoboSet provides both kinesthetic and teleoperated demonstrations with language instructions. Technical Features: 28,500 trajectories captured with 4 camera views per frame; tasks are semantically grouped. Advantages: Rich multi-modal information (visual + language) supports language-guided robotic learning. Disadvantages: Domain-specific to kitchen and household scenes; may not generalize to industrial or outdoor scenarios.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"37":{"title":"9. BridgeData V2","content":"Scope & Application:\nDesigned to boost generalization in robotic skills, BridgeData V2 spans 24 environments and 13 skills, with natural language annotations for goal conditioning. Technical Features: Approximately 60K trajectories with multi-view RGB (and some depth) data.Includes both teleoperated and scripted demonstrations. Advantages: High diversity in environments and tasks; strong support for language-conditioned policy learning. Disadvantages: Often tied to a particular hardware setup (e.g. WidowX 250), and the multi-view setup can complicate data preprocessing.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"38":{"title":"10. RT-1","content":"Scope & Application:\nRT-1 is a state-of-the-art transformer-based model for real-world robotic control trained on a massive dataset of diverse tasks. Technical Features: Over 130K episodes covering more than 700 tasks collected from 13 robots.Utilizes vision and natural language inputs to produce discretized action tokens. Advantages: Demonstrates superior performance and generalization, including sim-to-real transfer.Scalability through high-capacity transformer models. Disadvantages: Demands extensive data, compute, and engineering expertise; system complexity is high.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"39":{"title":"11. Dobb·E","content":"Scope & Application:\nDobb·E focuses on home robotics, providing a full stack (hardware, dataset, models) for learning household manipulation tasks with minimal demonstration time. Technical Features: “HoNY” dataset includes 13 hours of data from 22 New York City homes (5,620 trajectories, RGB + depth at 30 fps).Includes a low-cost hardware “Stick” for demonstration collection. Advantages: Cost-effective and designed for rapid task learning in domestic environments.Demonstrates strong real-world applicability in home settings. Disadvantages: Domain-specific and may not translate to other application areas; non-expert demonstrations can introduce variability.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"40":{"title":"12. RH20T","content":"Scope & Application:\nRH20T is a comprehensive dataset aimed at learning diverse, contact-rich manipulation skills with extensive multi-modal sensor information. Technical Features: Contains millions of demonstration pairs with modalities including high-resolution RGB, depth, force/torque, audio, and tactile sensing.Detailed synchronization and calibration across multiple sensors. Advantages: Extremely rich and diverse data ideal for advancing one-shot imitation learning and fine-grained sensor fusion.Supports research on contact-rich and dexterous manipulation. Disadvantages: Enormous data volume makes it challenging to store, process, and analyze; high complexity in data format and licensing.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"41":{"title":"13. BC-Z","content":"Scope & Application:\nBC-Z is targeted at behavior cloning for robotic manipulation, providing a large-scale dataset that is useful as a benchmark for imitation learning approaches. Technical Features: Although details are less extensively documented online, BC-Z is positioned alongside other large imitation learning datasets. Advantages: Serves as a standardized resource for evaluating behavior cloning algorithms. Disadvantages: May not offer as much diversity or multi-modal richness as some of the larger, more comprehensive datasets.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"42":{"title":"14. MT-Opt","content":"Scope & Application:\nMT-Opt is a framework for continuous multi-task reinforcement learning designed to learn a wide repertoire of manipulation skills concurrently. Technical Features: Built on data collected from 7 robots over 9,600 hours, spanning 12 tasks with a scalable RL method. Advantages: Effective at sharing experience across tasks, significantly boosting performance on rare tasks.Demonstrates both zero-shot and rapid fine-tuning capabilities. Disadvantages: Requires large-scale robotic infrastructure and sophisticated multi-task training pipelines.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"43":{"title":"15. VIMA","content":"Scope & Application:\nVIMA presents a novel formulation in which diverse robot manipulation tasks are “prompted” via interleaved language and visual tokens, unifying task specification. Technical Features: Transformer-based model that leverages multimodal prompts; benchmark includes thousands of procedurally generated tabletop task instances. Advantages: Unified, scalable approach that achieves strong zero-shot generalization and high sample efficiency.Allows integration of various forms of task instructions (text + image). Disadvantages: Largely demonstrated in controlled (often simulated or tabletop) settings; additional work may be needed for full real-world deployment.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"44":{"title":"16. SPOC","content":"Scope & Application:\nSPOC focuses on long-horizon navigation and manipulation by imitating shortest paths. Trained entirely in simulation (using RGB-only inputs), it is deployed in the real world without extra sim-to-real adaptation. Technical Features: Uses a transformer-based action decoder conditioned on language instructions and sequential RGB frames.Emphasizes a minimalist sensory setup (RGB only) to drive exploration and task completion. Advantages: Achieves robust long-horizon planning and recovery in real-world tasks despite minimal input modalities.Trains entirely in simulation and transfers effectively. Disadvantages: RGB-only perception can limit object detection accuracy; some failure cases persist in complex or cluttered real-world scenarios.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"45":{"title":"General-Purpose Robot Models Analysis","content":"Overview of recent works on general-purpose robot models, comparing key technical aspects and hardware/time requirements for training, fine-tuning, or distillation. Bellow provides an overview of several recent works on general-purpose robot models. It compares key technical aspects—such as model architecture, parameter scale, training data volume, and major innovations—and outlines the typical hardware and time requirements for training, fine-tuning, or distillation. Note: This analysis is accurate as of the last modified date, \"Mar 28, 2025.\"","titles":[]},"46":{"title":"Comparison of Robot Models","content":"Below is a table summarizing 10 projects, including their model architecture/method, parameter scale, training data volume, and key features/remarks. (Note: For some projects, specific numbers such as parameter counts or data volumes are not disclosed; descriptive indicators are provided instead.) Project NameModel Architecture / MethodParameter ScaleTraining Data / Data VolumeKey Features / Remarks1. Octo  (Website)Transformer-based diffusion policy supporting language, target images, and sensor history conditioningOcto-Small: 27MOcto-Base: 93MPre-trained on 800k robot demonstrations, integrating 25 datasets (Open X-Embodiment)Flexibly adaptable to different robots and sensors; efficient fine-tuning; excellent performance in zero-shot and few-shot scenarios2. OpenVLA  (Website)Fuses a visual encoder (SigLIP + DinoV2) with a Llama 2 7B language model to generate action tokens7BPre-trained on 970k robot demonstrations (Open X-Embodiment)Leverages internet pre-trained vision-language knowledge; supports multi-robot control; resource-intensive training (64 A100 GPUs, 15 days)3. UMI  (Website)Data collection and policy learning framework based on a handheld gripper and wrist-mounted camera for in-the-wild demonstrationsNot disclosedRapid in-the-wild demonstration capture (approx. 30 seconds per demo), with high data diversityLow-cost, portable hardware design; enables zero-calibration and bimanual dynamic manipulation; focuses on demonstration data collection4. RDT-1B  (Website)Transformer policy based on diffusion models, specifically designed for bimanual manipulation1.2BPre-trained on 46 datasets with over 1M demonstrations; additional 6K+ bimanual demonstrationsLarge-scale pre-training, multi-task cross-robot capability; excellent zero-shot generalization and few-shot learning ability5. openpi  (GitHub)Consists of π₀ (streaming diffusion VLA) and π₀-FAST (autoregressive VLA) for vision-language-action tasksNot explicitly disclosedPre-trained on 10k+ hours of robot dataProvides multiple base model checkpoints; easy fine-tuning for downstream tasks; adaptable to various robot platforms6. Mobile ALOHA  (Website)Imitation learning (behavior cloning) based mobile manipulation system combining whole-body control and low-cost remote operationNot disclosedApproximately 50 demonstrations per task, jointly trained with a static ALOHA datasetExtends traditional ALOHA to mobile platforms; enables complex mobile manipulation tasks (e.g., opening doors, using elevators)7. RT-2  (Website)Vision-language-action model that encodes robot actions as text tokens, combining internet pre-training with robot dataBased on PaLM-E: 12Bor PaLI-X: 55BMixed large-scale internet vision-language data and robot trajectory data (exact numbers undisclosed)Utilizes a pre-trained large model’s semantic understanding and reasoning; enables multi-step task planning and coherent execution; strong generalization8. VIMA  (Website)Transformer-based robotic agent that generates actions through multimodal prompts (language, image/video)2M - 200M (depending on variant)Over 600K expert demonstrations; supplemented with large amounts of programmatically generated task dataData-efficient; unified representation for various tasks; exhibits good zero-shot generalization and cross-task adaptability9. Perceiver-Actor  (Website)Behavior cloning strategy based on a Perceiver Transformer, using RGB-D voxelized input and discretized action predictionNot disclosed (relatively lightweight)Demonstration counts are relatively low (e.g., for RLBench with 249 variants and 7 real-world tasks, approx. 53 demos)Data-efficient learning for 6-DoF manipulation; suitable for few-shot multi-task scenarios; high-performance action detection10. SayCan  (Website)Integrates a large language model with pre-trained skill/value functions; uses language scoring combined with execution probabilities for task planningBased on LLM (e.g., PaLM) with parameters up to tens of billions; skill modules are smallerUtilizes large-scale internet text and robot skill demonstration data (exact figures undisclosed)Achieves long-horizon task planning and semantic reasoning; composes multi-step skills; supports multilingual capability; improves execution success rate","titles":["General-Purpose Robot Models Analysis"]},"47":{"title":"Hardware and Time Requirements for Training, Fine-Tuning, or Distillation","content":"The following table outlines typical hardware devices and approximate training times for various stages, such as pre-training (full training), fine-tuning (or parameter-efficient fine-tuning), and distillation. Actual requirements vary depending on model scale, data volume, training strategy (e.g., full vs. parameter-efficient fine-tuning), and task specifics. Project NamePre-training / Full Training (Hardware & Time)Fine-Tuning / Parameter-Efficient Fine-Tuning / Distillation (Hardware & Time)Remarks1. Octo  (Website)- Pre-training on 800k demos typically requires multiple high-performance GPUs (e.g., A100/RTX4090)- Training time: several days to weeks- Fine-tuning using efficient strategies can often be completed on a single GPU in a few hours to one dayAdaptable to different robots and sensors; fine-tuning time is relatively short2. OpenVLA  (Website)- Pre-training used 64 A100 GPUs, with a training duration of about 15 days- Task-specific fine-tuning using parameter-efficient methods usually takes a few hours to one day on a single GPULeverages large-scale internet pre-training; resource-intensive3. UMI  (Website)- Focused on data collection and policy learning; training can be done on low-cost GPUs (or even a single card)- Training time: on the order of a few hours- Fine-tuning for specific tasks (using fast demonstration capture) typically completes within hoursUses portable hardware design; suitable for in-the-wild demonstration data4. RDT-1B  (Website)- Pre-training a 1.2B parameter model generally requires a multi-GPU cluster (e.g., 8-16 A100 GPUs)- Training time: possibly over a week- Fine-tuning on specific bimanual tasks (using additional 6K+ demos) may take from a few hours to one dayLarge parameter scale and rich data; high resource and time demand for pre-training5. openpi  (GitHub)- Full training on 10k+ hours of robot data may require high-memory GPUs (e.g., A100/H100)- Parameter-efficient fine-tuning (e.g., using LoRA) typically requires at least 22.5GB of GPU memory (e.g., RTX4090) with training times from a few hours to a few daysOffers both full training and efficient fine-tuning options; hardware requirements are clearly defined6. Mobile ALOHA  (Website)- Imitation learning methods typically train on a single high-end GPU (e.g., RTX 3090/4090)- Training time: several hours to one day- Fine-tuning using combined static ALOHA data generally completes on a single GPU in a short periodFocuses on mobile and whole-body control; relatively small data volume7. RT-2  (Website)- Large models (12B-55B parameters) require extensive GPU clusters (e.g., 64 A100 GPUs)- Pre-training time: typically several weeks- Fine-tuning for specific tasks using joint training strategies may take from a few hours to one day, depending on data volumeCombines internet-scale pre-training with robot data; high hardware and time requirements8. VIMA  (Website)- Model sizes range from a few million to several hundred million parameters- Smaller variants can be trained on a single GPU in hours; larger variants may need multiple GPUs for days to a week- Fine-tuning is typically done on a single GPU or a small multi-GPU setup; high data efficiency can greatly reduce training timeModel and data scale are adjustable, making fine-tuning flexible9. Perceiver-Actor  (Website)- Due to voxelized inputs and discrete action prediction, training can often be done on a single GPU (8-16GB memory)- Training time: typically several hours to one day- Fine-tuning for few-shot scenarios is highly efficient, often completing within a few hoursEmphasizes data-efficient learning for 6-DoF manipulation; suitable for low-resource environments10. SayCan  (Website)- Integrates a large language model (e.g., PaLM series) with robot skills; pre-training typically uses TPUs or large-scale GPU clusters- Pre-training time: may span several weeks- Fine-tuning or distillation for specific scenarios is typically carried out on multi-GPU or TPU setups, taking from a few hours to one dayCombines semantic reasoning with low-level skills; high resource requirements for pre-training, but fine-tuning can leverage LLM improvements","titles":["General-Purpose Robot Models Analysis"]},"48":{"title":"Home","content":"Welcome to Cyber NachosA pioneering initiative committed to advancing the field of modern robotics, Artificial Intelligence (AI), and Cybersecurity.","titles":[]}},"dirtCount":0,"index":[["π₀",{"1":{"46":2}}],["+",{"1":{"36":1,"39":1,"43":1,"46":1}}],["quickly",{"1":{"27":1}}],["quality",{"1":{"25":1,"27":4,"32":1}}],["970k",{"1":{"46":1}}],["93mpre",{"1":{"46":1}}],["9",{"0":{"37":1},"1":{"27":2,"42":1}}],["800k",{"1":{"46":1,"47":1}}],["8",{"0":{"36":1},"1":{"27":1,"47":2}}],["86",{"1":{"11":1,"31":1}}],["~60k",{"1":{"27":1}}],["~19k",{"1":{"27":1}}],["~15m",{"1":{"27":1}}],["~9",{"1":{"27":1}}],["~350",{"1":{"27":1,"31":1}}],["6k+",{"1":{"46":1,"47":1}}],["64",{"1":{"46":1,"47":2}}],["60k",{"1":{"37":1}}],["600k",{"1":{"46":1}}],["600",{"1":{"27":1,"42":1}}],["620",{"1":{"27":1,"39":1}}],["6",{"0":{"34":1},"1":{"27":1,"46":1,"47":1}}],["5gb",{"1":{"47":1}}],["53",{"1":{"46":1}}],["55b",{"1":{"47":1}}],["55bmixed",{"1":{"46":1}}],["552",{"1":{"11":1}}],["564",{"1":{"31":1}}],["5k",{"1":{"27":1}}],["500",{"1":{"27":1,"36":1}}],["50",{"1":{"27":1,"34":1,"46":1}}],["5",{"0":{"33":1},"1":{"27":2,"39":1}}],["7b",{"1":{"46":1}}],["700",{"1":{"38":1}}],["700+",{"1":{"27":1}}],["76k",{"1":{"27":1,"31":1}}],["7",{"0":{"35":1},"1":{"25":1,"27":3,"35":1,"42":1,"46":2}}],["zero",{"0":{"25":1},"1":{"24":1,"25":2,"42":1,"43":1,"46":4}}],["z",{"0":{"41":1},"1":{"21":1,"26":1,"27":2,"41":2}}],["zhang",{"1":{"6":2}}],["zheshuo",{"1":{"6":1}}],["zhejiang",{"1":{"6":1}}],["kinesthetic",{"1":{"27":1,"36":1}}],["kitchens",{"1":{"27":1}}],["kitchen",{"1":{"27":1,"36":2}}],["kit",{"1":{"12":1,"19":1}}],["knowledge",{"1":{"19":1,"25":1,"27":1,"46":1}}],["keep",{"1":{"18":2}}],["key",{"1":{"7":1,"9":1,"18":1,"23":2,"25":2,"26":1,"45":2,"46":1}}],["084",{"1":{"23":1}}],["04",{"1":{"11":1}}],["0",{"1":{"11":2,"23":2}}],["4090",{"1":{"47":1}}],["46",{"1":{"46":1}}],["4",{"0":{"32":1},"1":{"11":2,"27":2,"36":1}}],["jointly",{"1":{"46":1}}],["joint",{"1":{"27":1,"47":1}}],["journey",{"1":{"7":1}}],["jinpu",{"1":{"6":1}}],["jiang",{"1":{"6":1}}],["jiayuan",{"1":{"6":1}}],["jiu",{"1":{"6":1}}],["vs",{"1":{"47":1}}],["voxelized",{"1":{"46":1,"47":1}}],["volumecombines",{"1":{"47":1}}],["volume7",{"1":{"47":1}}],["volumekey",{"1":{"46":1}}],["volumes",{"1":{"46":1}}],["volume",{"1":{"40":1,"45":1,"46":1,"47":1}}],["vla",{"1":{"46":2}}],["v2",{"0":{"37":1},"1":{"26":1,"27":1,"37":1}}],["v",{"1":{"18":1}}],["vast",{"1":{"31":1,"35":1}}],["varying",{"1":{"34":1}}],["vary",{"1":{"27":1,"32":1,"47":1}}],["variants",{"1":{"46":1,"47":2}}],["variant",{"1":{"46":1}}],["variability",{"1":{"27":1,"39":1}}],["variations",{"1":{"27":1,"34":2}}],["variation",{"1":{"27":1}}],["varied",{"1":{"27":1,"30":1}}],["various",{"1":{"2":1,"29":2,"43":1,"46":2,"47":1}}],["value",{"1":{"21":1,"46":1}}],["validation",{"1":{"25":1}}],["valid",{"1":{"15":1}}],["view",{"1":{"27":1,"37":2}}],["views",{"1":{"27":1,"31":1,"36":1}}],["viewpoints",{"1":{"27":2,"35":1}}],["video",{"1":{"27":1,"35":1,"46":1}}],["via",{"1":{"27":3,"30":1,"43":1}}],["visual",{"1":{"27":4,"31":1,"33":1,"35":1,"36":1,"43":1,"46":1}}],["visible",{"1":{"19":1}}],["vision",{"1":{"7":1,"27":1,"38":1,"46":4}}],["vima",{"0":{"43":1},"1":{"26":1,"27":1,"43":1,"46":1,"47":1}}],["virtual",{"1":{"11":2,"12":1,"23":1}}],["venue",{"1":{"25":1}}],["velocities",{"1":{"19":1,"21":1}}],["versatility",{"1":{"25":1}}],["version",{"1":{"11":8}}],["very",{"1":{"21":1,"27":3}}],["verify",{"1":{"16":1}}],["verifying",{"0":{"12":1,"16":1}}],["vectorized",{"1":{"9":1}}],["ve",{"1":{"8":1}}],["york",{"1":{"39":1}}],["your",{"1":{"7":4,"8":13,"10":1,"11":2,"12":1,"14":1,"16":1,"18":1}}],["you",{"1":{"7":1,"8":8,"11":1,"12":1,"15":3,"16":1,"18":7,"19":1}}],["yet",{"1":{"19":1}}],["yes",{"1":{"12":3}}],["yang",{"1":{"6":1}}],["yidan",{"1":{"6":1}}],["x",{"0":{"30":1},"1":{"26":1,"27":1,"46":3}}],["xiaoyu",{"1":{"6":1}}],["xingyu",{"1":{"6":1}}],["xi",{"1":{"6":1}}],["xu",{"1":{"6":2}}],["good",{"1":{"46":1}}],["google",{"1":{"27":1}}],["goal",{"1":{"23":1,"34":1,"37":1}}],["given",{"1":{"25":1}}],["github",{"1":{"8":1,"17":1,"23":1,"25":1,"27":1,"46":1,"47":1}}],["globe",{"1":{"23":1}}],["glibc",{"1":{"11":3}}],["greatly",{"1":{"47":1}}],["gripper",{"1":{"46":1}}],["grained",{"1":{"40":1}}],["graphical",{"1":{"18":4}}],["grouped",{"1":{"36":1}}],["group",{"1":{"21":1}}],["ground",{"1":{"16":1}}],["groundbreaking",{"1":{"7":1,"23":1,"25":1}}],["gym",{"1":{"18":1}}],["generates",{"1":{"46":1}}],["generate",{"1":{"46":1}}],["generated",{"1":{"27":1,"43":1,"46":1}}],["generating",{"1":{"25":1}}],["general",{"0":{"45":1},"1":{"27":1,"45":2},"2":{"46":1,"47":1}}],["generalist",{"1":{"27":1,"30":1}}],["generalize",{"1":{"27":1,"30":1,"36":1}}],["generalization8",{"1":{"46":1}}],["generalization",{"1":{"27":4,"30":1,"34":1,"35":1,"37":1,"38":1,"43":1,"46":2}}],["generally",{"1":{"18":1,"33":1,"47":2}}],["gestures",{"1":{"23":1}}],["getting",{"0":{"17":1},"2":{"18":1}}],["georgia",{"1":{"6":1}}],["game",{"1":{"23":3}}],["games",{"1":{"15":2}}],["gathers",{"1":{"23":1}}],["gao",{"1":{"6":1}}],["gpuleverages",{"1":{"47":1}}],["gpus",{"1":{"46":1,"47":7}}],["gpu",{"1":{"11":1,"47":12}}],["gptafter",{"1":{"8":1}}],["gpts",{"0":{"8":1},"1":{"8":4}}],["gpt",{"0":{"7":1},"1":{"7":4,"8":18},"2":{"8":1}}],["g",{"1":{"8":1,"27":1,"29":1,"32":1,"34":1,"37":1,"46":3,"47":9}}],["guessing",{"1":{"25":1}}],["gui",{"1":{"19":2}}],["guided",{"1":{"27":1,"36":1}}],["guides",{"1":{"7":1}}],["guide",{"0":{"10":1},"1":{"7":1,"8":1,"19":1},"2":{"11":1,"12":1,"13":1,"14":1,"15":1,"16":1}}],["guo",{"1":{"6":1}}],["guarantee",{"1":{"2":1}}],["umi",{"1":{"46":1,"47":1}}],["undisclosed",{"1":{"46":2}}],["understanding",{"1":{"46":1}}],["underrepresented",{"1":{"27":1}}],["under",{"1":{"23":1}}],["unmatched",{"1":{"30":1}}],["unlike",{"1":{"25":1}}],["unfamiliar",{"1":{"25":1}}],["ungrounded",{"1":{"25":1}}],["unifying",{"1":{"43":1}}],["unified",{"1":{"9":2,"23":1,"27":2,"43":1,"46":1}}],["unique",{"1":{"8":1}}],["university",{"1":{"6":15}}],["utilizing",{"1":{"23":1}}],["utilizes",{"1":{"38":1,"46":1}}],["utilize",{"1":{"4":1}}],["up",{"1":{"46":1}}],["upwards",{"1":{"12":1}}],["updateparticlestousd",{"1":{"21":1}}],["updatetousd",{"1":{"21":1}}],["update",{"1":{"11":1}}],["upon",{"1":{"9":1}}],["ubuntu",{"1":{"11":1,"15":1}}],["usability",{"1":{"25":1}}],["usually",{"1":{"23":1,"47":1}}],["usdgeom",{"1":{"21":1}}],["us",{"1":{"19":1}}],["used",{"1":{"34":1,"47":1}}],["uses",{"1":{"27":2,"44":1,"46":1,"47":1}}],["useful",{"1":{"18":1,"27":1,"41":1}}],["users",{"1":{"8":1,"12":1}}],["use",{"1":{"8":1,"9":1,"11":2,"12":1,"17":2,"18":1,"19":1,"21":4}}],["using",{"1":{"8":2,"11":1,"12":2,"15":2,"16":1,"18":1,"19":2,"23":2,"25":2,"27":3,"31":1,"44":1,"46":2,"47":7}}],["3090",{"1":{"47":1}}],["30",{"1":{"27":1,"39":1,"46":1}}],["31",{"1":{"11":1}}],["34+",{"1":{"11":1}}],["3",{"0":{"4":1,"31":1},"1":{"11":1,"27":1,"46":1}}],["nyc",{"1":{"27":1}}],["nlp",{"1":{"25":2}}],["numpy",{"1":{"21":2}}],["numbers",{"1":{"46":2}}],["number",{"1":{"9":1,"18":1,"27":2}}],["nvidia",{"1":{"9":1,"12":4}}],["noise",{"1":{"34":1}}],["non",{"1":{"27":3,"32":1,"39":1}}],["none",{"1":{"15":1}}],["novel",{"1":{"25":1,"43":1}}],["november",{"1":{"25":1}}],["note",{"1":{"21":1,"26":1,"45":1,"46":1}}],["notes",{"1":{"8":1}}],["not",{"1":{"12":1,"19":2,"21":2,"27":2,"34":1,"36":1,"39":1,"41":1,"46":1}}],["no",{"1":{"12":1,"19":1,"27":1}}],["now",{"1":{"8":1}}],["normal",{"1":{"6":1}}],["north",{"1":{"6":2}}],["neglecting",{"1":{"23":1}}],["necessary",{"1":{"11":1,"21":1,"23":1}}],["next",{"1":{"11":1,"21":1}}],["need",{"1":{"19":2,"21":4,"23":1,"27":1,"47":1}}],["needed",{"1":{"8":1,"18":1,"21":1,"43":1}}],["needs",{"1":{"3":1,"8":1,"9":1}}],["new",{"1":{"8":2,"9":1,"23":1,"39":1}}],["natural",{"1":{"25":2,"27":1,"37":1,"38":1}}],["navigation",{"1":{"9":1,"27":2,"44":1}}],["navigate",{"1":{"8":1}}],["namepre",{"1":{"47":1}}],["namemodel",{"1":{"46":1}}],["name",{"1":{"8":2,"15":1,"18":1}}],["nachosa",{"1":{"48":1}}],["nachos",{"0":{"0":1,"7":1},"1":{"0":1,"7":6,"8":2},"2":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"8":1}}],["wrist",{"1":{"27":1,"31":1,"46":1}}],["whole",{"1":{"46":1,"47":1}}],["why",{"1":{"21":1}}],["which",{"1":{"18":1,"19":1,"21":1,"23":1,"30":1,"43":1}}],["while",{"1":{"12":1}}],["where",{"1":{"18":1,"23":3,"25":1}}],["when",{"1":{"12":2,"18":1,"19":3,"21":1}}],["whenever",{"1":{"8":1}}],["whether",{"1":{"7":1,"19":1}}],["works",{"1":{"45":2}}],["workspace",{"1":{"14":1}}],["work",{"1":{"23":1,"25":1,"43":1}}],["workaround",{"1":{"21":1}}],["working",{"1":{"9":1}}],["workflows",{"1":{"9":2}}],["workflow",{"1":{"4":1,"19":3}}],["worldwide",{"1":{"25":1}}],["world",{"0":{"34":1},"1":{"7":1,"25":1,"26":1,"27":12,"31":1,"32":1,"34":2,"35":1,"38":1,"39":1,"43":1,"44":3,"46":1}}],["way",{"1":{"21":1}}],["was",{"1":{"16":1,"23":3}}],["want",{"1":{"8":1,"15":1}}],["wang",{"1":{"6":3}}],["warehousing",{"1":{"3":1}}],["widowx",{"1":{"27":1,"37":1}}],["widely",{"1":{"23":1,"34":1}}],["wide",{"1":{"7":1,"42":1}}],["wild",{"1":{"27":1,"31":1,"46":2,"47":1}}],["will",{"1":{"4":1,"8":2,"12":4,"15":1}}],["window",{"1":{"12":1,"16":1}}],["windows",{"1":{"11":2,"16":1}}],["without",{"1":{"23":1,"25":1,"44":1}}],["within",{"1":{"4":1,"25":1,"47":2}}],["with",{"0":{"23":1},"1":{"3":1,"8":2,"11":4,"12":2,"15":1,"16":1,"19":1,"20":1,"22":1,"23":3,"25":1,"27":15,"29":4,"31":1,"32":1,"34":1,"35":1,"36":2,"37":2,"39":1,"40":2,"42":1,"46":10,"47":5}}],["week",{"1":{"47":2}}],["weeks",{"1":{"47":3}}],["well",{"1":{"27":1,"29":1,"34":1}}],["welcome",{"1":{"0":1,"48":1}}],["website",{"1":{"27":14,"46":9,"47":9}}],["were",{"1":{"23":1}}],["wenbo",{"1":{"6":1}}],["we",{"1":{"2":1,"4":1,"9":1,"11":2,"17":1,"19":3,"21":9}}],["h100",{"1":{"47":1}}],["history",{"1":{"46":1}}],["higher",{"1":{"25":1}}],["highly",{"1":{"23":1,"27":1,"47":1}}],["highlights",{"1":{"23":1,"26":1}}],["high",{"1":{"23":1,"25":1,"27":5,"37":1,"38":2,"40":2,"43":1,"46":2,"47":7}}],["hosted",{"1":{"29":1}}],["horizon",{"1":{"27":2,"44":2,"46":1}}],["hony",{"1":{"27":1,"39":1}}],["homes",{"1":{"27":2,"39":1}}],["home",{"0":{"48":1},"1":{"27":3,"39":2}}],["household",{"1":{"27":3,"36":2,"39":1}}],["hoursemphasizes",{"1":{"47":1}}],["hoursuses",{"1":{"47":1}}],["hours",{"1":{"27":4,"31":1,"39":1,"42":1,"46":1,"47":11}}],["hoc",{"1":{"25":1}}],["however",{"1":{"21":2}}],["how",{"1":{"7":1,"8":1,"10":1,"17":2}}],["htmldo",{"1":{"12":1}}],["https",{"1":{"8":1,"12":1,"17":1}}],["heterogeneity",{"1":{"30":1}}],["heterogeneous",{"1":{"27":2}}],["held",{"1":{"25":1}}],["heavy",{"1":{"35":1}}],["headless",{"1":{"18":2,"19":2,"21":1}}],["healthcare",{"1":{"0":1}}],["here",{"1":{"7":1}}],["hardware",{"0":{"47":1},"1":{"27":2,"31":1,"35":1,"37":1,"39":2,"45":2,"46":1,"47":6}}],["hallucinatory",{"1":{"25":1}}],["hallucinations",{"1":{"25":2}}],["hallucination",{"0":{"24":1,"25":1},"1":{"24":1,"25":2},"2":{"25":1}}],["has",{"1":{"11":1,"19":1}}],["have",{"1":{"11":1,"17":1}}],["handheld",{"1":{"46":1}}],["handling",{"1":{"29":1}}],["hand",{"1":{"8":2,"17":1,"23":5}}],["haoran",{"1":{"6":1}}],["haoyang",{"1":{"6":1}}],["hailu",{"1":{"6":1}}],["hundred",{"1":{"47":1}}],["hundreds",{"1":{"27":1,"32":1}}],["hugging",{"1":{"29":1}}],["huining",{"1":{"6":1}}],["hu",{"1":{"6":1}}],["humans",{"1":{"23":1}}],["human",{"1":{"3":2,"23":12,"25":1,"27":3,"32":3,"33":1}}],["lts",{"1":{"11":1}}],["ldd",{"1":{"11":1}}],["llm",{"1":{"46":1,"47":1}}],["llms",{"0":{"24":1},"1":{"25":4},"2":{"25":1}}],["llama",{"1":{"46":1}}],["ll",{"1":{"8":1}}],["lora",{"1":{"47":1}}],["loop",{"1":{"27":1,"32":1}}],["located",{"1":{"19":1}}],["locate",{"1":{"18":1}}],["locomotion",{"1":{"9":1}}],["logged",{"1":{"8":1}}],["long",{"1":{"6":1,"27":2,"44":2,"46":1}}],["lowering",{"1":{"32":1}}],["lower",{"1":{"29":1}}],["low",{"1":{"3":1,"23":1,"32":1,"39":1,"46":2,"47":3}}],["lightweight",{"1":{"46":1}}],["licensing",{"1":{"40":1}}],["license",{"0":{"5":1},"1":{"12":3}}],["limit",{"1":{"27":1,"44":1}}],["limits",{"1":{"27":1}}],["limited",{"1":{"19":1,"27":2,"31":1,"33":1,"34":1}}],["linguistics",{"1":{"25":2}}],["lines",{"1":{"19":1}}],["line",{"1":{"19":2}}],["linux",{"1":{"11":3}}],["list",{"1":{"9":2}}],["live",{"1":{"8":1}}],["like",{"1":{"7":1}}],["li",{"1":{"6":3}}],["lu",{"1":{"6":1}}],["lerobot",{"0":{"29":1},"1":{"26":1,"27":1,"29":1}}],["less",{"1":{"23":2,"27":4,"41":1}}],["least",{"1":{"47":1}}],["leaders",{"1":{"25":1}}],["leading",{"1":{"23":1,"25":1}}],["learn",{"1":{"7":1,"10":1,"42":1}}],["learning",{"0":{"23":1},"1":{"3":1,"7":1,"9":4,"15":1,"17":2,"19":2,"22":1,"23":4,"27":17,"29":2,"30":1,"31":1,"32":1,"33":2,"34":2,"36":1,"37":1,"39":2,"40":2,"41":2,"42":1,"46":4,"47":3}}],["legged",{"1":{"9":1}}],["leverages",{"1":{"17":1,"27":1,"32":1,"43":1,"46":1}}],["leverage",{"1":{"9":1,"47":1}}],["level",{"1":{"8":1,"47":1}}],["left",{"1":{"8":2}}],["led",{"0":{"3":1},"1":{"3":1}}],["last",{"1":{"26":1,"45":1}}],["language",{"0":{"25":1},"1":{"24":1,"25":4,"27":6,"36":3,"37":2,"38":1,"43":1,"44":1,"46":9,"47":1}}],["latency",{"1":{"23":2,"32":1}}],["latest",{"1":{"9":1,"11":1,"12":1}}],["larger",{"1":{"41":1,"47":1}}],["largest",{"1":{"33":1}}],["largely",{"1":{"27":1,"43":1}}],["large",{"0":{"25":1},"1":{"18":1,"24":1,"25":2,"27":10,"30":1,"31":1,"41":2,"42":1,"46":5,"47":4}}],["launch",{"1":{"12":1,"16":1}}],["launching",{"1":{"3":1}}],["lab",{"0":{"14":1,"16":1},"1":{"9":3,"10":1,"11":1,"14":1,"17":2,"19":4,"21":5}}],["labeled",{"1":{"8":1}}],["labor",{"1":{"3":1}}],["layered",{"1":{"2":1}}],["elevators",{"1":{"46":1}}],["elevate",{"1":{"7":1}}],["especially",{"1":{"27":1}}],["establish",{"0":{"3":1},"1":{"4":1}}],["episodes",{"1":{"27":1,"38":1}}],["embodiments",{"1":{"27":1,"30":2}}],["embodiment",{"0":{"30":1},"1":{"26":1,"27":2,"46":2}}],["emnlp",{"1":{"25":3}}],["emphasizes",{"1":{"44":1}}],["emphasis",{"1":{"35":1}}],["empirical",{"1":{"25":2}}],["empty",{"1":{"12":1}}],["even",{"1":{"47":1}}],["evaluating",{"1":{"27":1,"34":1,"41":1}}],["evaluates",{"1":{"25":1}}],["evaluated",{"1":{"23":1,"25":1}}],["evolving",{"1":{"3":1}}],["efold",{"1":{"23":7}}],["effort",{"1":{"23":1,"30":1}}],["effectively",{"1":{"44":1}}],["effectiveness",{"1":{"32":1}}],["effective",{"1":{"27":2,"39":1,"42":1}}],["effects",{"1":{"23":4}}],["effect",{"0":{"23":1},"1":{"22":1,"23":3}}],["efficiency",{"1":{"21":1,"43":1,"47":1}}],["efficiently",{"1":{"23":1}}],["efficient",{"1":{"4":1,"9":1,"23":2,"27":1,"46":3,"47":9}}],["editing",{"1":{"18":1}}],["editable",{"1":{"15":1}}],["edge",{"1":{"7":1,"23":1}}],["eula",{"1":{"12":3}}],["e",{"0":{"39":1},"1":{"8":1,"26":1,"27":2,"29":1,"32":1,"34":1,"37":1,"39":1,"46":4,"47":9}}],["exhibits",{"1":{"46":1}}],["execution",{"1":{"46":3}}],["execute",{"1":{"18":1}}],["exact",{"1":{"46":2}}],["examples",{"1":{"18":1,"19":1}}],["example",{"1":{"8":2,"15":1}}],["excellent",{"1":{"46":2}}],["existing",{"1":{"25":1}}],["exit",{"1":{"16":1}}],["extra",{"1":{"44":1}}],["extracted",{"1":{"25":1}}],["extraction",{"1":{"23":1,"25":1}}],["extremely",{"1":{"27":1,"40":1}}],["exterior",{"1":{"31":1}}],["external",{"1":{"8":1,"23":1,"25":1}}],["extension",{"1":{"19":1}}],["extensions",{"1":{"8":1,"12":3,"15":2}}],["extensively",{"1":{"41":1}}],["extensive",{"1":{"19":1,"27":1,"31":1,"38":1,"40":1,"47":1}}],["extend",{"1":{"8":1,"9":1}}],["explicitly",{"1":{"46":1}}],["explained",{"0":{"21":1}}],["explore",{"1":{"7":1,"8":4}}],["exploration",{"1":{"7":1,"23":1,"44":1}}],["expected",{"1":{"12":1}}],["experts",{"1":{"32":1}}],["expert",{"1":{"27":2,"39":1,"46":1}}],["expertise",{"1":{"7":1,"29":1,"38":1}}],["experience",{"1":{"12":3,"27":2,"35":1,"42":1}}],["experimental",{"1":{"11":1}}],["expand",{"1":{"8":1}}],["easy",{"1":{"46":1}}],["easily",{"1":{"9":1}}],["east",{"1":{"6":1}}],["each",{"1":{"4":1,"12":1,"21":3,"26":1}}],["encodes",{"1":{"46":1}}],["encoder",{"1":{"46":1}}],["encounter",{"1":{"11":1}}],["enormous",{"1":{"40":1}}],["engineering",{"1":{"25":1,"38":1}}],["ensuring",{"1":{"25":1}}],["ensure",{"1":{"2":1,"3":1,"8":2,"11":3}}],["enhance",{"1":{"23":1}}],["enhancing",{"1":{"4":1,"25":1}}],["end",{"0":{"23":1},"1":{"22":1,"23":7,"27":2,"29":2,"47":1}}],["enabling",{"0":{"19":1},"1":{"27":2,"32":1},"2":{"20":1,"21":1}}],["enables",{"1":{"23":1,"27":1,"32":1,"46":3}}],["enabled",{"1":{"11":1,"18":1,"19":1}}],["enable",{"1":{"8":2,"18":1,"19":2,"21":1,"31":1}}],["env",{"1":{"21":2}}],["envs",{"1":{"18":1,"21":1}}],["environment",{"1":{"11":2,"12":1,"18":1,"21":2}}],["environments10",{"1":{"47":1}}],["environments",{"1":{"9":5,"18":2,"23":1,"27":5,"29":2,"34":2,"37":2,"39":1}}],["entirely",{"1":{"44":2}}],["entities",{"1":{"25":1}}],["entity",{"1":{"4":1}}],["enterprise",{"1":{"8":1}}],["enterprises",{"0":{"4":1}}],["2b",{"1":{"47":1}}],["2bpre",{"1":{"46":1}}],["2m",{"1":{"46":1}}],["25",{"1":{"46":1}}],["250",{"1":{"37":1}}],["27mocto",{"1":{"46":1}}],["249",{"1":{"46":1}}],["24",{"1":{"27":1,"37":1}}],["22",{"1":{"27":2,"30":1,"39":1,"47":1}}],["28",{"1":{"26":1,"27":1,"36":1,"45":1}}],["21",{"1":{"30":1}}],["214",{"1":{"19":1}}],["213",{"1":{"19":1}}],["200m",{"1":{"46":1}}],["2025",{"1":{"26":1,"45":1}}],["2024",{"1":{"19":1,"25":2}}],["20",{"1":{"11":1}}],["26",{"1":{"9":1}}],["2",{"0":{"3":1,"30":1},"1":{"11":3,"27":1,"46":2,"47":1}}],["rdt",{"1":{"46":1,"47":1}}],["rgb",{"1":{"27":6,"37":1,"39":1,"40":1,"44":4,"46":1}}],["richness",{"1":{"41":1}}],["rich",{"1":{"27":3,"31":1,"32":1,"36":1,"40":3,"47":1}}],["rh20t",{"0":{"40":1},"1":{"26":1,"27":1,"40":1}}],["rtx",{"1":{"47":1}}],["rtx4090",{"1":{"47":2}}],["rt",{"0":{"38":1},"1":{"26":1,"27":1,"38":1,"46":1,"47":1}}],["rsj",{"1":{"23":1}}],["rsl",{"1":{"15":1,"18":2,"19":3}}],["rate",{"1":{"46":1}}],["rather",{"1":{"23":1,"25":1}}],["rare",{"1":{"42":1}}],["rapid",{"1":{"27":1,"29":1,"39":1,"42":1}}],["rad",{"1":{"23":1}}],["randomized",{"1":{"27":1}}],["randomization",{"1":{"9":1}}],["range",{"1":{"7":1,"47":1}}],["rlbench",{"1":{"46":1}}],["rl",{"1":{"15":3,"17":1,"18":3,"19":6,"20":1,"21":2,"27":2,"34":1,"42":1}}],["runners",{"1":{"19":1}}],["runner",{"1":{"19":1}}],["running",{"1":{"9":1,"11":1,"12":1,"18":2,"19":3}}],["runthe",{"1":{"15":1}}],["runs",{"1":{"12":2}}],["run",{"1":{"11":1,"12":5,"15":1,"16":1,"18":1,"19":1}}],["ruoxu",{"1":{"6":1}}],["rochester",{"1":{"6":1}}],["role",{"1":{"4":1}}],["roles",{"1":{"4":1}}],["roboset",{"0":{"36":1},"1":{"26":1,"27":1,"36":1}}],["robonet",{"0":{"35":1},"1":{"26":1,"27":1,"35":1}}],["robomimic",{"1":{"15":1}}],["roboturk",{"0":{"32":1},"1":{"26":1,"27":1,"32":1}}],["robot",{"0":{"3":1,"45":1,"46":1},"1":{"2":1,"3":2,"4":3,"9":2,"23":4,"27":15,"29":1,"30":3,"31":1,"33":1,"35":2,"43":1,"45":2,"46":10,"47":3},"2":{"46":1,"47":1}}],["robots",{"1":{"2":1,"3":2,"4":1,"9":1,"23":1,"27":5,"29":1,"30":1,"31":2,"38":1,"42":1,"46":1,"47":1}}],["robotic",{"0":{"2":1,"4":1},"1":{"0":1,"2":1,"3":1,"7":2,"17":1,"23":4,"27":5,"32":1,"35":1,"36":1,"37":1,"38":1,"41":1,"42":1,"46":1}}],["robotics",{"0":{"26":1},"1":{"0":2,"7":5,"9":2,"23":2,"26":2,"27":2,"29":2,"39":1,"48":1},"2":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1}}],["robustness",{"1":{"2":1,"9":1,"25":1,"27":1,"31":1}}],["robust",{"0":{"2":1},"1":{"27":2,"31":1,"44":1}}],["requiring",{"1":{"25":1}}],["requirements8",{"1":{"47":1}}],["requirements",{"0":{"47":1},"1":{"27":2,"45":2,"47":3}}],["require",{"1":{"27":2,"47":2}}],["required",{"1":{"11":2,"12":1}}],["requires",{"1":{"11":1,"27":1,"35":1,"42":1,"47":3}}],["refrains",{"1":{"25":1}}],["refinement",{"1":{"8":1}}],["refine",{"1":{"8":1}}],["reduce",{"1":{"47":1}}],["reduces",{"1":{"23":1}}],["reducing",{"1":{"23":1}}],["redefines",{"1":{"23":1}}],["recent",{"1":{"45":2}}],["recreate",{"1":{"23":2}}],["recognition",{"1":{"27":1}}],["recognized",{"1":{"23":1}}],["recommended",{"1":{"18":1}}],["recommend",{"1":{"11":2}}],["recommendations",{"1":{"7":1}}],["recorded",{"1":{"27":2}}],["record",{"1":{"4":1,"21":1}}],["recovery",{"1":{"2":1,"44":1}}],["retrieving",{"1":{"19":1}}],["retrieve",{"1":{"19":1,"21":1}}],["return",{"1":{"8":1}}],["regardless",{"1":{"19":1}}],["registration",{"1":{"18":1}}],["registry",{"1":{"12":1}}],["register",{"1":{"18":1}}],["registered",{"1":{"18":2}}],["repertoire",{"1":{"42":1}}],["report",{"1":{"26":1}}],["repository",{"1":{"8":1,"14":1,"16":1,"18":2}}],["replicate",{"1":{"23":1}}],["reply",{"1":{"12":1}}],["representation",{"1":{"46":1}}],["represent",{"1":{"23":1}}],["relatively",{"1":{"46":2,"47":2}}],["related",{"1":{"23":1,"25":1}}],["release",{"1":{"11":1}}],["reliability",{"1":{"3":1,"25":1}}],["reliable",{"1":{"2":1}}],["rendering",{"1":{"9":2}}],["remarks1",{"1":{"46":1,"47":1}}],["remarks",{"1":{"46":1}}],["remain",{"1":{"9":1}}],["remote",{"1":{"7":1,"23":1,"46":1}}],["resolution",{"1":{"27":1,"40":1}}],["resolve",{"1":{"19":1}}],["resources",{"1":{"25":1,"27":1}}],["resource",{"0":{"25":1},"1":{"24":1,"25":2,"41":1,"46":1,"47":4}}],["response",{"1":{"23":1}}],["responses",{"1":{"8":1,"25":1}}],["results",{"1":{"23":1}}],["reset",{"1":{"19":1}}],["researchers",{"1":{"23":1,"25":1}}],["research",{"1":{"9":2,"23":2,"25":1,"29":2,"40":1}}],["reasoning",{"1":{"46":2,"47":1}}],["ready",{"1":{"8":1,"9":1}}],["realistic",{"1":{"9":1,"27":1}}],["realize",{"0":{"4":1}}],["real",{"0":{"22":1,"23":1},"1":{"3":1,"7":1,"8":2,"22":1,"23":2,"25":1,"27":16,"29":1,"31":1,"32":2,"34":1,"35":1,"38":2,"39":1,"43":1,"44":4,"46":1},"2":{"23":1}}],["reusable",{"1":{"7":1}}],["reinforcement",{"1":{"7":1,"9":1,"17":2,"19":2,"23":2,"27":3,"29":1,"34":1,"42":1}}],["re",{"1":{"7":1,"8":1}}],["d",{"1":{"46":1}}],["dynamic",{"1":{"46":1}}],["dynamics",{"1":{"29":1,"34":1}}],["daycombines",{"1":{"47":1}}],["daylarge",{"1":{"47":1}}],["day",{"1":{"47":4}}],["dayadaptable",{"1":{"47":1}}],["daysoffers",{"1":{"47":1}}],["days",{"1":{"46":1,"47":3}}],["date",{"1":{"26":1,"45":1}}],["data4",{"1":{"47":1}}],["datadata",{"1":{"46":1}}],["dataprovides",{"1":{"46":1}}],["databased",{"1":{"46":1}}],["database",{"1":{"27":1,"35":1}}],["databases",{"1":{"8":1}}],["datasetextends",{"1":{"46":1}}],["datasets",{"1":{"26":2,"27":4,"29":1,"30":1,"32":1,"33":1,"41":2,"46":2}}],["dataset",{"0":{"26":1},"1":{"25":1,"26":1,"27":5,"29":1,"31":2,"32":2,"36":1,"38":1,"39":2,"40":1,"41":1},"2":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1}}],["data",{"1":{"8":4,"21":1,"27":18,"29":1,"30":2,"32":1,"33":1,"35":4,"37":2,"38":1,"39":1,"40":3,"42":1,"45":1,"46":11,"47":11}}],["duration",{"1":{"47":1}}],["during",{"1":{"18":2,"19":1,"23":3}}],["due",{"1":{"32":1,"47":1}}],["duplicating",{"1":{"21":1}}],["duplicated",{"1":{"21":1}}],["done",{"1":{"47":3}}],["dof",{"1":{"46":1,"47":1}}],["doors",{"1":{"46":1}}],["downstream",{"1":{"46":1}}],["domestic",{"1":{"27":2,"39":1}}],["domain",{"1":{"9":1,"27":3,"36":1,"39":1}}],["dobb",{"0":{"39":1},"1":{"26":1,"27":1,"39":1}}],["documented",{"1":{"34":1,"41":1}}],["documentation",{"1":{"12":1,"27":1}}],["docs",{"1":{"12":1}}],["doesn",{"1":{"21":1}}],["does",{"1":{"12":1,"19":1,"21":1}}],["droid",{"0":{"31":1},"1":{"26":1,"27":1,"31":1}}],["drl",{"1":{"23":2}}],["dr",{"1":{"6":11}}],["driven",{"1":{"29":1}}],["driver",{"1":{"11":1}}],["drive",{"1":{"0":1,"44":1}}],["dinov2",{"1":{"46":1}}],["ding",{"1":{"6":1}}],["diffusion",{"1":{"29":1,"46":3}}],["differences",{"1":{"32":1}}],["different",{"1":{"25":1,"30":2,"35":2,"46":1,"47":1}}],["differ",{"1":{"19":1}}],["diverse",{"1":{"27":7,"29":1,"30":1,"31":1,"38":1,"40":2,"43":1}}],["diversitylow",{"1":{"46":1}}],["diversity",{"1":{"27":3,"30":1,"33":1,"37":1,"41":1}}],["directly",{"1":{"21":1}}],["direct",{"1":{"19":2,"21":1}}],["directory",{"1":{"15":1,"19":1}}],["discrete",{"1":{"47":1}}],["discretized",{"1":{"38":1,"46":1}}],["disclosedapproximately",{"1":{"46":1}}],["disclosedpre",{"1":{"46":1}}],["disclosedrapid",{"1":{"46":1}}],["disclosed",{"1":{"46":2}}],["discuss",{"1":{"23":1}}],["distillation",{"0":{"47":1},"1":{"45":2,"47":3}}],["distinct",{"1":{"27":1,"34":1}}],["distributions",{"1":{"11":2}}],["distribution",{"1":{"4":1}}],["disadvantages1",{"1":{"27":1}}],["disadvantages",{"1":{"26":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1}}],["disables",{"1":{"18":1}}],["display",{"1":{"16":1}}],["diego",{"1":{"6":2}}],["diagnostic",{"1":{"2":1}}],["decoder",{"1":{"44":1}}],["deep",{"1":{"23":2}}],["devices",{"1":{"47":1}}],["device",{"1":{"19":1}}],["developing",{"1":{"3":1}}],["develop",{"0":{"2":1},"1":{"4":1}}],["debug",{"1":{"12":1}}],["depending",{"1":{"46":1,"47":2}}],["dependencies",{"1":{"15":1}}],["dependent",{"1":{"12":1}}],["depth",{"1":{"27":4,"37":1,"39":1,"40":1}}],["deployed",{"1":{"27":1,"44":1}}],["deployment",{"0":{"18":1},"1":{"43":1}}],["deploy",{"1":{"8":1}}],["default",{"1":{"11":1,"12":1,"15":1}}],["defined6",{"1":{"47":1}}],["define",{"1":{"4":1,"8":1}}],["demand",{"1":{"29":1,"47":1}}],["demands",{"1":{"3":1,"27":1,"38":1}}],["demos",{"1":{"27":2,"46":1,"47":2}}],["demo",{"1":{"27":1,"46":1}}],["demonstration",{"1":{"27":4,"39":2,"40":1,"46":4,"47":2}}],["demonstrationslarge",{"1":{"46":1}}],["demonstrationsnot",{"1":{"46":1}}],["demonstrations",{"1":{"9":1,"27":3,"32":4,"33":1,"36":1,"37":1,"39":1,"46":5}}],["demonstrates",{"1":{"38":1,"39":1,"42":1}}],["demonstrated",{"1":{"23":1,"27":2,"43":1}}],["demonstrate",{"1":{"17":2}}],["detecting",{"1":{"25":1}}],["detection10",{"1":{"46":1}}],["detection",{"1":{"2":1,"25":1,"44":1}}],["determine",{"1":{"25":1}}],["details",{"1":{"27":1,"41":1}}],["detailed",{"0":{"28":1},"1":{"26":1,"27":1,"33":1,"40":1},"2":{"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1}}],["detail",{"1":{"8":1}}],["descriptive",{"1":{"46":1}}],["descriptions",{"1":{"26":1}}],["description",{"1":{"8":1}}],["descriptionprovide",{"1":{"8":1}}],["despite",{"1":{"44":1}}],["designed",{"1":{"27":2,"29":1,"37":1,"39":1,"42":1,"46":1}}],["design",{"1":{"18":1,"46":1,"47":1}}],["designing",{"1":{"2":1}}],["dexterous",{"0":{"22":1,"23":1},"1":{"7":1,"9":1,"22":1,"23":2,"40":1},"2":{"23":1}}],["denver",{"1":{"6":1}}],["1m",{"1":{"46":1}}],["1m+",{"1":{"27":1,"30":1}}],["1b",{"1":{"46":1,"47":1}}],["15m",{"1":{"35":1}}],["15",{"0":{"43":1},"1":{"27":1,"46":1,"47":1}}],["14",{"0":{"42":1},"1":{"27":1}}],["130k",{"1":{"27":1,"38":1}}],["13",{"0":{"41":1},"1":{"27":4,"37":1,"38":1,"39":1}}],["16gb",{"1":{"47":1}}],["16",{"0":{"44":1},"1":{"25":1,"26":2,"27":1,"47":1}}],["11s",{"1":{"23":1}}],["114",{"1":{"19":1}}],["11",{"0":{"39":1},"1":{"19":1,"27":1}}],["10k+",{"1":{"46":1,"47":1}}],["10",{"0":{"38":1},"1":{"11":1,"12":1,"27":1,"46":1}}],["12b",{"1":{"47":1}}],["12bor",{"1":{"46":1}}],["12",{"0":{"40":1},"1":{"11":1,"25":1,"27":2,"42":1}}],["1",{"0":{"2":1,"29":1,"38":1},"1":{"26":1,"27":1,"38":1,"47":1}}],["billions",{"1":{"46":1}}],["bimanual",{"1":{"46":3,"47":1}}],["bind",{"1":{"21":1}}],["binaries",{"1":{"11":1}}],["body",{"1":{"46":1,"47":1}}],["boosting",{"1":{"42":1}}],["boost",{"1":{"37":1}}],["boosts",{"1":{"31":1}}],["both",{"1":{"27":1,"29":1,"32":1,"36":1,"37":1,"42":1,"47":1}}],["bc",{"0":{"41":1},"1":{"26":1,"27":2,"41":2}}],["bridgedata",{"0":{"37":1},"1":{"26":1,"27":1,"37":1}}],["brief",{"1":{"8":1}}],["broader",{"1":{"25":1}}],["black",{"1":{"16":1}}],["blockchain",{"1":{"4":1}}],["base",{"1":{"46":2}}],["based",{"0":{"23":1},"1":{"4":1,"11":1,"19":1,"21":1,"22":1,"23":2,"27":1,"30":1,"38":1,"43":1,"44":1,"46":6}}],["barrier",{"1":{"27":1,"29":1}}],["backend",{"1":{"21":1}}],["battery",{"1":{"9":1}}],["baicheng",{"1":{"6":1}}],["build",{"1":{"11":1}}],["building",{"1":{"7":1}}],["built",{"1":{"9":1,"29":1,"42":1}}],["buffalo",{"1":{"6":1}}],["button",{"1":{"8":1}}],["but",{"1":{"3":1,"11":1,"21":1,"27":1,"47":1}}],["business",{"0":{"3":1},"1":{"0":1,"3":1,"4":3}}],["by",{"1":{"2":1,"7":2,"8":1,"9":1,"11":1,"12":2,"15":1,"16":1,"18":3,"19":1,"21":1,"23":4,"25":1,"29":1,"44":1}}],["bellow",{"1":{"45":1}}],["belongs",{"1":{"21":1}}],["below",{"1":{"12":1,"26":1,"46":1}}],["being",{"1":{"31":1}}],["benchmarking",{"1":{"27":1}}],["benchmark",{"1":{"23":1,"27":4,"34":2,"41":1,"43":1}}],["before",{"1":{"11":1}}],["best",{"1":{"8":1,"19":1}}],["behaviors",{"1":{"33":1}}],["behavior",{"1":{"8":1,"27":2,"41":2,"46":2}}],["behaviorcustomize",{"1":{"8":1}}],["behaves",{"1":{"8":2}}],["beach",{"1":{"6":1}}],["be",{"1":{"2":1,"8":2,"12":1,"18":1,"19":1,"21":2,"27":2,"31":1,"35":1,"43":1,"47":4}}],["begin",{"1":{"2":1,"8":1}}],["beyond",{"1":{"0":1}}],["fps",{"1":{"27":1,"39":1}}],["flexible9",{"1":{"47":1}}],["flexibly",{"1":{"46":1}}],["florida",{"1":{"25":1}}],["fluid",{"0":{"19":1},"1":{"19":8,"20":1,"21":1},"2":{"20":1,"21":1}}],["flag",{"1":{"15":1}}],["failure",{"1":{"27":1,"44":1}}],["face",{"1":{"29":1}}],["faced",{"1":{"23":1}}],["facilitates",{"1":{"27":1,"29":1}}],["familiarity",{"1":{"25":9}}],["fabric",{"1":{"19":1}}],["faster",{"1":{"21":1}}],["fast",{"1":{"9":2,"46":1,"47":1}}],["fault",{"1":{"2":1}}],["frequency",{"1":{"27":1}}],["franka",{"1":{"27":1,"31":1}}],["frames",{"1":{"27":1,"35":1,"44":1}}],["frame",{"1":{"27":2,"29":1,"36":1}}],["frameworkscope",{"1":{"27":1}}],["frameworks",{"1":{"15":1,"26":2}}],["framework",{"1":{"9":4,"15":3,"23":4,"25":1,"27":2,"29":1,"42":1,"46":1}}],["from",{"1":{"3":1,"7":1,"9":1,"11":1,"12":1,"16":2,"19":2,"21":1,"23":1,"25":2,"27":6,"30":2,"32":1,"35":2,"38":1,"39":1,"42":1,"47":5}}],["figures",{"1":{"46":1}}],["file",{"1":{"12":3,"19":2}}],["first",{"1":{"11":1,"12":3,"21":1,"26":1}}],["fixed",{"1":{"9":1,"27":1}}],["fine",{"0":{"47":1},"1":{"8":1,"40":1,"42":1,"45":2,"46":2,"47":19}}],["findings",{"1":{"25":3}}],["find",{"1":{"8":1}}],["field",{"1":{"0":2,"23":1,"25":1,"48":1}}],["feedback",{"1":{"23":1}}],["few",{"1":{"18":1,"46":3,"47":11}}],["fetching",{"1":{"8":1,"27":1}}],["fenglong",{"1":{"6":1}}],["featuresplugins",{"1":{"8":1}}],["features",{"1":{"2":1,"7":1,"8":1,"9":1,"23":1,"26":1,"29":1,"30":1,"31":1,"32":2,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1,"46":2}}],["fuses",{"1":{"46":1}}],["fusion",{"1":{"40":1}}],["full",{"1":{"27":1,"39":1,"43":1,"47":5}}],["fully",{"0":{"4":1},"1":{"4":1,"27":1,"34":1}}],["functions",{"1":{"46":1}}],["function",{"1":{"19":1}}],["functionality",{"1":{"8":3}}],["future",{"1":{"0":1}}],["four",{"1":{"25":1}}],["found",{"1":{"19":2}}],["follows",{"1":{"19":2}}],["following",{"1":{"11":1,"12":1,"16":1,"18":1,"19":1,"23":1,"47":1}}],["follow",{"1":{"8":1}}],["focused",{"1":{"31":1,"33":1,"36":1,"47":1}}],["focuses",{"1":{"7":1,"39":1,"44":1,"46":1}}],["focusing",{"1":{"23":2}}],["focus",{"1":{"2":1,"23":1,"27":1}}],["forms",{"1":{"43":1}}],["format",{"1":{"40":1}}],["formulation",{"1":{"27":1,"43":1}}],["formulated",{"1":{"23":1}}],["force",{"1":{"23":1,"27":1,"40":1}}],["forums",{"1":{"12":1}}],["for",{"0":{"25":1,"47":1},"1":{"2":1,"4":2,"7":1,"8":5,"9":6,"11":5,"12":1,"15":1,"17":2,"19":3,"21":3,"23":4,"24":1,"25":6,"27":22,"29":2,"30":2,"31":1,"32":2,"33":2,"34":2,"35":1,"37":2,"38":1,"39":3,"40":1,"41":3,"42":1,"43":1,"45":2,"46":10,"47":11}}],["small",{"1":{"46":1,"47":2}}],["smallerutilizes",{"1":{"46":1}}],["smaller",{"1":{"27":1,"33":1,"47":1}}],["synchronization",{"1":{"40":1}}],["system",{"1":{"2":1,"8":3,"10":1,"11":2,"21":5,"27":1,"32":1,"38":1,"46":1}}],["systems",{"1":{"0":1,"2":1,"3":2,"7":2,"23":2}}],["skills",{"1":{"27":4,"32":1,"37":2,"40":1,"42":1,"46":1,"47":2}}],["skill",{"1":{"27":1,"46":3}}],["skrl",{"1":{"15":1}}],["span",{"1":{"47":1}}],["spans",{"1":{"37":1}}],["spanning",{"1":{"27":2,"42":1}}],["sparser",{"1":{"27":1}}],["spoc",{"0":{"44":1},"1":{"26":1,"27":1,"44":1}}],["specifies",{"1":{"18":1}}],["specifics",{"1":{"47":1}}],["specification",{"1":{"27":2,"43":1}}],["specifically",{"1":{"27":1,"46":1}}],["specific",{"1":{"12":1,"15":1,"27":4,"31":1,"36":1,"39":1,"46":1,"47":5}}],["specializing",{"1":{"7":2}}],["slow",{"1":{"21":1}}],["sizes",{"1":{"47":1}}],["single",{"1":{"47":8}}],["since",{"1":{"19":1,"21":1}}],["siglip",{"1":{"46":1}}],["significant",{"1":{"27":1,"29":1}}],["significantly",{"1":{"21":1,"23":1,"31":1,"42":1}}],["sites",{"1":{"27":1}}],["simultaneous",{"1":{"27":1}}],["simulated",{"1":{"27":2,"29":1,"32":1,"34":1,"43":1}}],["simulator",{"1":{"12":2,"16":1,"19":1}}],["simulation",{"0":{"19":1},"1":{"9":3,"19":5,"20":1,"21":1,"27":6,"29":1,"34":1,"44":2},"2":{"20":1,"21":1}}],["simulations",{"1":{"7":1}}],["sim",{"0":{"11":1,"12":1,"13":1},"1":{"9":1,"10":1,"11":7,"12":3,"19":1,"27":1,"38":1,"44":1},"2":{"12":1,"13":1,"14":2,"15":2,"16":2}}],["simplify",{"1":{"9":2}}],["simple",{"1":{"3":1}}],["similar",{"1":{"8":2}}],["sb3",{"1":{"15":1}}],["scenarios2",{"1":{"46":1}}],["scenarios",{"1":{"27":2,"31":1,"36":1,"44":1,"46":1,"47":2}}],["scene",{"1":{"21":1}}],["scenes",{"1":{"9":1,"31":1,"36":1}}],["scalable",{"1":{"27":3,"32":1,"42":1,"43":1}}],["scalability",{"1":{"2":1,"38":1}}],["scaletraining",{"1":{"46":1}}],["scale",{"1":{"27":11,"30":1,"33":1,"41":1,"42":1,"45":1,"46":4,"47":6}}],["scoring",{"1":{"46":1}}],["scores",{"1":{"25":1}}],["scope",{"1":{"26":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1}}],["scripted",{"1":{"37":1}}],["script",{"1":{"16":1}}],["schema",{"1":{"8":1}}],["snippets",{"1":{"7":1}}],["sophisticated",{"1":{"42":1}}],["so",{"1":{"19":1,"21":1}}],["some",{"1":{"8":1,"11":2,"19":2,"27":2,"33":1,"37":1,"41":1,"44":1,"46":1}}],["something",{"1":{"8":1,"12":1}}],["source",{"1":{"15":1,"19":1}}],["sourced",{"1":{"9":1,"17":1}}],["sources",{"1":{"8":1,"27":1}}],["southeast",{"1":{"6":1}}],["solution",{"1":{"19":1}}],["solutions",{"1":{"7":1}}],["solving",{"1":{"7":1}}],["s",{"1":{"7":2,"8":4,"19":1,"21":2,"23":1,"25":1,"26":1,"46":1}}],["shift",{"1":{"25":1}}],["short",{"1":{"47":1}}],["short2",{"1":{"47":1}}],["shortest",{"1":{"27":1,"44":1}}],["shortcomings",{"1":{"23":1}}],["shot",{"1":{"27":1,"40":1,"42":1,"43":1,"46":6,"47":1}}],["show",{"1":{"23":1}}],["showcasing",{"1":{"23":1,"25":1}}],["should",{"1":{"16":1,"18":1}}],["shared",{"1":{"27":1}}],["sharing",{"1":{"23":1,"27":1,"42":1}}],["shadow",{"1":{"23":1}}],["shaoyu",{"1":{"6":1}}],["shape",{"1":{"0":1}}],["shuting",{"1":{"6":1}}],["suitable",{"1":{"46":1,"47":2}}],["suited",{"1":{"27":1,"29":1}}],["summarizing",{"1":{"46":1}}],["summary",{"0":{"27":1},"1":{"26":1}}],["supplemented",{"1":{"46":1}}],["supporting",{"1":{"46":1}}],["supports",{"1":{"27":3,"29":1,"30":1,"36":1,"40":1,"46":2}}],["support",{"1":{"9":1,"19":2,"21":1,"27":2,"29":1,"37":1}}],["supported",{"1":{"8":1}}],["superior",{"1":{"38":1}}],["substantial",{"1":{"27":1}}],["surface",{"1":{"21":1}}],["sure",{"1":{"8":1,"12":1}}],["success",{"1":{"46":1}}],["successful",{"1":{"16":1,"32":1}}],["such",{"1":{"0":1,"3":1,"9":1,"23":2,"27":1,"45":1,"46":1,"47":1}}],["suny",{"1":{"6":1}}],["saycan",{"1":{"46":1,"47":1}}],["sampling",{"1":{"29":1}}],["sample",{"1":{"20":1,"27":1,"43":1}}],["same",{"1":{"12":1}}],["saving",{"1":{"8":1}}],["saves",{"1":{"23":1}}],["save",{"1":{"8":2}}],["san",{"1":{"6":2}}],["safety",{"1":{"2":1}}],["safe",{"1":{"0":1}}],["series",{"1":{"47":1}}],["serves",{"1":{"25":1,"41":1}}],["serving",{"1":{"23":1}}],["semantic",{"1":{"46":2,"47":1}}],["semantically",{"1":{"36":1}}],["sequential",{"1":{"44":1}}],["sequencing",{"1":{"27":1}}],["sessions",{"1":{"27":1}}],["seem",{"1":{"21":1}}],["separate",{"1":{"21":1,"23":1}}],["sensing",{"1":{"27":1,"40":1}}],["sensitive",{"1":{"8":1}}],["sensory",{"1":{"44":1}}],["sensor",{"1":{"27":1,"29":1,"34":1,"40":2,"46":1}}],["sensors",{"1":{"9":2,"40":1,"46":1,"47":1}}],["setups",{"1":{"47":1}}],["setup",{"1":{"27":3,"37":2,"44":1,"47":1}}],["sets",{"1":{"23":1}}],["settings",{"1":{"8":1,"19":1,"27":3,"34":1,"39":1,"43":1}}],["settingsadjust",{"1":{"8":1}}],["set",{"1":{"8":1,"21":2}}],["several",{"1":{"8":1,"27":1,"45":1,"47":6}}],["select",{"1":{"8":2}}],["self",{"1":{"2":2,"3":1,"25":5}}],["seconds",{"1":{"46":1}}],["second",{"1":{"26":1}}],["security",{"1":{"8":1}}],["secure",{"0":{"2":1},"1":{"2":2}}],["section",{"1":{"8":2,"9":1,"21":1}}],["store",{"1":{"40":1}}],["storage",{"1":{"27":2,"35":1}}],["study",{"1":{"35":1}}],["studying",{"1":{"30":1}}],["studies",{"1":{"33":1}}],["stick",{"1":{"27":1,"39":1}}],["styles",{"1":{"25":1}}],["stages",{"1":{"47":1}}],["stack",{"1":{"39":1}}],["standardizing",{"1":{"30":1}}],["standardized",{"1":{"27":2,"34":1,"41":1}}],["standardization",{"1":{"27":1}}],["started",{"0":{"17":1},"2":{"18":1}}],["start",{"1":{"7":1}}],["static",{"1":{"46":1,"47":1}}],["states",{"1":{"21":2,"27":1}}],["state",{"1":{"6":6,"27":1,"33":1,"38":1}}],["statuses",{"1":{"4":1}}],["stable",{"1":{"3":1}}],["strong",{"1":{"37":1,"39":1,"43":1,"46":1}}],["streaming",{"1":{"46":1}}],["streams",{"1":{"29":1}}],["streamline",{"1":{"0":1}}],["structured",{"1":{"27":1,"34":1}}],["strategies",{"1":{"25":1,"47":2}}],["strategic",{"0":{"1":1},"2":{"2":1,"3":1,"4":1}}],["strategy",{"1":{"23":2,"46":1,"47":1}}],["steps",{"1":{"8":1,"19":1}}],["step",{"0":{"1":1,"2":1,"3":1,"4":1},"1":{"11":1,"25":1,"46":2},"2":{"2":1,"3":1,"4":1}}],["periodfocuses",{"1":{"47":1}}],["perceiver",{"1":{"46":2,"47":1}}],["perception",{"1":{"27":1,"44":1}}],["persist",{"1":{"27":1,"44":1}}],["per",{"1":{"27":1,"36":1,"46":2}}],["performance",{"1":{"25":1,"27":2,"31":1,"38":1,"42":1,"46":2,"47":1}}],["perform",{"1":{"23":1,"27":1}}],["pennsylvania",{"1":{"6":1}}],["py",{"1":{"19":1}}],["pytorch",{"1":{"11":2,"29":1}}],["python",{"1":{"11":2,"19":2}}],["portable",{"1":{"46":1,"47":1}}],["policies",{"1":{"29":1,"30":1}}],["policy",{"1":{"19":1,"23":1,"27":1,"31":1,"37":1,"46":3,"47":1}}],["potential",{"1":{"27":2,"30":1}}],["pooling",{"1":{"27":1,"30":1}}],["points",{"1":{"21":2}}],["possibly",{"1":{"47":1}}],["possible",{"1":{"11":1,"19":1}}],["positioned",{"1":{"41":1}}],["positions",{"1":{"19":2,"21":2,"34":1}}],["positive",{"1":{"27":1}}],["post",{"1":{"25":1}}],["pose",{"1":{"11":1}}],["published",{"1":{"25":1}}],["pulled",{"1":{"12":2}}],["purpose",{"0":{"45":1},"1":{"8":1,"45":2},"2":{"46":1,"47":1}}],["phase",{"1":{"23":1}}],["physical",{"1":{"21":2,"23":2,"27":1}}],["physics",{"1":{"9":1}}],["physx",{"1":{"9":1,"21":2}}],["photo",{"1":{"9":1}}],["pali",{"1":{"46":1}}],["palm",{"1":{"46":2,"47":1}}],["paths",{"1":{"44":1}}],["path",{"1":{"27":1}}],["pairs",{"1":{"27":1,"40":1}}],["paid",{"1":{"8":1}}],["panda",{"1":{"27":1,"31":1}}],["papers",{"1":{"25":1}}],["paper",{"1":{"23":3,"25":3}}],["pass",{"1":{"15":1}}],["packages",{"1":{"11":1}}],["parallel",{"1":{"18":1}}],["parameter",{"1":{"18":1,"45":1,"46":2,"47":7}}],["parameters",{"1":{"8":1,"46":1,"47":2}}],["parts",{"1":{"19":1,"26":1}}],["particular",{"1":{"37":1}}],["particularly",{"1":{"18":1}}],["particleutils",{"1":{"21":2}}],["particle",{"1":{"21":12}}],["particleset",{"1":{"21":1}}],["particles",{"1":{"19":2,"21":4}}],["party",{"1":{"8":2}}],["please",{"1":{"12":1,"16":1}}],["plus",{"1":{"8":1,"27":1}}],["plugins",{"1":{"8":2}}],["platforms6",{"1":{"46":1}}],["platforms",{"1":{"27":2,"29":1,"35":1,"46":1}}],["platform",{"1":{"4":2,"7":2,"8":2,"23":1,"25":2,"27":1,"31":1,"32":1,"35":1}}],["plane",{"1":{"16":1}}],["planningbased",{"1":{"46":1}}],["planning",{"1":{"9":1,"27":1,"44":1,"46":2}}],["plan",{"0":{"1":1},"2":{"2":1,"3":1,"4":1}}],["pipelines",{"1":{"42":1}}],["pipeline",{"1":{"27":1}}],["pip",{"1":{"11":5,"15":1}}],["pilot",{"1":{"3":1,"27":1,"32":1}}],["pioneering",{"1":{"0":2,"48":1}}],["practitioners",{"1":{"23":1,"25":1}}],["practicesversion",{"1":{"8":1}}],["practical",{"1":{"0":1,"2":1,"7":1}}],["prediction",{"1":{"47":1}}],["predictionnot",{"1":{"46":1}}],["preprocessing",{"1":{"37":1}}],["pretrained",{"1":{"27":1,"29":2}}],["previous",{"1":{"25":1}}],["preventative",{"1":{"25":1}}],["prevent",{"1":{"25":1}}],["prevention",{"0":{"24":1,"25":1},"1":{"24":1,"25":1},"2":{"25":1}}],["prevents",{"1":{"19":1}}],["pre",{"1":{"25":1,"46":5,"47":11}}],["premier",{"1":{"25":1}}],["precision",{"1":{"23":2}}],["precise",{"1":{"23":1}}],["prestigious",{"1":{"23":1}}],["presenting",{"1":{"25":1}}],["presented",{"1":{"23":1}}],["presents",{"1":{"23":1,"43":1}}],["pressing",{"1":{"16":1,"18":1}}],["privileged",{"1":{"27":1}}],["private",{"1":{"8":1}}],["primarily",{"1":{"27":2}}],["prioritizing",{"1":{"2":1}}],["probabilities",{"1":{"46":1}}],["problem",{"1":{"23":1}}],["programmatically",{"1":{"46":1}}],["project",{"1":{"46":1,"47":1}}],["projects",{"1":{"3":1,"7":1,"46":2}}],["proven",{"1":{"32":1}}],["providing",{"1":{"29":1,"39":1,"41":1}}],["provided",{"1":{"9":1,"17":1,"46":1}}],["provides",{"1":{"7":1,"8":1,"9":1,"25":1,"27":1,"32":1,"36":1,"45":1}}],["prototyping",{"1":{"29":1}}],["procedurally",{"1":{"27":1,"43":1}}],["processing",{"1":{"25":2,"27":2,"35":1}}],["processes",{"1":{"4":1}}],["process",{"1":{"4":1,"12":1,"16":1,"23":2,"40":1}}],["proactive",{"1":{"25":1}}],["proactively",{"1":{"25":1}}],["produce",{"1":{"25":1,"38":1}}],["proposes",{"1":{"25":1}}],["proposed",{"1":{"19":1,"23":1,"25":1}}],["properties",{"1":{"21":1}}],["prompts",{"1":{"27":2,"43":1,"46":1}}],["prompt",{"1":{"8":2,"12":1,"16":1,"25":1}}],["prompted",{"1":{"8":1,"12":1,"43":1}}],["imitating",{"1":{"44":1}}],["imitation",{"1":{"27":11,"29":1,"31":1,"32":1,"33":2,"40":1,"41":2,"46":1,"47":1}}],["image",{"1":{"43":1,"46":1}}],["images",{"1":{"31":1,"46":1}}],["improvements",{"1":{"47":1}}],["improves",{"1":{"27":2,"46":1}}],["improving",{"1":{"9":1}}],["impacting",{"1":{"21":1}}],["important",{"1":{"21":1}}],["implementation",{"1":{"7":1,"19":1,"21":1,"23":1,"25":1}}],["implementing",{"1":{"2":1}}],["ideal",{"1":{"27":1,"30":1,"33":1,"40":1}}],["ideas",{"1":{"23":1}}],["identifies",{"1":{"25":1}}],["identify",{"1":{"8":1}}],["iros",{"1":{"23":2}}],["ieee",{"1":{"23":1}}],["i",{"1":{"12":1}}],["if",{"1":{"8":2,"11":1,"12":2,"15":1,"18":3,"25":1}}],["iterates",{"1":{"15":1}}],["iteratively",{"1":{"8":1}}],["iterative",{"1":{"8":1}}],["its",{"1":{"8":1,"23":1,"31":1}}],["it",{"1":{"8":3,"9":1,"11":1,"12":1,"18":2,"19":1,"21":2,"25":1,"29":1,"30":1,"33":1,"40":1,"44":1,"45":1}}],["issues",{"1":{"11":3,"27":1}}],["isaaclab",{"0":{"18":1},"1":{"17":1,"18":1,"19":2}}],["isaacsim",{"1":{"12":1}}],["isaac",{"0":{"11":1,"12":1,"13":1,"14":1,"16":1},"1":{"9":4,"10":2,"11":8,"12":3,"14":1,"17":2,"19":5,"21":5},"2":{"12":1,"13":1,"14":2,"15":2,"16":2}}],["is",{"1":{"0":1,"2":1,"7":2,"9":3,"11":7,"12":3,"17":1,"18":2,"19":5,"20":1,"21":7,"23":3,"25":1,"26":3,"27":1,"29":2,"30":3,"32":1,"34":1,"35":1,"38":2,"40":1,"41":3,"42":1,"44":1,"45":1,"46":1,"47":4}}],["inaccurate",{"1":{"25":1}}],["inputs",{"1":{"27":2,"31":1,"33":1,"38":1,"44":1,"47":1}}],["input",{"1":{"23":1,"44":1,"46":1}}],["innovative",{"1":{"23":1,"25":1}}],["innovations",{"1":{"45":1}}],["innovation",{"1":{"0":1}}],["info",{"1":{"27":1}}],["information",{"1":{"8":1,"25":1,"36":1,"40":1}}],["infrastructure",{"1":{"27":1,"42":1}}],["influential",{"1":{"23":1}}],["involved",{"1":{"23":1}}],["involves",{"1":{"3":1}}],["indicators",{"1":{"46":1}}],["individual",{"1":{"21":1}}],["industry",{"1":{"25":1}}],["industrial",{"1":{"7":1,"36":1}}],["industries",{"1":{"0":1,"3":1}}],["inconsistencies",{"1":{"30":1}}],["incorrectly",{"1":{"12":1}}],["increases",{"1":{"30":1}}],["includes",{"1":{"27":2,"32":1,"37":1,"39":2,"43":1}}],["include",{"1":{"9":3,"27":1}}],["included",{"1":{"9":1}}],["including",{"1":{"8":1,"23":1,"25":1,"26":1,"27":1,"31":1,"33":1,"38":1,"40":1,"46":1}}],["institutions",{"1":{"27":1,"30":1}}],["institute",{"1":{"6":1}}],["instruction",{"1":{"25":4}}],["instructions",{"1":{"8":3,"12":1,"25":1,"27":1,"36":1,"43":1,"44":1}}],["instead",{"1":{"19":1,"21":1,"46":1}}],["instances",{"1":{"25":1,"27":1,"43":1}}],["instance",{"1":{"11":1}}],["installs",{"1":{"15":1}}],["installed",{"1":{"11":2}}],["installing",{"0":{"11":1,"13":1},"1":{"11":2,"12":1},"2":{"12":1,"13":1,"14":2,"15":2,"16":2}}],["install",{"1":{"10":1,"11":3,"15":5,"18":2}}],["installation",{"0":{"10":1,"12":1,"15":1,"16":1,"18":1},"1":{"11":2,"16":1,"18":1},"2":{"11":1,"12":1,"13":1,"14":1,"15":1,"16":1}}],["inside",{"1":{"8":1}}],["inspire",{"1":{"7":1}}],["into",{"1":{"14":1,"21":3,"26":1}}],["introduce",{"1":{"30":1,"39":1}}],["introduces",{"1":{"25":1}}],["introduction",{"0":{"9":1}}],["introducing",{"1":{"3":1}}],["intensive3",{"1":{"47":1}}],["intensive",{"1":{"46":1}}],["intended",{"1":{"8":2,"34":1}}],["internet",{"1":{"46":4,"47":2}}],["internal",{"1":{"23":1}}],["international",{"1":{"23":2}}],["interleaved",{"1":{"43":1}}],["interventions",{"1":{"32":1}}],["interpretability",{"1":{"23":1,"25":1}}],["interpret",{"1":{"23":1}}],["interact",{"1":{"8":1}}],["interactions",{"1":{"23":2}}],["interaction",{"1":{"2":1}}],["interface",{"1":{"8":2,"18":4}}],["integrating",{"1":{"35":1,"46":1}}],["integration",{"1":{"8":1,"23":1,"27":1,"43":1}}],["integrates",{"1":{"46":1,"47":1}}],["integrated",{"1":{"27":1,"29":1}}],["integrate",{"1":{"4":1,"8":2}}],["integrity",{"1":{"2":1}}],["intelligent",{"0":{"2":1},"1":{"0":1,"2":1,"3":1,"7":2,"23":2}}],["intelligence",{"1":{"0":2,"48":1}}],["in",{"0":{"24":1},"1":{"3":2,"7":2,"8":6,"9":5,"12":2,"15":1,"18":3,"19":12,"21":4,"23":5,"25":9,"27":15,"29":3,"31":1,"32":3,"33":1,"37":2,"39":2,"40":1,"43":2,"44":5,"46":3,"47":4},"2":{"25":1}}],["initiatives",{"1":{"7":1}}],["initiative",{"1":{"0":2,"48":1}}],["mt",{"0":{"42":1},"1":{"26":1,"27":1,"42":1}}],["mse",{"1":{"23":1}}],["much",{"1":{"21":1,"41":1}}],["must",{"1":{"21":1,"23":1}}],["multilingual",{"1":{"46":1}}],["multimodal",{"1":{"27":1,"43":1,"46":1}}],["multiple",{"1":{"27":2,"35":1,"40":1,"46":1,"47":2}}],["multi",{"1":{"2":1,"27":16,"29":1,"31":1,"33":1,"34":1,"35":1,"36":1,"37":2,"40":1,"41":1,"42":2,"46":5,"47":3}}],["major",{"1":{"45":1}}],["massive",{"1":{"27":1,"38":1}}],["mar",{"1":{"26":1,"45":1}}],["marks",{"1":{"25":1}}],["markov",{"1":{"23":3}}],["mathematical",{"1":{"23":1}}],["materials",{"1":{"21":1,"23":1,"25":1}}],["map",{"1":{"23":1}}],["mainstream",{"1":{"26":2}}],["main",{"1":{"17":1}}],["machines",{"1":{"16":1}}],["may",{"1":{"8":1,"11":2,"18":1,"19":1,"27":7,"31":1,"32":1,"36":1,"39":1,"41":1,"43":1,"47":5}}],["makes",{"1":{"40":1}}],["make",{"1":{"8":2,"12":1,"19":1}}],["making",{"1":{"7":1,"33":1,"47":1}}],["ma",{"1":{"6":1}}],["many",{"1":{"27":2}}],["manipulation1",{"1":{"46":1}}],["manipulation",{"0":{"18":1},"1":{"9":1,"17":1,"23":4,"27":18,"31":1,"33":3,"34":1,"35":1,"36":1,"39":1,"40":2,"41":1,"42":1,"43":1,"44":1,"46":4,"47":1}}],["manager",{"1":{"19":1}}],["manage",{"1":{"4":1}}],["management",{"1":{"4":1}}],["manufacturing",{"1":{"3":1}}],["memory",{"1":{"47":3}}],["members",{"0":{"6":1}}],["methodparameter",{"1":{"46":1}}],["method",{"1":{"42":1,"46":1}}],["methods",{"1":{"23":1,"25":3,"47":2}}],["meta",{"0":{"34":1},"1":{"26":1,"27":3,"34":3}}],["mechanism",{"1":{"25":2}}],["mechanisms",{"1":{"2":1,"4":1}}],["means",{"1":{"12":1}}],["message",{"1":{"12":1}}],["meets",{"1":{"8":1}}],["menu",{"1":{"8":2}}],["mengmeng",{"1":{"6":1}}],["million",{"1":{"47":2}}],["millions",{"1":{"27":1,"40":1}}],["might",{"1":{"33":1}}],["mix",{"1":{"27":1}}],["mime",{"0":{"33":1},"1":{"26":1,"27":1,"33":1}}],["mimics",{"1":{"25":1}}],["mimicking",{"1":{"23":1}}],["miami",{"1":{"25":1}}],["minutes",{"1":{"12":1}}],["minimalist",{"1":{"44":1}}],["minimal",{"1":{"27":1,"39":1,"44":1}}],["minimum",{"1":{"21":1}}],["mini",{"1":{"12":1}}],["mingjie",{"1":{"6":1}}],["mitigation",{"1":{"25":1}}],["mitigating",{"1":{"25":1}}],["mit",{"1":{"5":1}}],["mission",{"1":{"0":1}}],["mobile",{"1":{"46":4,"47":2}}],["mounted",{"1":{"46":1}}],["mostly",{"1":{"27":1}}],["most",{"1":{"23":1}}],["movement",{"1":{"23":1}}],["motions",{"1":{"23":1}}],["motion",{"1":{"9":1,"19":1}}],["more",{"1":{"7":1,"9":1,"38":1,"41":1}}],["monitoring",{"1":{"3":1}}],["modalities",{"1":{"27":1,"40":1,"44":1}}],["modalitieskey",{"1":{"27":1}}],["modal",{"1":{"27":5,"33":1,"36":1,"40":1,"41":1}}],["modified",{"1":{"26":1,"45":1}}],["modifications",{"1":{"19":1}}],["modify",{"1":{"18":1,"19":1}}],["modules",{"1":{"18":1,"46":1}}],["modularity",{"1":{"9":1}}],["modular",{"1":{"2":1,"9":2,"29":1}}],["moderate",{"1":{"27":1}}],["modern",{"1":{"0":2,"48":1}}],["mode",{"1":{"18":1,"19":5,"21":1}}],["modeling",{"1":{"23":1}}],["model",{"1":{"7":2,"23":2,"25":1,"27":1,"38":1,"43":1,"45":1,"46":6,"47":4}}],["models",{"0":{"25":1,"45":1,"46":1},"1":{"3":1,"24":1,"25":2,"27":2,"29":1,"38":1,"39":1,"45":2,"46":1,"47":1},"2":{"46":1,"47":1}}],["octo",{"1":{"46":1,"47":1}}],["out",{"1":{"47":1}}],["outlines",{"1":{"45":1,"47":1}}],["outdoor",{"1":{"36":1}}],["outside",{"1":{"27":1}}],["outstanding",{"1":{"27":1}}],["outperforms",{"1":{"25":1}}],["outcomes",{"1":{"23":1}}],["our",{"0":{"1":1},"1":{"0":1,"2":1,"19":1},"2":{"2":1,"3":1,"4":1}}],["observations",{"1":{"27":1}}],["obtaining",{"1":{"32":1}}],["obtain",{"1":{"21":1}}],["object",{"1":{"27":2,"44":1}}],["objects",{"1":{"21":2,"23":1}}],["objectives",{"1":{"9":1}}],["omitting",{"1":{"18":1}}],["omniverse",{"1":{"12":4}}],["overview",{"1":{"26":2,"45":2}}],["overall",{"1":{"25":1}}],["overburdening",{"1":{"23":1}}],["overcome",{"1":{"23":1}}],["over",{"1":{"9":1,"15":1,"27":2,"35":1,"38":1,"42":1,"46":2,"47":1}}],["own",{"1":{"8":2,"18":1}}],["oklahoma",{"1":{"6":2}}],["others",{"1":{"8":1}}],["other",{"1":{"4":1,"8":1,"21":1,"27":1,"31":1,"39":1,"41":1}}],["opt",{"0":{"42":1},"1":{"26":1,"27":1,"42":1}}],["options",{"1":{"15":1,"47":1}}],["optional",{"1":{"8":2,"11":1}}],["option",{"1":{"8":1}}],["optionlook",{"1":{"8":1}}],["optimization",{"1":{"3":1}}],["opening",{"1":{"46":1}}],["openpi",{"1":{"46":1,"47":1}}],["openvla",{"1":{"46":1,"47":1}}],["open",{"0":{"30":1},"1":{"9":1,"17":1,"26":1,"27":2,"35":1,"46":2}}],["openness",{"1":{"9":1}}],["openly",{"1":{"8":1}}],["openai",{"1":{"7":2,"8":2}}],["operator",{"1":{"23":3}}],["operated",{"1":{"4":1}}],["operationnot",{"1":{"46":1}}],["operation",{"1":{"2":1}}],["operations",{"0":{"3":1},"1":{"0":1,"2":1,"3":2}}],["order",{"1":{"47":1}}],["organized",{"1":{"25":1,"26":1}}],["oriented",{"0":{"23":1},"1":{"22":1,"23":1}}],["or",{"0":{"47":1},"1":{"3":1,"7":1,"8":9,"12":2,"16":1,"18":1,"25":2,"27":1,"36":1,"41":1,"43":1,"44":1,"45":2,"46":1,"47":6}}],["online",{"1":{"23":1,"27":1,"41":1}}],["only",{"1":{"8":1,"15":2,"18":1,"19":1,"21":3,"23":1,"27":3,"44":3}}],["onto",{"1":{"23":1}}],["one",{"1":{"19":1,"21":3,"23":1,"25":1,"27":1,"40":1,"47":7}}],["once",{"1":{"8":1,"12":1}}],["on",{"1":{"2":1,"7":3,"8":2,"9":1,"10":1,"11":4,"12":1,"15":1,"16":2,"18":1,"19":1,"21":1,"23":5,"25":2,"27":4,"29":2,"31":1,"32":2,"33":1,"35":1,"36":1,"38":1,"39":1,"40":1,"42":2,"44":2,"45":2,"46":11,"47":17}}],["often",{"1":{"23":1,"27":1,"37":1,"43":1,"47":3}}],["offering",{"1":{"33":1}}],["offers",{"1":{"29":1,"31":1,"35":1}}],["offer",{"1":{"27":1,"33":1,"41":1}}],["offline",{"1":{"23":3}}],["off",{"1":{"18":1}}],["of",{"0":{"8":1,"18":1,"46":1},"1":{"0":3,"3":1,"6":5,"7":1,"8":4,"9":3,"11":2,"12":3,"15":1,"16":1,"18":1,"19":7,"20":1,"21":5,"23":10,"25":6,"26":4,"27":9,"30":1,"31":1,"32":3,"33":1,"35":2,"38":2,"39":1,"40":1,"41":1,"42":1,"43":3,"45":3,"46":4,"47":4,"48":1}}],["tpu",{"1":{"47":1}}],["tpus",{"1":{"47":1}}],["tdmpc",{"1":{"29":1}}],["typical",{"1":{"45":1,"47":1}}],["typically",{"1":{"21":1,"47":9}}],["types",{"1":{"27":1}}],["two",{"1":{"23":1,"26":1}}],["t",{"1":{"21":1}}],["tied",{"1":{"37":1}}],["tiled",{"1":{"9":1}}],["timemodel",{"1":{"47":1}}],["times",{"1":{"47":2}}],["time",{"0":{"22":1,"23":1,"47":1},"1":{"3":1,"8":2,"12":1,"22":1,"23":3,"39":1,"45":2,"47":12},"2":{"23":1}}],["tuning",{"0":{"47":1},"1":{"42":1,"45":2,"46":2,"47":19}}],["tune",{"1":{"8":1}}],["turn",{"1":{"18":1}}],["tutorial",{"0":{"8":1}}],["taking",{"1":{"47":1}}],["takes",{"1":{"47":1}}],["take",{"1":{"12":1,"47":2}}],["target",{"1":{"46":1}}],["targeted",{"1":{"41":1}}],["targets",{"1":{"33":1}}],["tabletop",{"1":{"27":1,"43":2}}],["table",{"0":{"27":1},"1":{"26":1,"46":1,"47":1}}],["tactile",{"1":{"23":1,"27":1,"40":1}}],["tangible",{"1":{"7":1}}],["tao",{"1":{"6":1}}],["task",{"1":{"4":2,"18":3,"23":1,"27":12,"34":2,"39":1,"42":2,"43":3,"44":1,"46":8,"47":2}}],["tasksnot",{"1":{"46":1}}],["tasks",{"1":{"2":1,"9":5,"18":1,"23":1,"27":12,"30":1,"31":1,"32":2,"33":1,"36":2,"37":1,"38":2,"39":1,"42":3,"43":1,"44":1,"46":4,"47":3}}],["tsinghua",{"1":{"6":1}}],["tens",{"1":{"46":1}}],["tensors",{"1":{"21":1}}],["text",{"1":{"43":1,"46":2}}],["temporal",{"1":{"27":1,"29":2}}],["template",{"1":{"17":4}}],["technical",{"1":{"26":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1,"45":2}}],["technology",{"1":{"6":1}}],["technologies",{"1":{"4":2}}],["terminate",{"1":{"16":1}}],["terminal",{"1":{"16":1}}],["terms",{"1":{"12":1,"23":1}}],["testing",{"1":{"18":1,"19":1,"23":3}}],["test",{"1":{"8":1,"34":1}}],["testonce",{"1":{"8":1}}],["teleop",{"1":{"27":1}}],["teleoperated",{"1":{"27":1,"36":1,"37":1}}],["teleoperation",{"1":{"27":2,"32":3,"33":1}}],["telesurgery",{"1":{"7":1,"23":1}}],["telemanipulation",{"0":{"22":1,"23":1},"1":{"7":1,"22":1,"23":5},"2":{"23":1}}],["team",{"0":{"6":1}}],["treating",{"1":{"23":1}}],["tree",{"1":{"17":1}}],["troubleshoot",{"1":{"12":1}}],["trustworthiness",{"1":{"4":1}}],["trajectory",{"1":{"46":1}}],["trajectories",{"1":{"27":8,"30":1,"31":1,"33":1,"36":1,"37":1,"39":1}}],["train",{"1":{"47":1}}],["trains",{"1":{"44":1}}],["trained",{"1":{"23":1,"27":2,"38":1,"44":1,"46":8,"47":1}}],["training5",{"1":{"47":1}}],["training",{"0":{"47":1},"1":{"17":2,"19":2,"20":1,"21":1,"23":5,"27":1,"30":1,"42":1,"45":3,"46":4,"47":28}}],["traditional",{"1":{"23":1,"46":1}}],["translate",{"1":{"39":1}}],["transfers",{"1":{"44":1}}],["transfer",{"1":{"27":3,"30":1,"38":1}}],["transformer",{"1":{"27":3,"30":1,"38":2,"43":1,"44":1,"46":4}}],["transform",{"1":{"7":1}}],["transparency",{"1":{"4":1}}],["transitioning",{"1":{"3":1}}],["tracking",{"1":{"23":1}}],["track",{"1":{"3":1}}],["through",{"1":{"27":1,"33":1,"38":1,"46":1}}],["three",{"0":{"1":1},"1":{"25":1},"2":{"2":1,"3":1,"4":1}}],["thousands",{"1":{"27":2,"32":1,"43":1}}],["those",{"1":{"19":1}}],["than",{"1":{"23":3,"25":1,"27":1,"38":1}}],["that",{"1":{"0":1,"2":2,"3":1,"9":3,"11":1,"12":3,"15":1,"16":1,"19":1,"21":1,"23":4,"25":1,"26":1,"27":3,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"41":1,"43":2,"46":2}}],["third",{"1":{"8":2}}],["this",{"1":{"8":2,"11":3,"12":2,"15":1,"17":1,"18":1,"19":3,"20":1,"21":3,"23":3,"25":3,"26":1,"45":1}}],["their",{"1":{"25":1,"46":1}}],["therefore",{"1":{"21":1}}],["there",{"1":{"21":1}}],["they",{"1":{"18":1}}],["them",{"1":{"15":1,"21":1,"25":1}}],["then",{"1":{"11":1}}],["these",{"1":{"8":1,"9":1,"18":1,"23":1}}],["the",{"0":{"12":1,"16":1,"20":1,"21":1},"1":{"0":3,"4":1,"8":18,"9":10,"11":9,"12":16,"14":1,"15":6,"16":8,"17":1,"18":12,"19":15,"21":20,"23":29,"25":15,"26":2,"27":6,"29":1,"30":2,"31":1,"32":3,"33":1,"37":1,"38":1,"41":1,"44":1,"45":2,"46":2,"47":3,"48":1}}],["tokens7bpre",{"1":{"46":1}}],["tokens",{"1":{"38":1,"43":1,"46":1}}],["torque",{"1":{"27":1,"40":1}}],["toward",{"1":{"25":1}}],["top",{"1":{"16":1,"23":1}}],["topics",{"1":{"7":1}}],["tone",{"1":{"8":1}}],["tool",{"1":{"8":1}}],["tools",{"1":{"8":3}}],["toolclick",{"1":{"8":1}}],["to",{"1":{"0":4,"2":2,"3":3,"4":3,"7":3,"8":18,"9":8,"10":1,"11":5,"12":5,"15":2,"16":1,"17":4,"18":5,"19":9,"21":12,"23":10,"25":3,"27":11,"29":2,"31":1,"32":2,"33":1,"34":2,"35":1,"36":2,"37":2,"38":2,"39":1,"40":1,"42":1,"44":2,"46":5,"47":13,"48":2}}],["city",{"1":{"39":1}}],["cpu",{"1":{"19":4}}],["ctrl+f",{"1":{"18":1}}],["ctrl+fn+b",{"1":{"16":1}}],["ctrl+break",{"1":{"16":1}}],["ctrl+c",{"1":{"16":1}}],["currently",{"1":{"19":1,"21":1}}],["cuda",{"1":{"11":4}}],["customize",{"1":{"9":1}}],["customized",{"1":{"8":2}}],["custom",{"0":{"8":1},"1":{"8":7}}],["cutting",{"1":{"7":1,"23":1}}],["clusters",{"1":{"47":2}}],["cluster",{"1":{"47":1}}],["cluttered",{"1":{"44":1}}],["classes",{"1":{"29":1}}],["classic",{"1":{"9":1}}],["closed",{"1":{"27":1}}],["clone",{"1":{"14":1,"18":1}}],["cloning",{"0":{"14":1},"1":{"27":2,"41":2,"46":2}}],["cloud",{"1":{"9":1}}],["click",{"1":{"7":1,"8":2}}],["clearly",{"1":{"47":1}}],["clear",{"1":{"4":1}}],["crowdsourcing",{"1":{"32":1}}],["crowdsourced",{"1":{"27":1}}],["cross",{"1":{"27":3,"30":1,"46":2}}],["critical",{"1":{"23":1}}],["crashes",{"1":{"12":1}}],["crafted",{"1":{"7":2}}],["creation",{"1":{"8":1,"19":1}}],["creating",{"0":{"8":1},"1":{"2":1,"8":1,"11":1,"21":1}}],["createandbindmdlmaterialfromlibrary",{"1":{"21":1}}],["createmdlmaterialprim",{"1":{"21":2}}],["created",{"1":{"8":1,"21":1}}],["create",{"1":{"0":1,"8":5,"21":4}}],["choose",{"1":{"18":1}}],["checkpoints",{"1":{"46":1}}],["check",{"1":{"11":1,"12":2}}],["chen",{"1":{"6":4}}],["chenhan",{"1":{"6":1}}],["challenging",{"1":{"27":1,"30":1,"32":1,"35":1,"40":1}}],["challenges",{"1":{"7":1,"23":1,"27":1}}],["characteristics",{"1":{"26":1}}],["changing",{"1":{"9":1}}],["chat",{"1":{"8":2}}],["chatgpt",{"1":{"8":5}}],["china",{"1":{"6":1}}],["cases",{"1":{"27":1,"44":1}}],["carried",{"1":{"47":1}}],["card",{"1":{"47":1}}],["careful",{"1":{"27":1}}],["carolina",{"1":{"6":2}}],["capacity",{"1":{"38":1}}],["capability",{"1":{"23":1,"46":2}}],["capabilities",{"1":{"8":1,"9":1,"42":1}}],["capable",{"1":{"3":1}}],["captured",{"1":{"34":1,"36":1}}],["capture",{"1":{"27":1,"33":1,"46":1,"47":1}}],["camera",{"1":{"27":3,"31":1,"35":1,"36":1,"46":1}}],["calibration",{"1":{"27":1,"40":1,"46":1}}],["california",{"1":{"6":3}}],["categories",{"1":{"23":1}}],["categorization",{"1":{"23":1}}],["cached",{"1":{"12":1}}],["can",{"1":{"2":1,"7":1,"8":1,"12":1,"15":2,"16":1,"18":3,"19":1,"23":1,"27":2,"29":1,"30":2,"35":1,"37":1,"39":1,"44":1,"47":6}}],["coherent",{"1":{"46":1}}],["counts",{"1":{"46":2}}],["coordination",{"1":{"27":1}}],["coordinate",{"1":{"4":1}}],["cost",{"1":{"27":1,"32":1,"39":2,"46":2,"47":1}}],["coverage",{"1":{"31":1}}],["covering",{"1":{"27":1,"38":1}}],["covers",{"1":{"7":1,"21":1}}],["correcting",{"1":{"25":1}}],["correctly",{"1":{"19":1}}],["core",{"1":{"9":1}}],["codebase",{"1":{"29":1}}],["code",{"0":{"20":1,"21":1},"1":{"7":2,"19":2,"20":1,"23":1,"25":1}}],["combined",{"1":{"46":1,"47":1}}],["combines",{"1":{"25":1}}],["combining",{"1":{"27":1,"46":2}}],["composes",{"1":{"46":1}}],["complicate",{"1":{"37":1}}],["complexities",{"1":{"34":1}}],["complexity",{"1":{"27":2,"29":1,"38":1,"40":1}}],["complex",{"1":{"23":1,"27":5,"33":1,"44":1,"46":1}}],["completion",{"1":{"44":1}}],["completing",{"1":{"18":1,"47":1}}],["completes",{"1":{"47":2}}],["completed",{"1":{"47":1}}],["complete",{"1":{"9":1,"19":1}}],["comprises",{"1":{"34":1}}],["comprehensive",{"1":{"7":1,"26":2,"27":1,"40":1,"41":1}}],["compute",{"1":{"29":1,"38":1}}],["computing",{"1":{"27":1}}],["computational",{"1":{"25":2,"27":2}}],["compares",{"1":{"45":1}}],["compared",{"1":{"27":2,"33":1}}],["comparing",{"1":{"45":1}}],["comparison",{"0":{"26":1,"28":1,"46":1},"2":{"27":1,"28":1,"29":2,"30":2,"31":2,"32":2,"33":2,"34":2,"35":2,"36":2,"37":2,"38":2,"39":2,"40":2,"41":2,"42":2,"43":2,"44":2}}],["comparative",{"1":{"26":2}}],["compatible",{"1":{"11":1}}],["compatibility",{"1":{"11":4}}],["commands",{"1":{"23":1}}],["command",{"1":{"11":1,"15":1,"16":3,"21":3,"23":1}}],["community",{"1":{"9":2,"27":1,"29":1}}],["common",{"1":{"9":2,"12":1}}],["committed",{"1":{"0":2,"48":1}}],["com",{"1":{"8":1,"12":1,"17":1}}],["collecting",{"1":{"32":1}}],["collection4",{"1":{"46":1}}],["collection",{"1":{"27":3,"32":1,"39":1,"46":1,"47":1}}],["collected",{"1":{"27":4,"31":1,"33":1,"35":1,"38":1,"42":1}}],["collaborative",{"1":{"27":1,"30":1}}],["collaboration",{"1":{"3":1,"4":2}}],["colorado",{"1":{"6":1}}],["concurrently",{"1":{"42":1}}],["concept",{"1":{"25":4}}],["concepts",{"1":{"25":4}}],["conditioned",{"1":{"37":1,"44":1}}],["conditioningocto",{"1":{"46":1}}],["conditioning",{"1":{"37":1}}],["conducting",{"1":{"19":1}}],["conferences",{"1":{"23":1,"25":1}}],["conference",{"1":{"23":2,"25":1}}],["configuration",{"1":{"8":1,"19":1}}],["configured",{"1":{"8":1,"12":1}}],["configure",{"1":{"8":2,"21":1}}],["convert",{"1":{"21":1}}],["converting",{"1":{"21":2}}],["conversations",{"1":{"8":1}}],["consists",{"1":{"46":1}}],["consistent",{"1":{"25":1}}],["consistency",{"1":{"3":1,"25":1,"27":2}}],["considered",{"1":{"23":1}}],["consequences",{"1":{"23":1}}],["consecutive",{"1":{"12":1}}],["connections",{"1":{"8":1}}],["connect",{"1":{"8":2}}],["contact",{"1":{"27":1,"40":2}}],["contains",{"1":{"21":1,"31":1,"35":1,"40":1}}],["context",{"1":{"27":1}}],["contributions",{"1":{"23":1,"25":2,"29":1}}],["contribute",{"1":{"9":1}}],["controlled",{"1":{"43":1}}],["control",{"1":{"2":1,"9":1,"23":1,"27":1,"38":1,"46":2,"47":1}}],["continuous",{"1":{"2":1,"27":1,"42":1}}],["cybernachos",{"1":{"17":1}}],["cybersecurity",{"1":{"0":2,"48":1}}],["cyber",{"0":{"0":1,"7":1},"1":{"0":1,"7":6,"8":2,"48":1},"2":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"8":1}}],["a100",{"1":{"46":1,"47":5}}],["amounts",{"1":{"35":1,"46":1}}],["audio",{"1":{"27":1,"40":1}}],["autoregressive",{"1":{"46":1}}],["automated",{"1":{"27":1}}],["automation",{"1":{"7":2,"23":1}}],["autonomously",{"1":{"23":1}}],["autonomous",{"0":{"4":1}}],["axis",{"1":{"21":1}}],["about",{"1":{"47":1}}],["above",{"1":{"12":1,"16":1}}],["ability5",{"1":{"46":1}}],["able",{"1":{"18":1}}],["after",{"1":{"18":1,"19":1}}],["agent",{"1":{"46":1}}],["agents",{"1":{"23":2}}],["aggregates",{"1":{"30":1}}],["aggregation",{"1":{"25":1}}],["agree",{"1":{"12":1}}],["agreement",{"1":{"12":3}}],["agility",{"1":{"9":1}}],["avoid",{"1":{"8":1}}],["available",{"1":{"8":3,"9":2,"11":1,"17":1,"21":1,"23":1,"25":1}}],["apt",{"1":{"15":1}}],["api",{"1":{"8":1,"21":1}}],["apis",{"1":{"8":2,"9":1}}],["approximate",{"1":{"47":1}}],["approximately",{"1":{"37":1}}],["approx",{"1":{"46":2}}],["approaches",{"1":{"23":1,"41":1}}],["approach",{"0":{"23":1},"1":{"11":3,"22":1,"23":2,"25":2,"43":1}}],["apps",{"1":{"19":1}}],["appear",{"1":{"8":1}}],["application",{"1":{"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":2,"40":1,"41":1,"42":1,"43":1,"44":1}}],["applicationscale",{"1":{"27":1}}],["applications",{"1":{"7":2,"25":1}}],["applicability",{"1":{"23":1,"31":1,"39":1}}],["applicable",{"1":{"12":1}}],["applied",{"1":{"2":1}}],["aloha",{"1":{"46":3,"47":2}}],["alongside",{"1":{"27":1,"41":1}}],["along",{"1":{"21":1}}],["although",{"1":{"41":1}}],["algorithm",{"1":{"18":1}}],["algorithms",{"0":{"2":1},"1":{"2":3,"18":1,"27":1,"34":1,"41":1}}],["all",{"1":{"12":1,"15":2,"25":1}}],["allowing",{"1":{"23":2}}],["allow",{"1":{"8":1,"9":1}}],["allows",{"1":{"8":1,"43":1}}],["also",{"1":{"8":1,"21":1,"27":1}}],["architecture",{"1":{"45":1,"46":2}}],["architectures",{"1":{"27":1,"30":1}}],["art",{"1":{"38":1}}],["artificial",{"1":{"0":2,"48":1}}],["array",{"1":{"21":1}}],["arrays",{"1":{"21":1}}],["argument",{"1":{"15":1}}],["arms",{"1":{"27":1}}],["arm",{"1":{"9":1,"17":1}}],["areas",{"1":{"39":1}}],["are",{"1":{"8":2,"9":3,"12":1,"15":1,"18":3,"19":1,"21":1,"23":3,"25":2,"27":1,"34":1,"36":1,"41":1,"43":1,"46":4,"47":2}}],["acl",{"1":{"25":1}}],["achieving",{"1":{"23":1}}],["achieves",{"1":{"25":1,"43":1,"44":1,"46":1}}],["achieve",{"1":{"4":1,"23":1}}],["across",{"1":{"23":1,"25":2,"27":5,"30":2,"31":1,"35":1,"40":1,"42":1}}],["actor",{"1":{"46":1,"47":1}}],["act",{"1":{"29":1}}],["actual",{"1":{"21":1,"47":1}}],["action",{"1":{"33":1,"38":1,"44":1,"46":5,"47":1}}],["actions",{"1":{"23":1,"27":1,"46":2}}],["actionable",{"1":{"7":1}}],["active",{"1":{"29":1}}],["actively",{"1":{"9":1}}],["activated",{"1":{"12":1}}],["accuracy",{"1":{"25":1,"44":1}}],["accurate",{"1":{"9":1,"23":1,"26":1,"45":1}}],["accidentally",{"1":{"18":1}}],["accept",{"1":{"12":3}}],["accessible",{"1":{"29":1}}],["accessdata",{"1":{"25":1}}],["access",{"1":{"8":3}}],["annotation",{"1":{"27":1}}],["annotations",{"1":{"27":1,"37":1}}],["analyze",{"1":{"40":1}}],["analyzing",{"1":{"25":1}}],["analysis",{"0":{"45":1},"1":{"26":3,"27":1,"45":1},"2":{"46":1,"47":1}}],["an",{"0":{"23":1},"1":{"7":2,"12":1,"15":1,"21":1,"22":1,"23":2,"25":2,"29":2,"35":2,"45":1}}],["and",{"0":{"2":1,"18":1,"47":1},"1":{"0":5,"2":8,"3":3,"4":6,"7":5,"8":9,"9":15,"10":1,"11":1,"12":3,"15":1,"16":1,"17":2,"18":2,"19":2,"21":7,"23":18,"25":10,"26":7,"27":34,"29":8,"30":1,"31":3,"32":3,"33":1,"34":3,"35":2,"36":2,"37":5,"38":3,"39":2,"40":7,"42":2,"43":2,"44":5,"45":4,"46":18,"47":12,"48":1}}],["attracting",{"1":{"25":1}}],["at",{"1":{"6":1,"17":1,"23":1,"27":3,"30":1,"39":1,"40":1,"41":1,"42":1,"47":1}}],["advantageskey",{"1":{"27":1}}],["advantages",{"1":{"26":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"43":1,"44":1}}],["advances",{"1":{"23":1}}],["advanced",{"1":{"4":1,"7":1,"8":2}}],["advancing",{"1":{"0":2,"40":1,"48":1}}],["adopts",{"1":{"23":1}}],["adapt",{"1":{"9":1}}],["adaptable",{"1":{"46":2}}],["adaptability9",{"1":{"46":1}}],["adaptability",{"1":{"2":1,"9":1}}],["adaptation",{"1":{"3":1,"27":1,"44":1}}],["addresses",{"1":{"23":1}}],["address",{"1":{"19":1}}],["additional",{"1":{"27":1,"43":1,"46":1,"47":1}}],["additionally",{"1":{"9":1,"19":1}}],["addition",{"1":{"12":1}}],["adding",{"1":{"9":1}}],["add",{"1":{"8":2,"9":1,"19":1,"21":2}}],["adjustable",{"1":{"47":1}}],["adjustments",{"1":{"8":1}}],["adjust",{"1":{"3":1,"8":1}}],["assesses",{"1":{"25":1}}],["assessment",{"1":{"25":1}}],["associated",{"1":{"25":1}}],["association",{"1":{"25":1}}],["assisted",{"1":{"23":1}}],["assistant",{"1":{"8":1}}],["assignments",{"1":{"4":1}}],["aspects",{"1":{"8":1,"45":2}}],["as",{"1":{"0":1,"3":1,"8":1,"9":1,"12":1,"15":1,"19":2,"21":2,"23":6,"25":1,"26":1,"27":1,"41":4,"45":2,"46":2,"47":1}}],["aimed",{"1":{"27":1,"30":1,"40":1}}],["aims",{"1":{"9":2,"23":1}}],["ai",{"1":{"0":2,"4":1,"7":2,"48":1}}],["a",{"1":{"0":2,"4":2,"7":1,"8":8,"9":4,"11":3,"12":1,"15":1,"16":2,"17":3,"18":2,"19":2,"20":1,"21":6,"23":10,"25":6,"26":3,"27":5,"30":1,"31":2,"32":1,"34":1,"36":1,"37":1,"38":2,"39":2,"40":1,"41":3,"42":3,"43":1,"44":2,"46":8,"47":26}}]],"serializationVersion":2}