{"_path":"/published-research/real-time-dexterous","_dir":"published-research","_draft":false,"_partial":false,"_locale":"","title":"Real-time Dexterous Telemanipulation","description":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach","icon":"lucide:bot","lastModified":"Nov 17, 2024","body":{"type":"root","children":[{"type":"element","tag":"h2","props":{"id":"real-time-dexterous-telemanipulation-with-an-end-effect-oriented-learning-based-approach"},"children":[{"type":"text","value":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach"}]},{"type":"element","tag":"img","props":{"alt":"CyberNachos","className":["h-full","w-full","object-cover","object-[50%_53%]"],"src":"/dexterous.png"},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This paper presents the "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"End-Effects-Oriented Learning-Based Dexterous Telemanipulation (EFOLD) Framework"}]},{"type":"text","value":",\nwhich aims to overcome the challenges faced in robotic telemanipulation by focusing on outcomes rather than mimicking human hand motions.\nTraditional approaches to telemanipulation usually map human hand gestures onto a robotic hand, often neglecting the complex physical interactions involved.\nEFOLD addresses these shortcomings by utilizing "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Deep Reinforcement Learning (DRL)"}]},{"type":"text","value":" and focusing on "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"end effects"}]},{"type":"text","value":"—key features that represent the physical consequences of manipulation, such as force, tactile feedback, and movement."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This paper was presented at the "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}]},{"type":"text","value":",\na prestigious international conference that gathers top researchers and practitioners from across the globe to discuss advances in robotics, automation, and intelligent systems.\n"},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"IROS"}]},{"type":"text","value":" is widely recognized as one of the most influential conferences in the field of robotics, showcasing cutting-edge research and serving as a platform for sharing groundbreaking ideas."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Key Highlights of the EFOLD Framework:"}]}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"End-Effect Modeling:"}]},{"type":"text","value":" EFOLD redefines the telemanipulation process by treating the task as a Markov Game, where the human operator and robot are considered separate agents.\nThe goal is to interpret the human operator's actions in terms of end effects that the robot must recreate."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Deep Reinforcement Learning:"}]},{"type":"text","value":" By using a learning-based approach, EFOLD enables the robotic hand to autonomously recreate the necessary interactions with objects,\nleading to precise and efficient manipulation without overburdening the human operator."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Human-Offline Training & Human-Online Testing:"}]},{"type":"text","value":" The framework adopts an innovative strategy where the DRL policy is trained offline,\nreducing the need for human input during training, and allowing humans to focus only on the testing phase."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The framework was evaluated using a virtual Shadow Robot Hand to perform dexterous manipulation tasks. Results show that EFOLD can achieve "},{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"real-time control"}]},{"type":"text","value":" with low latency and high precision. During testing,\nEFOLD demonstrated its capability to replicate end effects efficiently, achieving a command-following latency of less than 0.11s and highly accurate tracking with an MSE of less than 0.084 rad."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Research Contributions:"}]}]},{"type":"element","tag":"ol","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Markov Game Model:"}]},{"type":"text","value":" The telemanipulation problem was formulated as a Markov Game, allowing for the integration of human and robotic agents under a unified mathematical model."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"End Effect Categorization:"}]},{"type":"text","value":" Two categories of end effect extraction methods were proposed—internal and external—to enhance the interpretability and applicability of human commands."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"Efficient Training Approach:"}]},{"type":"text","value":" The human-offline training strategy significantly saves time and reduces human effort during the training process."}]}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"This work sets a new benchmark for robot-assisted manipulation in environments where precision and real-time response are critical, such as telesurgery and remote exploration."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"The paper and related materials, including implementation code, are available on "},{"type":"element","tag":"a","props":{"href":"https://github.com/Hao-yang-Wang/Real-time-Dexterous-Telemanipulation-with-an-End-Effect-Oriented-Learning-based-Approach","rel":["nofollow"]},"children":[{"type":"text","value":"GitHub"}]},{"type":"text","value":"."}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"real-time-dexterous-telemanipulation-with-an-end-effect-oriented-learning-based-approach","depth":2,"text":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach"}]}},"_type":"markdown","_id":"content:4.published-research:1. real-time-dexterous.md","_source":"content","_file":"4.published-research/1. real-time-dexterous.md","_stem":"4.published-research/1. real-time-dexterous","_extension":"md"}