{"documentCount":86,"nextId":86,"documentIds":{"0":"/cybernachos","1":"/cybernachos#our-three-step-strategic-plan","2":"/cybernachos#step-1-develop-robust-secure-and-intelligent-robotic-algorithms","3":"/cybernachos#step-2-establish-robot-led-business-operations","4":"/cybernachos#step-3-realize-fully-autonomous-robotic-enterprises","5":"/cybernachos#license","6":"/cybernachos#team-members","7":"/cybernachos#community-users","8":"/published/cybernachos-gpt","9":"/published/cybernachos-gpt#tutorial-of-creating-custom-gpts","10":"/tutorial-isaaclab/introduction","11":"/tutorial-isaaclab/installation","12":"/tutorial-isaaclab/installation#installing-isaac-sim","13":"/tutorial-isaaclab/installation#verifying-the-isaac-sim-installation","14":"/tutorial-isaaclab/installation#installing-isaac-sim-1","15":"/tutorial-isaaclab/installation#cloning-isaac-lab","16":"/tutorial-isaaclab/installation#installation","17":"/tutorial-isaaclab/installation#verifying-the-isaac-lab-installation","18":"/tutorial-isaaclab/getting-started","19":"/tutorial-isaaclab/getting-started#installation-and-deployment-of-isaaclabmanipulation","20":"/tutorial-isaaclab/enable-fluid","21":"/tutorial-isaaclab/enable-fluid#the-code","22":"/tutorial-isaaclab/enable-fluid#the-code-explained","23":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers","24":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#prerequisites","25":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#full-code","26":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#explanation-of-key-steps","27":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_1-device-setup","28":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_2-choosing-stable-base-models","29":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_3-loading-models-in-fp32-adjusting-dropout","30":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_4-loading-the-tokenizer","31":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_5-data-augmentation","32":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_6-improved-data-preprocessing","33":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_7-loading-splitting-the-openwebtext-dataset","34":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_8-dataloader-configuration","35":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_9-label-smoothing","36":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_10-improved-distillation-loss-function","37":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_11-training-loop","38":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_12-model-evaluation","39":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_13-running-the-training","40":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_14-saving-the-final-model","41":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#_15-16-comparison-and-saving-outputs","42":"/tutorial-llms/distilling-gpt-with-pytorch-and-transformers#conclusion","43":"/published-research/real-time-dexterous","44":"/published-research/real-time-dexterous#real-time-dexterous-telemanipulation-with-an-end-effect-oriented-learning-based-approach","45":"/published-research/hallucination","46":"/published-research/hallucination#zero-resource-hallucination-prevention-for-large-language-models","47":"/robotics-overview/robotics-datasets","48":"/robotics-overview/robotics-datasets#summary-table","49":"/robotics-overview/robotics-datasets#detailed-comparison","50":"/robotics-overview/robotics-datasets#_1-lerobot","51":"/robotics-overview/robotics-datasets#_2-open-x-embodiment","52":"/robotics-overview/robotics-datasets#_3-droid","53":"/robotics-overview/robotics-datasets#_4-roboturk","54":"/robotics-overview/robotics-datasets#_5-mime","55":"/robotics-overview/robotics-datasets#_6-meta-world","56":"/robotics-overview/robotics-datasets#_7-robonet","57":"/robotics-overview/robotics-datasets#_8-roboset","58":"/robotics-overview/robotics-datasets#_9-bridgedata-v2","59":"/robotics-overview/robotics-datasets#_10-rt-1","60":"/robotics-overview/robotics-datasets#_11-dobbe","61":"/robotics-overview/robotics-datasets#_12-rh20t","62":"/robotics-overview/robotics-datasets#_13-bc-z","63":"/robotics-overview/robotics-datasets#_14-mt-opt","64":"/robotics-overview/robotics-datasets#_15-vima","65":"/robotics-overview/robotics-datasets#_16-spoc","66":"/robotics-overview/robotics-models","67":"/robotics-overview/robotics-models#comparison-of-robot-models","68":"/robotics-overview/robotics-models#hardware-and-time-requirements-for-training-fine-tuning-or-distillation","69":"/robotics-overview/wheel-based-robots","70":"/robotics-overview/wheel-based-robots#overview-of-wheel-based-humanoid-robots","71":"/robotics-overview/wheel-based-robots#conclusion","72":"/posts/robotic-sociology","73":"/posts/robotic-sociology#introduction","74":"/posts/robotic-sociology#i-the-social-dimensions-of-human-robot-interaction","75":"/posts/robotic-sociology#from-functional-tools-to-social-actors","76":"/posts/robotic-sociology#the-evolution-of-trust-from-reliability-to-ethical-agency","77":"/posts/robotic-sociology#social-presence-and-theatrical-interaction","78":"/posts/robotic-sociology#ii-toward-machine-societies-the-emergence-of-collective-robotic-behavior","79":"/posts/robotic-sociology#multi-robot-systems-and-swarm-coordination","80":"/posts/robotic-sociology#from-coordination-to-social-norms","81":"/posts/robotic-sociology#human-machine-co-constitution-the-need-for-social-governance","82":"/posts/robotic-sociology#conclusion-are-robots-becoming-social-members","83":"/posts/robotic-sociology#suggested-readings-references","84":"/","85":"/promptrobot"},"fieldIds":{"title":0,"content":1,"titles":2},"fieldLength":{"0":[2,43,1],"1":[5,1,2],"2":[9,54,7],"3":[7,55,7],"4":[7,53,7],"5":[1,1,2],"6":[2,1,2],"7":[2,63,2],"8":[3,93,1],"9":[5,214,3],"10":[1,120,1],"11":[2,12,1],"12":[3,104,2],"13":[5,124,5],"14":[3,1,5],"15":[3,9,5],"16":[1,60,5],"17":[5,50,5],"18":[2,38,1],"19":[6,97,2],"20":[3,143,1],"21":[2,12,3],"22":[3,143,3],"23":[6,83,1],"24":[1,34,6],"25":[2,38,6],"26":[4,1,6],"27":[3,21,10],"28":[5,31,10],"29":[7,21,10],"30":[4,23,10],"31":[3,20,10],"32":[4,25,10],"33":[6,20,10],"34":[3,22,10],"35":[3,22,10],"36":[5,32,10],"37":[3,26,10],"38":[3,23,10],"39":[4,17,10],"40":[5,10,10],"41":[6,19,10],"42":[1,73,6],"43":[4,12,1],"44":[12,263,4],"45":[4,8,1],"46":[8,211,4],"47":[3,76,1],"48":[2,432,3],"49":[2,1,3],"50":[2,88,4],"51":[4,66,4],"52":[2,76,4],"53":[2,72,4],"54":[2,57,4],"55":[3,59,4],"56":[2,57,4],"57":[2,58,4],"58":[3,64,4],"59":[3,71,4],"60":[3,85,4],"61":[2,77,4],"62":[3,60,4],"63":[3,71,4],"64":[2,80,4],"65":[2,83,4],"66":[5,55,1],"67":[4,331,5],"68":[10,261,5],"69":[4,53,1],"70":[6,354,4],"71":[1,58,4],"72":[12,18,1],"73":[1,70,12],"74":[8,1,12],"75":[6,68,15],"76":[9,100,15],"77":[5,83,15],"78":[10,27,12],"79":[6,40,18],"80":[5,80,18],"81":[9,85,18],"82":[7,68,12],"83":[3,60,12],"84":[1,19,1],"85":[1,1,1]},"averageFieldLength":[4.046511627906977,69.8953488372093,5.94186046511628],"storedFields":{"0":{"title":"Cyber Nachos","content":"A pioneering initiative committed to advancing the field of modern robotics, Artificial Intelligence (AI), and Cybersecurity. Welcome to Cyber Nachos , a pioneering initiative committed to advancing the field of modern robotics, Artificial Intelligence (AI), and Cybersecurity.\nOur mission is to create practical, intelligent, and safe robotic systems that drive innovation, streamline business operations, and shape the future of industries such as healthcare and beyond.","titles":[]},"1":{"title":"Our Three-Step Strategic Plan","content":"","titles":["Cyber Nachos"]},"2":{"title":"Step 1: Develop Robust, Secure and Intelligent Robotic Algorithms","content":"We begin by creating practical, secure, and intelligent control and interaction algorithms for robots. Our focus is on: Safety and Robustness: Prioritizing algorithms that ensure secure and reliable robot operations.Scalability and Adaptability: Designing modular algorithms that can be applied to various robotic systems and tasks.Self-Diagnostic Mechanisms: Implementing multi-layered self-detection and fault-recovery features to guarantee continuous operation and system integrity.","titles":["Cyber Nachos","Our Three-Step Strategic Plan"]},"3":{"title":"Step 2: Establish Robot-Led Business Operations","content":"Transitioning from human-robot collaboration to robot-led models involves: Pilot Projects: Launching in industries with low human labor demands but stable operations, such as warehousing or simple manufacturing.Intelligent Monitoring Systems: Developing systems that track and adjust robotic operations in real-time to ensure reliability and consistency.Learning Robots: Introducing robots capable of self-optimization and adaptation to evolving business needs.","titles":["Cyber Nachos","Our Three-Step Strategic Plan"]},"4":{"title":"Step 3: Realize Fully Autonomous Robotic Enterprises","content":"To achieve a fully robot-operated business entity, we will: Define Roles and Collaboration: Establish clear role assignments and task collaboration mechanisms for each robot within the business process.AI-Based Management Platform: Develop a platform to coordinate robots and manage task distribution for efficient workflow.Integrate Advanced Technologies: Utilize blockchain and other technologies to record robot statuses and business processes, enhancing transparency and trustworthiness.","titles":["Cyber Nachos","Our Three-Step Strategic Plan"]},"5":{"title":"License","content":"MIT","titles":["Cyber Nachos"]},"6":{"title":"Team Members","content":"","titles":["Cyber Nachos"]},"7":{"title":"Community Users","content":"Dr. Yidan Hu, Rochester Institute of Technology Dr. Jiu Lu, University of Georgia Dr. Mingjie Li, Zhejiang University Dr. Zheshuo Li, University of Colorado Denver Dr. Fenglong Ma, Pennsylvania State University Dr. Chenhan Xu, North Carolina State University Dr. Huining Li, North Carolina State University Dr. Hailu Xu, California State University, Long Beach Dr. Wenbo Ding, Tsinghua University Dr. Xi Wang, Southeast University Dr. Yang Gao, East China Normal University Haoyang Wang, Oklahoma State University Haoran Guo, Oklahoma State University Xingyu Chen, University of California, San Diego Baicheng Chen, University of California, San Diego Xiaoyu Zhang, University at Buffalo, SUNY Jiayuan Chen Mengmeng Jiang Shuting Zhang Jinpu Tao Ruoxu Wang Shaoyu Chen","titles":["Cyber Nachos"]},"8":{"title":"Cyber Nachos GPT","content":"An AI model specializing in intelligent robotics, crafted by Cyber Nachos on OpenAI's platform. Cyber Nachos GPT is an AI model specializing in intelligent robotics, crafted by Cyber Nachos on OpenAI's platform.\nWhether you're building groundbreaking robotic systems or solving advanced automation challenges, Cyber Nachos GPT is here to inspire, guide, and elevate your projects. Key Features: Comprehensive Robotics Expertise: Covers a wide range of topics, from dexterous telemanipulation and reinforcement learning to simulations for robotic systems.Code and Practical Solutions: Provides reusable code snippets, actionable implementation guides, and cutting-edge recommendations.Real-World Applications: Focuses on applications like telesurgery, industrial automation, and remote exploration, making your robotics vision tangible. Explore More Learn how Cyber Nachos GPT can transform your robotics initiatives. Click Cyber Nachos GPT to start your journey!","titles":[]},"9":{"title":"Tutorial of Creating Custom GPTs","content":"Follow these steps to create a customized GPT in the ChatGPT interface: Access the ChatGPT Platform Make sure you are logged in to the OpenAI ChatGPT platform (https://chat.openai.com). Navigate to the Custom GPT Creation ToolClick on “Explore GPTs” or a Similar OptionLook for the “Explore GPTs” option in the left-hand menu.This section allows you to explore custom GPTs created by others and also provides the tools to create your own.Select “Create a New GPT”Inside the “Explore GPTs” section, find and click the button labeled “Create a New GPT” or something similar. Configure Your Custom GPT Once you begin creating your GPT, you'll be prompted to configure several aspects: Set a Name and DescriptionProvide a unique name for your GPT to identify it.Add a brief description of its intended purpose or functionality.Define System BehaviorCustomize the GPT's instructions using a System Prompt.Example:This prompt will guide how the GPT behaves in conversations.Enable Plugins or Extensions (Optional)If supported, you can enable plugins or connect APIs to extend your GPT's functionality.For example, integrate real-time data fetching or third-party tools.Fine-Tune SettingsAdjust other available parameters to refine your GPT's responses, tone, and level of detail. Save and TestOnce you've configured the settings, click Save.Interact with your custom GPT to ensure it behaves as intended.If needed, return to the configuration tool to make adjustments. Use Your Custom GPTAfter saving, your custom GPT will appear in the left-hand menu of the ChatGPT interface.Select it whenever you want to chat using your customized assistant. Optional Advanced FeaturesPlugins Integration: Add third-party tools to expand functionality.API Connections: Integrate with external APIs for advanced capabilities.Live Data Access: Allow the GPT to connect to real-time data sources or databases. Notes and Best PracticesVersion Access: Some features may only be available for paid users (e.g., ChatGPT Plus or Enterprise).Data Security: Avoid including sensitive or private information in system instructions.Iterative Refinement: Test and adjust the behavior iteratively to ensure your GPT meets your needs. Now you're ready to create and deploy your own custom GPT! The Instructions and Schema of Cyber Nachos GPT are openly available on Cyber Nachos GPT's GitHub repository.","titles":["Cyber Nachos GPT"]},"10":{"title":"Introduction","content":"A unified and modular framework for robot learning that aims to simplify common workflows in robotics research. Isaac Lab is a unified and modular framework for robot learning that aims to simplify common workflows in robotics research (such as reinforcement learning, learning from demonstrations, and motion planning).\nIt is built upon NVIDIA Isaac Sim to leverage the latest simulation capabilities for photo-realistic scenes, and fast and efficient simulation. The core objectives of the framework are: Modularity: Easily customize and add new environments, robots, and sensors.Agility: Adapt to the changing needs of the community.Openness: Remain open-sourced to allow the community to contribute and extend the framework.Battery-included: Include a number of environments, sensors, and tasks that are ready to use. Key features available in Isaac Lab include fast and accurate physics simulation provided by PhysX, tiled rendering APIs for vectorized rendering, domain randomization for improving robustness and adaptability, and support for running in the cloud. Additionally, Isaac Lab provides over 26 environments, and we are actively working on adding more environments to the list.\nThese include classic control tasks, fixed-arm and dexterous manipulation tasks, legged locomotion tasks, and navigation tasks. A complete list is available in the environments section.","titles":[]},"11":{"title":"Installation Guide","content":"Learn how to install Isaac Lab and Isaac Sim on your system.","titles":[]},"12":{"title":"Installing Isaac Sim","content":"From Isaac Sim 4.0 release, it is possible to install Isaac Sim using pip. This approach is experimental and may have compatibility issues with some Linux distributions. Installing Isaac Sim with pip requires GLIBC 2.34+ version compatibility. To check the GLIBC version on your system, use command ldd --version.This may pose compatibility issues with some Linux distributions.\nFor instance, Ubuntu 20.04 LTS has GLIBC 2.31 by default. If you encounter compatibility issues, we recommend following the Isaac Sim Binaries Installation approach. On Windows with CUDA 12, the GPU driver version 552.86 is required. To use the pip installation approach for Isaac Sim, we recommend first creating a virtual environment. Ensure that the Python version of the virtual environment is Python 3.10. Next, install a CUDA-enabled PyTorch 2.4.0 build based on the CUDA version available on your system. This step is optional for Linux, but required for Windows to ensure a CUDA-compatible version of PyTorch is installed. Before installing Isaac Sim, ensure the latest pip version is installed. To update pip, run Then, install the Isaac Sim packages necessary for running Isaac Lab:","titles":["Installation Guide"]},"13":{"title":"Verifying the Isaac Sim installation","content":"Make sure that your virtual environment is activated (if applicable)Check that the simulator runs as expected: By default, this will launch an empty mini Kit window. To run with a specific experience file, run: When running Isaac Sim for the first time, all dependent extensions will be pulled from the registry.\nThis process can take upwards of 10 minutes and is required on the first run of each experience file.\nOnce the extensions are pulled, consecutive runs using the same experience file will use the cached extensions.In addition, the first run will prompt users to accept the Nvidia Omniverse License Agreement.\nTo accept the EULA, reply Yes when prompted with the below message:By installing or using Isaac Sim, I agree to the terms of NVIDIA OMNIVERSE LICENSE AGREEMENT (EULA)\nin https://docs.omniverse.nvidia.com/isaacsim/latest/common/NVIDIA_Omniverse_License_Agreement.htmlDo you accept the EULA? (Yes/No): Yes If the simulator does not run or crashes while following the above instructions, it means that something is incorrectly configured.\nTo debug and troubleshoot, please check Isaac Sim documentation and the forums.","titles":["Installation Guide","Installing Isaac Sim"]},"14":{"title":"Installing Isaac Sim","content":"","titles":["Installation Guide","Installing Isaac Sim"]},"15":{"title":"Cloning Isaac Lab","content":"Clone the Isaac Lab repository into your workspace:","titles":["Installation Guide","Installing Isaac Sim","Installing Isaac Sim"]},"16":{"title":"Installation","content":"Install dependencies using apt (on Ubuntu):Run the install command that iterates over all the extensions in source/extensions directory and installs them using pip (with --editable flag): By default, this will install all the learning frameworks.\nIf you want to install only a specific framework, you can pass the name of the framework as an argument.\nFor example, to install only the rl_games framework, you can runThe valid options are rl_games, rsl_rl, sb3, skrl, robomimic, none.","titles":["Installation Guide","Installing Isaac Sim","Installing Isaac Sim"]},"17":{"title":"Verifying the Isaac Lab installation","content":"To verify that the installation was successful, run the following command from the top of the repository: The above command should launch the simulator and display a window with a black ground plane. You can exit the script by pressing Ctrl+C on your terminal.\nOn Windows machines, please terminate the process from Command Prompt using Ctrl+Break or Ctrl+fn+B.","titles":["Installation Guide","Installing Isaac Sim","Installing Isaac Sim"]},"18":{"title":"Getting Started","content":"A template to demonstrate how to use Isaac Lab for reinforcement learning training. We have provided a template to demonstrate how to use Isaac Lab.\nThis template leverages a robotic arm and hand for reinforcement learning (RL) training.\nThe template is open-sourced and available at: https://github.com/CyberNachos/isaacLab.manipulation/tree/main.","titles":[]},"19":{"title":"Installation and Deployment of IsaacLab.manipulation","content":"Clone repository and install:Install RSL_RL in the isaacLab repository: You can design your own RL Algorithm by editing \"modules\" and \"algorithms\" in RSL-RL After completing the installation, you should be able to run the following examples: The --task parameter specifies which task to execute. These tasks are registered in the environment using gym.register. You can use Ctrl+F to locate where they are registered or modify the task name during registration if needed.The --headless mode disables the graphical interface. This is particularly useful when running a large number of parallel environments (envs). If you accidentally enable it, you can turn off the graphical interface by pressing the V key. If you are running only a few environments, you may choose to keep the graphical interface enabled. It is generally recommended to keep the graphical interface on (by omitting --headless) during testing.","titles":["Getting Started"]},"20":{"title":"Enabling fluid simulation","content":"A guide to enable fluid simulation in Isaac Lab for reinforcement learning training. Since Isaac Lab's support for fluid simulation in reinforcement learning (RL) is currently limited, we need to make some modifications to enable fluid simulation during RL training.\nTo the best of our knowledge (by 11/2024), no one has yet proposed a complete solution for conducting fluid simulation in Isaac Lab. The implementation steps are as follows: Run simulation with cpu mode using --device cpu.\nAfter extensive testing, we found that fluid motion is visible in the GUI only when Isaac Sim is running in CPU mode, regardless of whether the fabric extension is enabled.\nAdditionally, it is possible to retrieve the positions and velocities of fluid particles using Python code in this configuration.When running RL in CPU mode, some parts of the rsl_rl code may not function correctly.\nTo address this, you need to add the following line to line 114 of the on_policy_runner.py file located in rsl_rl\\rsl_rl\\runners:When running Isaac Lab in headless mode, the simulator settings differ from those in GUI mode, which prevents us from retrieving the positions of fluid particles.\nTo resolve this, modify lines 213-214 in the file IsaacLab\\source\\apps\\isaaclab.python.headless.kit as follows:The Manager-based workflow does not support fluid creation and reset, so we use the Direct workflow instead. Examples of the Direct workflow can be found in the directory:","titles":[]},"21":{"title":"The Code","content":"This is a sample code of RL training with fluid simulation:","titles":["Enabling fluid simulation"]},"22":{"title":"The Code Explained","content":"This section covers the implementation of fluid simulation in Isaac Lab. In Isaac Lab, when creating a scene, we typically only need to create one env, and the other envs are duplicated by Isaac Lab based on the first one.\nHowever, since Isaac Lab does not support duplicating particle objects, we need to create individual particle objects for each env. We use particleUtils.add_physx_particle_system to create the particle system and the CreateMdlMaterialPrim command to bind the physical and surface materials of the particles. It is important to note that the CreateAndBindMdlMaterialFromLibrary command is not available in headless mode, so we need to use the CreateMdlMaterialPrim command instead. Next, we configure the physical properties of the particle system. We use particleUtils.add_physx_particleset_points to create a particle set, which belongs to the particle system and contains the actual particles.\nIn an RL environment, only one particle system is needed, but a separate particle set must be created for each environment. Currently, there doesn't seem to be a direct way to retrieve the positions and velocities of particles from Isaac Lab's backend.\nAs a workaround, we use the UsdGeom Points API to obtain the particle states. This is also why it's necessary to enable UpdateToUsd and UpdateParticlesToUsd. Directly converting particle states into tensors is very slow, significantly impacting RL training efficiency. However, converting them into NumPy arrays is much faster.\nTherefore, we convert the particle positions into a NumPy array and record the minimum value along the z-axis for each group of particles, as this is the only data we need.","titles":["Enabling fluid simulation"]},"23":{"title":"Distilling GPT with PyTorch and Transformers","content":"A step-by-step tutorial demonstrating how to distill GPT models using the PyTorch and Hugging Face Transformers libraries. This tutorial explains how to distill GPT2 into a smaller distilgpt2 model. The entire pipeline includes: Setting up a stable training environment.Loading teacher (gpt2) and student (distilgpt2) models.Using data augmentation (if desired).Applying improved preprocessing steps.Implementing label smoothing.Using a custom distillation loss function.Training and evaluating the distilled model. Throughout the tutorial, you'll see how to train the student model using teacher outputs (knowledge distillation) while also retaining some direct supervision from ground-truth labels (hard loss). This balance is configured with a parameter alpha.","titles":[]},"24":{"title":"Prerequisites","content":"PyTorch (for building and training neural networks)Hugging Face Transformers (for pretrained transformer models)Datasets (to load and process datasets)Basic familiarity with Python and deep learning concepts Ensure you have installed these packages before proceeding:","titles":["Distilling GPT with PyTorch and Transformers"]},"25":{"title":"Full Code","content":"Below is the complete code for the distillation workflow. You can save it in a file named Distill_GPT.py (or any name you prefer) and run it. Comments in the code are partly in Chinese, but each section is explained in English below the code blocks.","titles":["Distilling GPT with PyTorch and Transformers"]},"26":{"title":"Explanation of Key Steps","content":"","titles":["Distilling GPT with PyTorch and Transformers"]},"27":{"title":"1. Device Setup","content":"We detect whether a GPU is available using torch.cuda.is_available(): This ensures our model will train on GPU if available, otherwise on CPU.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"28":{"title":"2. Choosing Stable Base Models","content":"We define the teacher and student models: Feel free to switch them to other models (like GPT-Neo or GPT-J) if you wish, as long as they match a causal language modeling architecture.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"29":{"title":"3. Loading Models in FP32 & Adjusting Dropout","content":"We load both teacher and student in FP32 for more stable training. We also increase the dropout for the student model to reduce overfitting:","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"30":{"title":"4. Loading the Tokenizer","content":"We use the same tokenizer as our teacher model for consistency: We set pad_token to eos_token to ensure all sequences are padded consistently.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"31":{"title":"5. Data Augmentation","content":"Here, you can optionally include text augmentation techniques (synonym replacements, random insertions, etc.). Currently, this function returns the original text.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"32":{"title":"6. Improved Data Preprocessing","content":"We perform minimal text cleaning and tokenization: We remove texts that are too short (less than 10 characters). This helps avoid training with trivial examples.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"33":{"title":"7. Loading & Splitting the OpenWebText Dataset","content":"The dataset is split into training (90%) and testing (10%). We then map our tokenize_function to tokenize the entire dataset.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"34":{"title":"8. DataLoader Configuration","content":"We create PyTorch DataLoaders for both training and testing, defining a custom collate_fn that moves tensors to the correct device:","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"35":{"title":"9. Label Smoothing","content":"A custom class LabelSmoothingCrossEntropy is implemented to mitigate overconfidence in predictions. We replace the typical cross-entropy loss with label smoothing:","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"36":{"title":"10. Improved Distillation Loss Function","content":"The distillation_loss function calculates: Hard Loss: computed via label smoothing (label_smoothing_loss_fn).Soft Loss: a Kullback-Leibler divergence between teacher and student logits, scaled by a temperature. The parameter alpha balances between hard and soft losses.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"37":{"title":"11. Training Loop","content":"We define train_student to run through multiple epochs of training: During each batch: The teacher model generates logits.The student model generates logits.We compute the distillation loss and backpropagate.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"38":{"title":"12. Model Evaluation","content":"We generate text from both teacher and student models on the test set using: We collect a few samples to compare their outputs.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"39":{"title":"13. Running the Training","content":"Here, we call train_student(...) with the desired parameters: Adjust epochs or learning rate as needed.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"40":{"title":"14. Saving the Final Model","content":"We save the student model's final state dictionary:","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"41":{"title":"15-16. Comparison and Saving Outputs","content":"We generate a few samples from both teacher and student and write them to a text file to visually compare performance.","titles":["Distilling GPT with PyTorch and Transformers","Explanation of Key Steps"]},"42":{"title":"Conclusion","content":"You have now completed a step-by-step guide for distilling a GPT model (GPT2) into a smaller student (DistilGPT2). This approach balances teacher-derived knowledge (soft labels) with the original ground truth (hard labels) to produce a more compact yet capable model. Feel free to modify: The data augmentation logic.The temperature and alpha parameters in the distillation loss.The dropout rates.Other hyperparameters (batch size, learning rate, epochs, etc.). Experiment with these settings to find the best trade-off between performance and model size. Good luck distilling!","titles":["Distilling GPT with PyTorch and Transformers"]},"43":{"title":"Real-time Dexterous Telemanipulation","content":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach","titles":[]},"44":{"title":"Real-time Dexterous Telemanipulation with an End-Effect-Oriented Learning-based Approach","content":"This paper presents the End-Effects-Oriented Learning-Based Dexterous Telemanipulation (EFOLD) Framework,\nwhich aims to overcome the challenges faced in robotic telemanipulation by focusing on outcomes rather than mimicking human hand motions.\nTraditional approaches to telemanipulation usually map human hand gestures onto a robotic hand, often neglecting the complex physical interactions involved.\nEFOLD addresses these shortcomings by utilizing Deep Reinforcement Learning (DRL) and focusing on end effects—key features that represent the physical consequences of manipulation, such as force, tactile feedback, and movement. This paper was presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),\na prestigious international conference that gathers top researchers and practitioners from across the globe to discuss advances in robotics, automation, and intelligent systems.\nIROS is widely recognized as one of the most influential conferences in the field of robotics, showcasing cutting-edge research and serving as a platform for sharing groundbreaking ideas. Key Highlights of the EFOLD Framework: End-Effect Modeling: EFOLD redefines the telemanipulation process by treating the task as a Markov Game, where the human operator and robot are considered separate agents.\nThe goal is to interpret the human operator's actions in terms of end effects that the robot must recreate.Deep Reinforcement Learning: By using a learning-based approach, EFOLD enables the robotic hand to autonomously recreate the necessary interactions with objects,\nleading to precise and efficient manipulation without overburdening the human operator.Human-Offline Training & Human-Online Testing: The framework adopts an innovative strategy where the DRL policy is trained offline,\nreducing the need for human input during training, and allowing humans to focus only on the testing phase. The framework was evaluated using a virtual Shadow Robot Hand to perform dexterous manipulation tasks. Results show that EFOLD can achieve real-time control with low latency and high precision. During testing,\nEFOLD demonstrated its capability to replicate end effects efficiently, achieving a command-following latency of less than 0.11s and highly accurate tracking with an MSE of less than 0.084 rad. Research Contributions: Markov Game Model: The telemanipulation problem was formulated as a Markov Game, allowing for the integration of human and robotic agents under a unified mathematical model.End Effect Categorization: Two categories of end effect extraction methods were proposed—internal and external—to enhance the interpretability and applicability of human commands.Efficient Training Approach: The human-offline training strategy significantly saves time and reduces human effort during the training process. This work sets a new benchmark for robot-assisted manipulation in environments where precision and real-time response are critical, such as telesurgery and remote exploration. The paper and related materials, including implementation code, are available on GitHub.","titles":["Real-time Dexterous Telemanipulation"]},"45":{"title":"Hallucination Prevention in LLMs","content":"Zero-Resource Hallucination Prevention for Large Language Models","titles":[]},"46":{"title":"Zero-Resource Hallucination Prevention for Large Language Models","content":"The paper \"Zero-Resource Hallucination Prevention for Large Language Models\", published in the Findings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024 Findings),\nheld from November 12–16 in Miami, Florida, introduces a novel approach to mitigating hallucinations—instances where large language models (LLMs)\nproduce inaccurate or ungrounded information. EMNLP, organized by the Association for Computational Linguistics (ACL), is one of the premier conferences in\nthe field of natural language processing (NLP). It provides a leading platform for presenting groundbreaking research in NLP and computational linguistics,\nattracting researchers, practitioners, and industry leaders worldwide. The Findings of EMNLP serves as an associated venue for high-quality papers, ensuring a broader platform for innovative contributions. This paper proposes SELF-FAMILIARITY, a zero-resource pre-detection mechanism that evaluates the model's\nfamiliarity with the concepts in a given instruction and refrains from generating responses if the concepts are unfamiliar. Key Contributions: Self-Familiarity Mechanism: This approach mimics human self-assessment, analyzing concept familiarity to prevent hallucinations proactively rather than correcting them post hoc.Three-Step Framework:Concept Extraction: Identifies key entities within an instruction.Concept Guessing: Assesses the familiarity of extracted concepts using prompt engineering.Aggregation: Combines familiarity scores of all concepts to determine the overall instruction familiarity.Robustness and Versatility: Unlike previous methods, SELF-FAMILIARITY achieves consistent performance across different LLMs and instruction styles without requiring external knowledge or resources.Empirical Validation: Evaluated across four LLMs using the proposed Concept-7 dataset, SELF-FAMILIARITY outperforms existing methods in detecting hallucinatory instructions, showcasing higher accuracy, consistency, and interpretability. This work marks a shift toward proactive and preventative strategies for hallucination mitigation in LLMs, enhancing their reliability and usability in real-world applications. The paper and related materials, including the implementation code, are available on GitHub and AccessData.","titles":["Hallucination Prevention in LLMs"]},"47":{"title":"Robotics Dataset Comparison","content":"A comprehensive overview and comparative analysis of 16 mainstream robotics datasets and frameworks, including LeRobot, Open X-Embodiment, DROID, RoboTurk, MIME, Meta-World, RoboNet, RoboSet, BridgeData V2, RT-1, Dobb·E, RH20T, BC-Z, MT-Opt, VIMA, and SPOC. Below is a comprehensive overview and comparative analysis of 16 mainstream robotics datasets and frameworks. The report is organized into two parts: first, a summary table that highlights key characteristics, and second, detailed descriptions of each dataset's scope, technical features, advantages, and disadvantages. Note: This analysis is accurate as of the last modified date, \"Mar 28, 2025.\"","titles":[]},"48":{"title":"Summary Table","content":"Dataset / FrameworkScope & ApplicationScale & ModalitiesKey AdvantagesKey Disadvantages1. LeRobot  (GitHub)Real-world robotics for imitation and reinforcement learning; supports both simulation and physical robots.Pretrained models and demo datasets; primarily visual and robot state data with temporal (multi-frame) context.End-to-end learning with community support; integrated simulation environments.Complex setup; may require substantial computing and sensor calibration.2. Open X-Embodiment  (Website)Large-scale, multi-embodiment robotic manipulation; pooling data from many institutions.1M+ trajectories spanning 22 robot embodiments; heterogeneous real-world data.Massive diversity enabling cross-robot transfer and positive knowledge sharing.Heterogeneous quality and potential standardization issues across varied sources.3. DROID  (Website)In-the-wild robot manipulation for robust imitation learning.76K demonstration trajectories (~350 hours) recorded with Franka Panda arms; multiple camera viewpoints.Diverse, large-scale manipulation data that improves policy robustness.Mostly limited to manipulation with a specific hardware setup; less diversity in task types.4. RoboTurk  (Website)Crowdsourced robotic skill learning via teleoperation; real-world demonstration collection.Pilot and real-world datasets (hundreds to thousands of demos, several hours of data) from teleoperated sessions.Leverages non-expert, scalable human demonstrations; supports collaborative tasks.Variation in demonstration quality and potential limits in scale compared to fully automated data collection.5. MIME  (Google Sites)Imitation learning for robot manipulation using human demonstrations.Multi-modal data (visual, robot states, actions) collected via teleoperation; moderate number of trajectories.Focus on high-quality manipulation trajectories; well-suited for imitation learning.May be smaller in scale and less diverse than some large-scale multi-robot datasets.6. Meta-World  (Website)Benchmark for multi-task and meta-reinforcement learning in simulation.50 distinct simulated manipulation environments; task variations with visual observations.Standardized benchmark for meta-RL; structured for evaluating generalization.Limited to simulation and may not capture the full variability of real-world settings.7. RoboNet  (Website)Open database of real robotic experience for manipulation tasks across multiple platforms.~15M video frames, collected from 7 robot platforms with diverse camera viewpoints.Large-scale, multi-platform real-world data that facilitates cross-robot generalization.Very high storage and processing requirements; complex data integration.8. RoboSet  (Website)Multi-task dataset for household (kitchen) manipulation tasks, including language instructions.28,500 trajectories (mix of ~9.5K teleop and ~19K kinesthetic demos), recorded with 4 camera views per frame.Rich, multi-modal data in realistic home environments; supports language-guided sequencing.Domain-specific (largely kitchens); may not generalize to non-domestic scenarios.9. BridgeData V2  (Website)Large-scale robotic manipulation across diverse environments and skills with language annotations.~60K trajectories, 24 environments, 13 skills; includes multi-view (fixed, wrist, randomized) RGB (and depth) data plus natural language.Very diverse and large-scale, ideal for cross-domain generalization and multi-modal learning.Often collected with a specific robot (e.g. WidowX); complex setup and annotation consistency challenges.10. RT-1  (Website)Real-world imitation learning for multi-task manipulation using transformer architectures.Over 130K episodes covering 700+ tasks from 13 robots; uses visual and language inputs for closed-loop control.Outstanding generalization and performance on diverse tasks; scalable transformer model.High training and computational requirements; system complexity may be a barrier.11. Dobb·E  (Website)Framework for home robotics: learning household manipulation tasks quickly in real homes.“HoNY” dataset: 13 hours from 22 NYC homes, 5,620 trajectories, RGB and depth at 30 fps; also includes hardware (the “Stick”) for data collection.Cost-effective, rapid task learning with real household data; designed for generalist home robots.Domain-specific to domestic settings; quality and consistency can vary with non-expert demonstrations.12. RH20T  (Website)Comprehensive dataset for contact-rich, multi-modal robot manipulation tasks in the real world.Millions of human-robot demonstration pairs; modalities include high-resolution RGB, depth, force/torque, audio, tactile, and high-frequency joint data.Extremely rich multi-modal data enabling detailed analysis and one-shot imitation learning.Very large and complex; requires significant computational and storage resources; complex data processing pipeline.13. BC-Z  (Website)Large-scale behavior cloning for robotic manipulation.(Details are sparser online but BC-Z is designed to support imitation learning with a large number of trajectories.)Provides a standardized dataset specifically aimed at behavior cloning; useful for benchmarking imitation algorithms.May offer less diversity outside manipulation tasks and less extensive documentation compared to other datasets.14. MT-Opt  (Website)Multi-task reinforcement learning at scale across many manipulation skills.Data collected from 7 robots over 9,600 robot hours spanning 12 tasks; continuous multi-task RL framework.Enables simultaneous learning across tasks; improves performance especially on underrepresented skills through shared experience.Demands large-scale infrastructure and careful task specification; complexity in multi-task coordination.15. VIMA  (Website)General robot manipulation via multimodal prompts (combining language and vision) for unified task specification.Benchmark with thousands of procedurally generated tabletop task instances; uses imitation learning data alongside transformer-based models.Unified formulation that “prompts” the robot to perform diverse tasks; highly scalable and sample-efficient.Primarily demonstrated in benchmark/simulated settings; real-world transfer may require additional adaptation.16. SPOC  (Website)Imitation learning for long-horizon navigation and manipulation using shortest path imitation (trained in simulation, deployed in the real world).Trained with RGB-only inputs in simulation; demonstrated on real robots for tasks such as object fetching and navigation.Robust long-horizon planning; effective sim-to-real transfer with minimal sensing (RGB only); no need for depth or privileged info.RGB-only perception can limit object recognition; some failure cases persist in challenging real-world scenarios.","titles":["Robotics Dataset Comparison"]},"49":{"title":"Detailed Comparison","content":"","titles":["Robotics Dataset Comparison"]},"50":{"title":"1. LeRobot","content":"Scope & Application:\nLeRobot is designed to lower the barrier for robotics research by providing an end-to-end learning framework with integrated pretrained models, diverse datasets, and simulation environments. It is well suited for imitation and reinforcement learning research on both simulated and real robots. Technical Features: Built in PyTorch with modular dataset classes that support multi-frame temporal sampling.Offers pretrained policies (e.g. ACT, Diffusion, TDMPC) and supports various robot platforms and environments. Advantages: Community-driven with active contributions and hosted on Hugging Face.Facilitates rapid prototyping in robotics with an accessible codebase. Disadvantages: Complexity in data handling (various sensor streams and temporal dynamics) can demand significant compute and expertise.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"51":{"title":"2. Open X-Embodiment","content":"Scope & Application:\nA collaborative effort pooling robot data from 21 institutions, it is aimed at training “generalist” policies across 22 different robot embodiments. Technical Features: Aggregates 1M+ trajectories from diverse robots and tasks.Supports learning via transformer-based architectures that can generalize across different embodiments. Advantages: Unmatched diversity, which is ideal for studying cross-robot transfer.Large scale increases the potential for generalization. Disadvantages: The heterogeneity of data can introduce inconsistencies; standardizing varied datasets is challenging.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"52":{"title":"3. DROID","content":"Scope & Application:\nFocused on in-the-wild robot manipulation, DROID offers a vast dataset for robust imitation learning using Franka Panda robots. Technical Features: Contains 76K trajectories (~350 hours) across 564 scenes and 86 tasks.Multi-camera views (including wrist and exterior images) enable rich visual inputs. Advantages: Large, diverse dataset that significantly boosts policy performance and robustness.Extensive coverage of real-world scenarios. Disadvantages: Being collected with a specific hardware platform, its applicability to other robots may be limited.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"53":{"title":"4. RoboTurk","content":"Scope & Application:\nRoboTurk is a crowdsourcing platform that leverages teleoperation for collecting human demonstrations on both simulated and real robotic tasks. Technical Features: Provides datasets with hundreds to thousands of successful demonstrations (e.g. pilot dataset and real-world dataset).Includes system features for low-latency teleoperation and human-in-the-loop interventions. Advantages: Enables scalable data collection from non-experts, lowering the cost of obtaining rich demonstrations.Proven effectiveness in enabling imitation learning on challenging tasks. Disadvantages: The quality of demonstrations may vary due to differences in human teleoperation skills.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"54":{"title":"5. MIME","content":"Scope & Application:\nMIME targets imitation learning for manipulation, offering human demonstrations that capture complex manipulation behaviors. Technical Features: Multi-modal data including visual inputs and robot state/action trajectories collected through teleoperation. Advantages: Focused on detailed manipulation tasks, making it ideal for imitation learning studies. Disadvantages: Generally smaller in scale compared to some of the largest datasets; might offer limited diversity.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"55":{"title":"6. Meta-World","content":"Scope & Application:\nA simulation benchmark intended for meta-reinforcement learning and multi-task learning, Meta-World comprises 50 distinct manipulation environments. Technical Features: Structured environments with varying goal positions and task variations to test generalization. Advantages: Standardized and well-documented benchmark that is widely used for evaluating meta-RL algorithms. Disadvantages: Limited to simulated settings; real-world complexities (e.g. sensor noise, dynamics variations) are not fully captured.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"56":{"title":"7. RoboNet","content":"Scope & Application:\nRoboNet is an open database of robotic experience collected from 7 different robot platforms, with an emphasis on visual data for manipulation. Technical Features: Contains over 15M video frames and data from multiple camera viewpoints. Advantages: Offers vast amounts of real-world data to study generalization across different robot hardware. Disadvantages: Requires heavy storage and processing; integrating multi-platform data can be challenging.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"57":{"title":"8. RoboSet","content":"Scope & Application:\nA dataset focused on household (kitchen) manipulation tasks, RoboSet provides both kinesthetic and teleoperated demonstrations with language instructions. Technical Features: 28,500 trajectories captured with 4 camera views per frame; tasks are semantically grouped. Advantages: Rich multi-modal information (visual + language) supports language-guided robotic learning. Disadvantages: Domain-specific to kitchen and household scenes; may not generalize to industrial or outdoor scenarios.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"58":{"title":"9. BridgeData V2","content":"Scope & Application:\nDesigned to boost generalization in robotic skills, BridgeData V2 spans 24 environments and 13 skills, with natural language annotations for goal conditioning. Technical Features: Approximately 60K trajectories with multi-view RGB (and some depth) data.Includes both teleoperated and scripted demonstrations. Advantages: High diversity in environments and tasks; strong support for language-conditioned policy learning. Disadvantages: Often tied to a particular hardware setup (e.g. WidowX 250), and the multi-view setup can complicate data preprocessing.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"59":{"title":"10. RT-1","content":"Scope & Application:\nRT-1 is a state-of-the-art transformer-based model for real-world robotic control trained on a massive dataset of diverse tasks. Technical Features: Over 130K episodes covering more than 700 tasks collected from 13 robots.Utilizes vision and natural language inputs to produce discretized action tokens. Advantages: Demonstrates superior performance and generalization, including sim-to-real transfer.Scalability through high-capacity transformer models. Disadvantages: Demands extensive data, compute, and engineering expertise; system complexity is high.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"60":{"title":"11. Dobb·E","content":"Scope & Application:\nDobb·E focuses on home robotics, providing a full stack (hardware, dataset, models) for learning household manipulation tasks with minimal demonstration time. Technical Features: “HoNY” dataset includes 13 hours of data from 22 New York City homes (5,620 trajectories, RGB + depth at 30 fps).Includes a low-cost hardware “Stick” for demonstration collection. Advantages: Cost-effective and designed for rapid task learning in domestic environments.Demonstrates strong real-world applicability in home settings. Disadvantages: Domain-specific and may not translate to other application areas; non-expert demonstrations can introduce variability.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"61":{"title":"12. RH20T","content":"Scope & Application:\nRH20T is a comprehensive dataset aimed at learning diverse, contact-rich manipulation skills with extensive multi-modal sensor information. Technical Features: Contains millions of demonstration pairs with modalities including high-resolution RGB, depth, force/torque, audio, and tactile sensing.Detailed synchronization and calibration across multiple sensors. Advantages: Extremely rich and diverse data ideal for advancing one-shot imitation learning and fine-grained sensor fusion.Supports research on contact-rich and dexterous manipulation. Disadvantages: Enormous data volume makes it challenging to store, process, and analyze; high complexity in data format and licensing.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"62":{"title":"13. BC-Z","content":"Scope & Application:\nBC-Z is targeted at behavior cloning for robotic manipulation, providing a large-scale dataset that is useful as a benchmark for imitation learning approaches. Technical Features: Although details are less extensively documented online, BC-Z is positioned alongside other large imitation learning datasets. Advantages: Serves as a standardized resource for evaluating behavior cloning algorithms. Disadvantages: May not offer as much diversity or multi-modal richness as some of the larger, more comprehensive datasets.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"63":{"title":"14. MT-Opt","content":"Scope & Application:\nMT-Opt is a framework for continuous multi-task reinforcement learning designed to learn a wide repertoire of manipulation skills concurrently. Technical Features: Built on data collected from 7 robots over 9,600 hours, spanning 12 tasks with a scalable RL method. Advantages: Effective at sharing experience across tasks, significantly boosting performance on rare tasks.Demonstrates both zero-shot and rapid fine-tuning capabilities. Disadvantages: Requires large-scale robotic infrastructure and sophisticated multi-task training pipelines.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"64":{"title":"15. VIMA","content":"Scope & Application:\nVIMA presents a novel formulation in which diverse robot manipulation tasks are “prompted” via interleaved language and visual tokens, unifying task specification. Technical Features: Transformer-based model that leverages multimodal prompts; benchmark includes thousands of procedurally generated tabletop task instances. Advantages: Unified, scalable approach that achieves strong zero-shot generalization and high sample efficiency.Allows integration of various forms of task instructions (text + image). Disadvantages: Largely demonstrated in controlled (often simulated or tabletop) settings; additional work may be needed for full real-world deployment.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"65":{"title":"16. SPOC","content":"Scope & Application:\nSPOC focuses on long-horizon navigation and manipulation by imitating shortest paths. Trained entirely in simulation (using RGB-only inputs), it is deployed in the real world without extra sim-to-real adaptation. Technical Features: Uses a transformer-based action decoder conditioned on language instructions and sequential RGB frames.Emphasizes a minimalist sensory setup (RGB only) to drive exploration and task completion. Advantages: Achieves robust long-horizon planning and recovery in real-world tasks despite minimal input modalities.Trains entirely in simulation and transfers effectively. Disadvantages: RGB-only perception can limit object detection accuracy; some failure cases persist in complex or cluttered real-world scenarios.","titles":["Robotics Dataset Comparison","Detailed Comparison"]},"66":{"title":"General-Purpose Robot Models Analysis","content":"Overview of recent works on general-purpose robot models, comparing key technical aspects and hardware/time requirements for training, fine-tuning, or distillation. Bellow provides an overview of several recent works on general-purpose robot models. It compares key technical aspects—such as model architecture, parameter scale, training data volume, and major innovations—and outlines the typical hardware and time requirements for training, fine-tuning, or distillation. Note: This analysis is accurate as of the last modified date, \"Mar 28, 2025.\"","titles":[]},"67":{"title":"Comparison of Robot Models","content":"Below is a table summarizing 10 projects, including their model architecture/method, parameter scale, training data volume, and key features/remarks. (Note: For some projects, specific numbers such as parameter counts or data volumes are not disclosed; descriptive indicators are provided instead.) Project NameModel Architecture / MethodParameter ScaleTraining Data / Data VolumeKey Features / Remarks1. Octo  (Website)Transformer-based diffusion policy supporting language, target images, and sensor history conditioningOcto-Small: 27MOcto-Base: 93MPre-trained on 800k robot demonstrations, integrating 25 datasets (Open X-Embodiment)Flexibly adaptable to different robots and sensors; efficient fine-tuning; excellent performance in zero-shot and few-shot scenarios2. OpenVLA  (Website)Fuses a visual encoder (SigLIP + DinoV2) with a Llama 2 7B language model to generate action tokens7BPre-trained on 970k robot demonstrations (Open X-Embodiment)Leverages internet pre-trained vision-language knowledge; supports multi-robot control; resource-intensive training (64 A100 GPUs, 15 days)3. UMI  (Website)Data collection and policy learning framework based on a handheld gripper and wrist-mounted camera for in-the-wild demonstrationsNot disclosedRapid in-the-wild demonstration capture (approx. 30 seconds per demo), with high data diversityLow-cost, portable hardware design; enables zero-calibration and bimanual dynamic manipulation; focuses on demonstration data collection4. RDT-1B  (Website)Transformer policy based on diffusion models, specifically designed for bimanual manipulation1.2BPre-trained on 46 datasets with over 1M demonstrations; additional 6K+ bimanual demonstrationsLarge-scale pre-training, multi-task cross-robot capability; excellent zero-shot generalization and few-shot learning ability5. openpi  (GitHub)Consists of π₀ (streaming diffusion VLA) and π₀-FAST (autoregressive VLA) for vision-language-action tasksNot explicitly disclosedPre-trained on 10k+ hours of robot dataProvides multiple base model checkpoints; easy fine-tuning for downstream tasks; adaptable to various robot platforms6. Mobile ALOHA  (Website)Imitation learning (behavior cloning) based mobile manipulation system combining whole-body control and low-cost remote operationNot disclosedApproximately 50 demonstrations per task, jointly trained with a static ALOHA datasetExtends traditional ALOHA to mobile platforms; enables complex mobile manipulation tasks (e.g., opening doors, using elevators)7. RT-2  (Website)Vision-language-action model that encodes robot actions as text tokens, combining internet pre-training with robot dataBased on PaLM-E: 12Bor PaLI-X: 55BMixed large-scale internet vision-language data and robot trajectory data (exact numbers undisclosed)Utilizes a pre-trained large model’s semantic understanding and reasoning; enables multi-step task planning and coherent execution; strong generalization8. VIMA  (Website)Transformer-based robotic agent that generates actions through multimodal prompts (language, image/video)2M - 200M (depending on variant)Over 600K expert demonstrations; supplemented with large amounts of programmatically generated task dataData-efficient; unified representation for various tasks; exhibits good zero-shot generalization and cross-task adaptability9. Perceiver-Actor  (Website)Behavior cloning strategy based on a Perceiver Transformer, using RGB-D voxelized input and discretized action predictionNot disclosed (relatively lightweight)Demonstration counts are relatively low (e.g., for RLBench with 249 variants and 7 real-world tasks, approx. 53 demos)Data-efficient learning for 6-DoF manipulation; suitable for few-shot multi-task scenarios; high-performance action detection10. SayCan  (Website)Integrates a large language model with pre-trained skill/value functions; uses language scoring combined with execution probabilities for task planningBased on LLM (e.g., PaLM) with parameters up to tens of billions; skill modules are smallerUtilizes large-scale internet text and robot skill demonstration data (exact figures undisclosed)Achieves long-horizon task planning and semantic reasoning; composes multi-step skills; supports multilingual capability; improves execution success rate","titles":["General-Purpose Robot Models Analysis"]},"68":{"title":"Hardware and Time Requirements for Training, Fine-Tuning, or Distillation","content":"The following table outlines typical hardware devices and approximate training times for various stages, such as pre-training (full training), fine-tuning (or parameter-efficient fine-tuning), and distillation. Actual requirements vary depending on model scale, data volume, training strategy (e.g., full vs. parameter-efficient fine-tuning), and task specifics. Project NamePre-training / Full Training (Hardware & Time)Fine-Tuning / Parameter-Efficient Fine-Tuning / Distillation (Hardware & Time)Remarks1. Octo  (Website)- Pre-training on 800k demos typically requires multiple high-performance GPUs (e.g., A100/RTX4090)- Training time: several days to weeks- Fine-tuning using efficient strategies can often be completed on a single GPU in a few hours to one dayAdaptable to different robots and sensors; fine-tuning time is relatively short2. OpenVLA  (Website)- Pre-training used 64 A100 GPUs, with a training duration of about 15 days- Task-specific fine-tuning using parameter-efficient methods usually takes a few hours to one day on a single GPULeverages large-scale internet pre-training; resource-intensive3. UMI  (Website)- Focused on data collection and policy learning; training can be done on low-cost GPUs (or even a single card)- Training time: on the order of a few hours- Fine-tuning for specific tasks (using fast demonstration capture) typically completes within hoursUses portable hardware design; suitable for in-the-wild demonstration data4. RDT-1B  (Website)- Pre-training a 1.2B parameter model generally requires a multi-GPU cluster (e.g., 8-16 A100 GPUs)- Training time: possibly over a week- Fine-tuning on specific bimanual tasks (using additional 6K+ demos) may take from a few hours to one dayLarge parameter scale and rich data; high resource and time demand for pre-training5. openpi  (GitHub)- Full training on 10k+ hours of robot data may require high-memory GPUs (e.g., A100/H100)- Parameter-efficient fine-tuning (e.g., using LoRA) typically requires at least 22.5GB of GPU memory (e.g., RTX4090) with training times from a few hours to a few daysOffers both full training and efficient fine-tuning options; hardware requirements are clearly defined6. Mobile ALOHA  (Website)- Imitation learning methods typically train on a single high-end GPU (e.g., RTX 3090/4090)- Training time: several hours to one day- Fine-tuning using combined static ALOHA data generally completes on a single GPU in a short periodFocuses on mobile and whole-body control; relatively small data volume7. RT-2  (Website)- Large models (12B-55B parameters) require extensive GPU clusters (e.g., 64 A100 GPUs)- Pre-training time: typically several weeks- Fine-tuning for specific tasks using joint training strategies may take from a few hours to one day, depending on data volumeCombines internet-scale pre-training with robot data; high hardware and time requirements8. VIMA  (Website)- Model sizes range from a few million to several hundred million parameters- Smaller variants can be trained on a single GPU in hours; larger variants may need multiple GPUs for days to a week- Fine-tuning is typically done on a single GPU or a small multi-GPU setup; high data efficiency can greatly reduce training timeModel and data scale are adjustable, making fine-tuning flexible9. Perceiver-Actor  (Website)- Due to voxelized inputs and discrete action prediction, training can often be done on a single GPU (8-16GB memory)- Training time: typically several hours to one day- Fine-tuning for few-shot scenarios is highly efficient, often completing within a few hoursEmphasizes data-efficient learning for 6-DoF manipulation; suitable for low-resource environments10. SayCan  (Website)- Integrates a large language model (e.g., PaLM series) with robot skills; pre-training typically uses TPUs or large-scale GPU clusters- Pre-training time: may span several weeks- Fine-tuning or distillation for specific scenarios is typically carried out on multi-GPU or TPU setups, taking from a few hours to one dayCombines semantic reasoning with low-level skills; high resource requirements for pre-training, but fine-tuning can leverage LLM improvements","titles":["General-Purpose Robot Models Analysis"]},"69":{"title":"Wheel-Based Humanoid Robots","content":"An overview of notable wheel-based humanoid robots, highlighting their developers, descriptions, applications, features, advantages, and disadvantages. Wheel-based humanoid robots combine the stability and efficiency of wheels with the versatility of a humanoid upper body, making them suitable for various applications such as logistics, customer service, and research. Below is a comprehensive overview of notable wheel-based humanoid robots, highlighting their developers, descriptions, applications, features, advantages, and disadvantages. Note: This analysis is accurate as of the last modified date, \"Aprl 6, 2025.\"","titles":[]},"70":{"title":"Overview of Wheel-Based Humanoid Robots","content":"Robot NameDeveloperDescriptionApplication ScenariosFeaturesAdvantagesDisadvantages1. Reflex Robot  (Website)Reflex RoboticsA humanoid robot with a wheeled base and a humanoid upper body, capable of dynamically adjusting its height to access different shelves.Warehouse picking, logistics operationsReportedly costs 20 times less than other humanoid robots; supports remote control for complex tasks.Cost-effective, suitable for budget-limited enterprises; remote control enhances operational flexibility.May have limitations in load capacity and autonomy.2. Handle  (Website)Boston DynamicsA research robot combining wheeled mobility with bipedal stance, equipped with two arms for handling and manipulating objects.Warehouse material handling, industrial logisticsMoves at 9 mph, jumps up to 4 feet, battery life of approximately 15 miles.Multi-modal mobility performs well in both flat and complex environments.Focuses primarily on physical tasks, lacking human-robot interaction capabilities.3. ARI  (Website)PAL RoboticsA social robot with a humanoid appearance, featuring a head with LCD eyes, two arms, and a wheeled base, designed for human-robot interaction and front-desk activities.Retail front desk, research institutions, educational environmentsCapable of facial recognition, speaks 30 languages, provides information via touchscreen.Strong interaction capabilities, customizable behavior through web interface, suitable for scenarios requiring high-level social interaction.May have limitations in complex tasks and load capacity.4. Pepper  (Website)Softbank RoboticsA wheeled humanoid robot with a screen as its \"face,\" adept at emotion recognition and customer service.Customer service, retail interaction, educational assistanceUnderstands and responds to human speech, suitable for retail, healthcare, and education sectors.Outstanding emotion recognition and multilingual dialogue capabilities in social robots.Production ceased in 2021, potentially affecting future support and maintenance.5. HSR (Human Support Robot)  (Website)ToyotaA compact wheeled robot with a cylindrical body and folding arm, designed to assist the elderly and disabled with household tasks.Home assistance, elderly careCapable of tasks like picking up objects and opening curtains; high safety and reliability, suitable for home environments.Functional design prioritizes utility over traditional humanoid aesthetics, which may affect user acceptance.Limited to specific household tasks, may not be suitable for more complex applications.6. EVE  (Website)1X TechnologiesThe first-generation wheeled robot developed by Norwegian company 1X Technologies, primarily used in logistics, retail, and security sectors.Logistics, retail, security patrolsFlexible mobility and basic interaction functions.Suitable for various commercial scenarios, agile movement.Limited interaction capabilities, may not be suitable for scenarios requiring complex human-robot interaction.7. Walker X  (Website)UBTECH RoboticsA large humanoid robot with 41 high-performance servo joints, offering flexible movement and interaction capabilities.Tour guidance, dance performances, calligraphy tasksEngages in natural interactions and performs complex actions.Suitable for exhibitions, education, and other fields; outstanding interaction and movement abilities.Larger size may limit applications in confined spaces.8. RB-Y1  (GitHub)Rainbow RoboticsA wheeled robot with a humanoid dual-arm manipulator mounted on top, utilizing a base for flexible movement.Material handling, assembly, inspection, research experiments24 degrees of freedom, movement speed up to 1.5 m/s, operates for three hours per charge.Flexible movement and operation capabilities, suitable for various industrial and research applications.Primarily targeted at research institutions, with limited commercial applications.9. Expedition A2-W  (Website)Zhiyuan RoboticsA wheeled humanoid robot with a planned shipment of 100 units, suitable for various service and interaction scenarios.Service, interactionWheeled design with humanoid features, planned for mass production.Applicable to various service and interaction scenarios; mass production reduces costs.Performance and application effectiveness await market validation.10. MercuryX1  (Website)Elephant RoboticsA wheeled humanoid robot that has achieved mass production, with hundreds of units delivered.Multi-scenario servicesWheeled design combining dual arms and visual applications, suitable for various service scenarios.Successfully mass-produced with mature market application experience.Future plans for X323 model have undisclosed performance details.11. GoMate  (Website)GAC GroupThe third-generation embodied intelligent humanoid robot adopting a variable wheel-leg mobility structure.Security patrols, complex terrain inspectionsFaster speed and more stable mobility.Adapts to various terrains, fast and stable movement.Complex design may result in higher costs.","titles":["Wheel-Based Humanoid Robots"]},"71":{"title":"Conclusion","content":"Wheel-based humanoid robots represent a significant advancement in robotics, merging the efficiency of wheeled locomotion with the versatility of humanoid interaction. They are increasingly being integrated into various sectors, including logistics, customer service, and research, offering tailored solutions to meet specific needs. As technology continues to evolve, these robots are expected to become even more capable and accessible, further transforming the landscape of human-robot collaboration.","titles":["Wheel-Based Humanoid Robots"]},"72":{"title":"Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","content":"Exploring the social dimensions of human-robot interaction and the potential emergence of machine societies through multi-agent systems.","titles":[]},"73":{"title":"Introduction","content":"As robots increasingly enter homes, hospitals, classrooms, and cities, we are gradually moving toward a society where humans coexist with non-human intelligent agents. This transformation is not merely technological—it challenges our basic understanding of who counts as a social member and how society itself evolves. This article focuses on two core topics in robotic sociology: (1) the social dimensions of Human-Robot Interaction (HRI), and\n(2) the potential emergence of \"machine societies\" through multi-agent systems.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures"]},"74":{"title":"I. The Social Dimensions of Human-Robot Interaction","content":"","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures"]},"75":{"title":"From Functional Tools to Social Actors","content":"Social robots are no longer just smart tools that follow commands—they are interactive systems that mimic human social behaviors and seek integration into everyday life. Through facial expressions, verbal cues, gestures, and physical presence, these robots are designed to build rapport with humans. Common examples include NAO as an educational assistant, Paro the therapeutic seal for elder care, and Pepper for customer service. These robots prompt a key sociological shift: from human-robot interaction to human-robot relationship.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","I. The Social Dimensions of Human-Robot Interaction"]},"76":{"title":"The Evolution of Trust: From Reliability to Ethical Agency","content":"Trust in robots can be unpacked into three layers: Functional Trust: Does the robot reliably complete tasks?Affective Trust: Does the robot evoke comfort or companionship?Ethical Trust: Can the robot make morally acceptable decisions? Critical factors that shape trust include: Explainability: Can the robot justify its actions?Adaptability: Does it adjust to user behavior and context?Agency: Is it capable of ethical decision-making? As robots take on roles in high-stakes domains (e.g., autonomous vehicles, robotic surgery), these trust dynamics become existential questions—how much control are we willing to delegate to machines? Hence, recent design efforts emphasize transparent, auditable, and behaviorally predictable AI systems, where trust is earned not just through utility, but through legibility and accountability.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","I. The Social Dimensions of Human-Robot Interaction"]},"77":{"title":"Social Presence and Theatrical Interaction","content":"Social presence theory, rooted in social psychology, explores how humans perceive an intelligent system’s “co-presence” in either physical or virtual space. Even disembodied systems like Siri or Alexa are often addressed with politeness or frustration—indicating a cognitive attribution of social agency. Reeves & Nass’s Media Equation suggests that people instinctively treat interactive technologies as social beings. Goffman’s Dramaturgical Theory complements this: human-robot interaction is a kind of performance. The robot \"acts\" according to social scripts, and humans “play along.” This performative dynamic is what makes robots acceptable, even likable, in daily life.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","I. The Social Dimensions of Human-Robot Interaction"]},"78":{"title":"II. Toward “Machine Societies”: The Emergence of Collective Robotic Behavior","content":"When robots transition from individual agents to interconnected systems, the nature of interaction also scales: they begin to form coordinated collectives that resemble early forms of social structures.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures"]},"79":{"title":"Multi-Robot Systems and Swarm Coordination","content":"Three dominant technical paradigms define modern multi-robot systems: ParadigmFeaturesExamplesPhilosophical ViewCybernetic ControlCentralized planning and taskingManufacturing arms, warehouse botsStructuralism (top-down design)Swarm IntelligenceDecentralized, emergent behaviorDrone swarms, rescue botsBehavioral EcologyMulti-Agent LearningExperience-driven, strategic cooperationUrban traffic, autonomous fleetsSystems Theory (evolutionary)","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","II. Toward “Machine Societies”: The Emergence of Collective Robotic Behavior"]},"80":{"title":"From Coordination to Social Norms","content":"A system of robots doesn't become a society until it develops: Identity and boundary recognition (“us” vs “them”),Hierarchies or power structures (which bots lead others),Reward or penalty systems (correcting misbehavior),Communication protocols (to share intent and rules). Some experimental systems already implement components like reputation scores, democratic voting, or error punishment mechanisms, but these are often human-engineered and lack autonomous institutionalization. The challenge remains: can social norms emerge organically within robot collectives?\nIf so, will they mirror human social dynamics—or evolve differently?","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","II. Toward “Machine Societies”: The Emergence of Collective Robotic Behavior"]},"81":{"title":"Human-Machine Co-Constitution: The Need for Social Governance","content":"Today’s large-scale robotic systems—autonomous vehicles, drone swarms, last-mile delivery fleets—already exhibit quasi-social behavior. They operate with increasing autonomy, adaptability, and interdependence. But the question is no longer just technical. We must ask: Who governs robot societies?Who is responsible when systems fail?Can robot collectives develop bias, hierarchy, or exclusionary practices?How do we design hybrid social contracts between humans and machines? Robotic sociology warns us not to underestimate these systems. Their “sociality” may be synthetic, but their impact on real-world institutions and behaviors is very real.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures","II. Toward “Machine Societies”: The Emergence of Collective Robotic Behavior"]},"82":{"title":"Conclusion: Are Robots Becoming Social Members?","content":"The question robotic sociology poses is profound: Are robots still tools, or are they becoming participants in society? From micro-level interactions to macro-level collectives, robotic systems are evolving from mechanical servants to complex social actors. As they do, we must rethink: The boundaries of moral and legal responsibility,The dynamics of trust, identity, and belonging,The frameworks for ethical design and democratic oversight. This is no longer a question of engineering alone—it’s a co-construction of society between humans and machines.","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures"]},"83":{"title":"Suggested Readings & References","content":"Reeves, B. & Nass, C. (1996). The Media EquationGoffman, E. (1959). The Presentation of Self in Everyday LifeAwad, E. et al. (2018). The Moral Machine Experiment, NatureChen, W. (2023). Machine Encounters with the Other MindBelpaeme, T. et al. (2018). Social Robots for Education: A Review, Science RoboticsIEEE (2019). Ethically Aligned DesignUNESCO (2021). Recommendation on the Ethics of AI If citing or reposting this article, please credit the author and source: CyberNachos","titles":["Robotic Sociology: Human-Robot Interaction and the Emergence of Machine Social Structures"]},"84":{"title":"Home","content":"Welcome to Cyber NachosA pioneering initiative committed to advancing the field of modern robotics, Artificial Intelligence (AI), and Cybersecurity.","titles":[]},"85":{"title":"Promptrobot","content":"","titles":[]}},"dirtCount":0,"index":[["π₀",{"1":{"67":2}}],["+",{"1":{"57":1,"60":1,"64":1,"67":1}}],["question",{"1":{"81":1,"82":2}}],["questions",{"1":{"76":1}}],["quasi",{"1":{"81":1}}],["quality",{"1":{"46":1,"48":4,"53":1}}],["quickly",{"1":{"48":1}}],["~60k",{"1":{"48":1}}],["~19k",{"1":{"48":1}}],["~15m",{"1":{"48":1}}],["~9",{"1":{"48":1}}],["~350",{"1":{"48":1,"52":1}}],["970k",{"1":{"67":1}}],["93mpre",{"1":{"67":1}}],["9",{"0":{"35":1,"58":1},"1":{"48":2,"63":1,"70":2}}],["90",{"1":{"33":1}}],["800k",{"1":{"67":1,"68":1}}],["8",{"0":{"34":1,"57":1},"1":{"48":1,"68":2,"70":1}}],["86",{"1":{"12":1,"52":1}}],["7b",{"1":{"67":1}}],["700",{"1":{"59":1}}],["700+",{"1":{"48":1}}],["76k",{"1":{"48":1,"52":1}}],["7",{"0":{"33":1,"56":1},"1":{"46":1,"48":3,"56":1,"63":1,"67":2,"70":1}}],["6k+",{"1":{"67":1,"68":1}}],["64",{"1":{"67":1,"68":2}}],["60k",{"1":{"58":1}}],["600k",{"1":{"67":1}}],["600",{"1":{"48":1,"63":1}}],["620",{"1":{"48":1,"60":1}}],["6",{"0":{"32":1,"55":1},"1":{"48":1,"67":1,"68":1,"69":1,"70":1}}],["5gb",{"1":{"68":1}}],["53",{"1":{"67":1}}],["55b",{"1":{"68":1}}],["55bmixed",{"1":{"67":1}}],["552",{"1":{"12":1}}],["564",{"1":{"52":1}}],["5k",{"1":{"48":1}}],["500",{"1":{"48":1,"57":1}}],["50",{"1":{"48":1,"55":1,"67":1}}],["5",{"0":{"31":1,"54":1},"1":{"48":2,"60":1,"70":2}}],["zero",{"0":{"46":1},"1":{"45":1,"46":2,"63":1,"64":1,"67":4}}],["z",{"0":{"62":1},"1":{"22":1,"47":1,"48":2,"62":2}}],["zhiyuan",{"1":{"70":1}}],["zhang",{"1":{"7":2}}],["zheshuo",{"1":{"7":1}}],["zhejiang",{"1":{"7":1}}],["kind",{"1":{"77":1}}],["kinesthetic",{"1":{"48":1,"57":1}}],["kitchens",{"1":{"48":1}}],["kitchen",{"1":{"48":1,"57":2}}],["kit",{"1":{"13":1,"20":1}}],["kullback",{"1":{"36":1}}],["knowledge",{"1":{"20":1,"23":1,"42":1,"46":1,"48":1,"67":1}}],["keep",{"1":{"19":2}}],["key",{"0":{"26":1},"1":{"8":1,"10":1,"19":1,"44":2,"46":2,"47":1,"66":2,"67":1,"75":1},"2":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1}}],["084",{"1":{"44":1}}],["04",{"1":{"12":1}}],["0",{"1":{"12":2,"44":2}}],["41",{"1":{"70":1}}],["4090",{"1":{"68":1}}],["46",{"1":{"67":1}}],["4",{"0":{"30":1,"53":1},"1":{"12":2,"48":2,"57":1,"70":2}}],["justify",{"1":{"76":1}}],["just",{"1":{"75":1,"76":1,"81":1}}],["jumps",{"1":{"70":1}}],["joints",{"1":{"70":1}}],["jointly",{"1":{"67":1}}],["joint",{"1":{"48":1,"68":1}}],["journey",{"1":{"8":1}}],["j",{"1":{"28":1}}],["jinpu",{"1":{"7":1}}],["jiang",{"1":{"7":1}}],["jiayuan",{"1":{"7":1}}],["jiu",{"1":{"7":1}}],["vs",{"1":{"68":1,"80":1}}],["voting",{"1":{"80":1}}],["voxelized",{"1":{"67":1,"68":1}}],["volumecombines",{"1":{"68":1}}],["volume7",{"1":{"68":1}}],["volumekey",{"1":{"67":1}}],["volumes",{"1":{"67":1}}],["volume",{"1":{"61":1,"66":1,"67":1,"68":1}}],["vla",{"1":{"67":2}}],["v2",{"0":{"58":1},"1":{"47":1,"48":1,"58":1}}],["v",{"1":{"19":1}}],["vast",{"1":{"52":1,"56":1}}],["varying",{"1":{"55":1}}],["vary",{"1":{"48":1,"53":1,"68":1}}],["variable",{"1":{"70":1}}],["variability",{"1":{"48":1,"60":1}}],["variants",{"1":{"67":1,"68":2}}],["variant",{"1":{"67":1}}],["variations",{"1":{"48":1,"55":2}}],["variation",{"1":{"48":1}}],["varied",{"1":{"48":1,"51":1}}],["various",{"1":{"2":1,"50":2,"64":1,"67":2,"68":1,"69":1,"70":6,"71":1}}],["value",{"1":{"22":1,"67":1}}],["validation",{"1":{"46":1,"70":1}}],["valid",{"1":{"16":1}}],["viewcybernetic",{"1":{"79":1}}],["view",{"1":{"48":1,"58":2}}],["views",{"1":{"48":1,"52":1,"57":1}}],["viewpoints",{"1":{"48":2,"56":1}}],["video",{"1":{"48":1,"56":1,"67":1}}],["vima",{"0":{"64":1},"1":{"47":1,"48":1,"64":1,"67":1,"68":1}}],["visual",{"1":{"48":4,"52":1,"54":1,"56":1,"57":1,"64":1,"67":1,"70":1}}],["visually",{"1":{"41":1}}],["visible",{"1":{"20":1}}],["vision",{"1":{"8":1,"48":1,"59":1,"67":4}}],["via",{"1":{"36":1,"48":3,"51":1,"64":1,"70":1}}],["virtual",{"1":{"12":2,"13":1,"44":1,"77":1}}],["vehicles",{"1":{"76":1,"81":1}}],["venue",{"1":{"46":1}}],["velocities",{"1":{"20":1,"22":1}}],["verbal",{"1":{"75":1}}],["versatility",{"1":{"46":1,"69":1,"71":1}}],["version",{"1":{"12":8}}],["very",{"1":{"22":1,"48":3,"81":1}}],["verify",{"1":{"17":1}}],["verifying",{"0":{"13":1,"17":1}}],["vectorized",{"1":{"10":1}}],["ve",{"1":{"9":1}}],["y1",{"1":{"70":1}}],["york",{"1":{"60":1}}],["your",{"1":{"8":4,"9":13,"11":1,"12":2,"13":1,"15":1,"17":1,"19":1}}],["you",{"1":{"8":1,"9":8,"12":1,"13":1,"16":3,"17":1,"19":7,"20":1,"23":1,"24":1,"25":2,"28":1,"31":1,"42":1}}],["yet",{"1":{"20":1,"42":1}}],["yes",{"1":{"13":3}}],["yang",{"1":{"7":1}}],["yidan",{"1":{"7":1}}],["x323",{"1":{"70":1}}],["x",{"0":{"51":1},"1":{"47":1,"48":1,"67":3,"70":1}}],["xiaoyu",{"1":{"7":1}}],["xingyu",{"1":{"7":1}}],["xi",{"1":{"7":1}}],["xu",{"1":{"7":2}}],["given",{"1":{"46":1}}],["github",{"1":{"9":1,"18":1,"44":1,"46":1,"48":1,"67":1,"68":1,"70":1}}],["governs",{"1":{"81":1}}],["governance",{"0":{"81":1}}],["goffman",{"1":{"77":1}}],["gomate",{"1":{"70":1}}],["google",{"1":{"48":1}}],["good",{"1":{"42":1,"67":1}}],["goal",{"1":{"44":1,"55":1,"58":1}}],["globe",{"1":{"44":1}}],["glibc",{"1":{"12":3}}],["greatly",{"1":{"68":1}}],["gripper",{"1":{"67":1}}],["gradually",{"1":{"73":1}}],["grained",{"1":{"61":1}}],["graphical",{"1":{"19":4}}],["groupthe",{"1":{"70":1}}],["grouped",{"1":{"57":1}}],["group",{"1":{"22":1}}],["ground",{"1":{"17":1,"23":1,"42":1}}],["groundbreaking",{"1":{"8":1,"44":1,"46":1}}],["gym",{"1":{"19":1}}],["gestures",{"1":{"44":1,"75":1}}],["general",{"0":{"66":1},"1":{"48":1,"66":2},"2":{"67":1,"68":1}}],["generalist",{"1":{"48":1,"51":1}}],["generalize",{"1":{"48":1,"51":1,"57":1}}],["generalization8",{"1":{"67":1}}],["generalization",{"1":{"48":4,"51":1,"55":1,"56":1,"58":1,"59":1,"64":1,"67":2}}],["generally",{"1":{"19":1,"54":1,"68":2}}],["generation",{"1":{"70":2}}],["generating",{"1":{"46":1}}],["generated",{"1":{"48":1,"64":1,"67":1}}],["generate",{"1":{"38":1,"41":1,"67":1}}],["generates",{"1":{"37":2,"67":1}}],["getting",{"0":{"18":1},"2":{"19":1}}],["georgia",{"1":{"7":1}}],["gac",{"1":{"70":1}}],["game",{"1":{"44":3}}],["games",{"1":{"16":2}}],["gathers",{"1":{"44":1}}],["gao",{"1":{"7":1}}],["gpuleverages",{"1":{"68":1}}],["gpus",{"1":{"67":1,"68":7}}],["gpu",{"1":{"12":1,"27":2,"68":12}}],["gpt2",{"1":{"23":2,"42":1}}],["gptafter",{"1":{"9":1}}],["gpts",{"0":{"9":1},"1":{"9":4}}],["gpt",{"0":{"8":1,"23":1},"1":{"8":4,"9":18,"23":1,"25":1,"28":2,"42":1},"2":{"9":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1}}],["g",{"1":{"9":1,"48":1,"50":1,"53":1,"55":1,"58":1,"67":3,"68":9,"76":1}}],["guessing",{"1":{"46":1}}],["guidance",{"1":{"70":1}}],["guided",{"1":{"48":1,"57":1}}],["guides",{"1":{"8":1}}],["guide",{"0":{"11":1},"1":{"8":1,"9":1,"20":1,"42":1},"2":{"12":1,"13":1,"14":1,"15":1,"16":1,"17":1}}],["gui",{"1":{"20":2}}],["guo",{"1":{"7":1}}],["guarantee",{"1":{"2":1}}],["ubtech",{"1":{"70":1}}],["ubuntu",{"1":{"12":1,"16":1}}],["utility",{"1":{"70":1,"76":1}}],["utilizing",{"1":{"44":1,"70":1}}],["utilizes",{"1":{"59":1,"67":1}}],["utilize",{"1":{"4":1}}],["umi",{"1":{"67":1,"68":1}}],["until",{"1":{"80":1}}],["unpacked",{"1":{"76":1}}],["undisclosed",{"1":{"67":2,"70":1}}],["underestimate",{"1":{"81":1}}],["understanding",{"1":{"67":1,"73":1}}],["underrepresented",{"1":{"48":1}}],["under",{"1":{"44":1}}],["unmatched",{"1":{"51":1}}],["unlike",{"1":{"46":1}}],["unfamiliar",{"1":{"46":1}}],["ungrounded",{"1":{"46":1}}],["units",{"1":{"70":2}}],["unifying",{"1":{"64":1}}],["unified",{"1":{"10":2,"44":1,"48":2,"64":1,"67":1}}],["unique",{"1":{"9":1}}],["university",{"1":{"7":15}}],["upper",{"1":{"69":1,"70":1}}],["up",{"1":{"23":1,"67":1,"70":3}}],["upwards",{"1":{"13":1}}],["updateparticlestousd",{"1":{"22":1}}],["updatetousd",{"1":{"22":1}}],["update",{"1":{"12":1}}],["upon",{"1":{"10":1}}],["usability",{"1":{"46":1}}],["usually",{"1":{"44":1,"68":1}}],["usdgeom",{"1":{"22":1}}],["us",{"1":{"20":1,"80":1,"81":1}}],["user",{"1":{"70":1,"76":1}}],["users",{"0":{"7":1},"1":{"9":1,"13":1}}],["used",{"1":{"55":1,"68":1,"70":1}}],["uses",{"1":{"48":2,"65":1,"67":1,"68":1}}],["useful",{"1":{"19":1,"48":1,"62":1}}],["use",{"1":{"9":1,"10":1,"12":2,"13":1,"18":2,"19":1,"20":1,"22":4,"30":1}}],["using",{"1":{"9":2,"12":1,"13":2,"16":2,"17":1,"19":1,"20":2,"23":4,"27":1,"38":1,"44":2,"46":2,"48":3,"52":1,"65":1,"67":2,"68":7}}],["3090",{"1":{"68":1}}],["30",{"1":{"48":1,"60":1,"67":1,"70":1}}],["31",{"1":{"12":1}}],["34+",{"1":{"12":1}}],["3",{"0":{"4":1,"29":1,"52":1},"1":{"12":1,"48":1,"67":1,"70":1}}],["nyc",{"1":{"48":1}}],["nlp",{"1":{"46":2}}],["numpy",{"1":{"22":2}}],["numbers",{"1":{"67":2}}],["number",{"1":{"10":1,"19":1,"48":2}}],["nvidia",{"1":{"10":1,"13":4}}],["noise",{"1":{"55":1}}],["non",{"1":{"48":3,"53":1,"60":1,"73":1}}],["none",{"1":{"16":1}}],["novel",{"1":{"46":1,"64":1}}],["november",{"1":{"46":1}}],["notable",{"1":{"69":2}}],["note",{"1":{"22":1,"47":1,"66":1,"67":1,"69":1}}],["notes",{"1":{"9":1}}],["not",{"1":{"13":1,"20":2,"22":2,"48":2,"55":1,"57":1,"60":1,"62":1,"67":1,"70":2,"73":1,"76":1,"81":1}}],["no",{"1":{"13":1,"20":1,"48":1,"75":1,"81":1,"82":1}}],["now",{"1":{"9":1,"42":1}}],["norms",{"0":{"80":1},"1":{"80":1}}],["normal",{"1":{"7":1}}],["norwegian",{"1":{"70":1}}],["north",{"1":{"7":2}}],["neglecting",{"1":{"44":1}}],["neo",{"1":{"28":1}}],["networks",{"1":{"24":1}}],["neural",{"1":{"24":1}}],["necessary",{"1":{"12":1,"22":1,"44":1}}],["next",{"1":{"12":1,"22":1}}],["need",{"0":{"81":1},"1":{"20":2,"22":4,"44":1,"48":1,"68":1}}],["needed",{"1":{"9":1,"19":1,"22":1,"39":1,"64":1}}],["needs",{"1":{"3":1,"9":1,"10":1,"71":1}}],["new",{"1":{"9":2,"10":1,"44":1,"60":1}}],["naturechen",{"1":{"83":1}}],["nature",{"1":{"78":1}}],["natural",{"1":{"46":2,"48":1,"58":1,"59":1,"70":1}}],["nass",{"1":{"77":1,"83":1}}],["nao",{"1":{"75":1}}],["navigation",{"1":{"10":1,"48":2,"65":1}}],["navigate",{"1":{"9":1}}],["namepre",{"1":{"68":1}}],["namemodel",{"1":{"67":1}}],["namedeveloperdescriptionapplication",{"1":{"70":1}}],["named",{"1":{"25":1}}],["name",{"1":{"9":2,"16":1,"19":1,"25":1}}],["nachosa",{"1":{"84":1}}],["nachos",{"0":{"0":1,"8":1},"1":{"0":1,"8":6,"9":2},"2":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"9":1}}],["w",{"1":{"70":1,"83":1}}],["wrist",{"1":{"48":1,"52":1,"67":1}}],["write",{"1":{"41":1}}],["what",{"1":{"77":1}}],["who",{"1":{"73":1,"81":2}}],["whole",{"1":{"67":1,"68":1}}],["why",{"1":{"22":1}}],["which",{"1":{"19":1,"20":1,"22":1,"44":1,"51":1,"64":1,"70":1,"80":1}}],["while",{"1":{"13":1,"23":1}}],["wheeled",{"1":{"70":9,"71":1}}],["wheels",{"1":{"69":1}}],["wheel",{"0":{"69":1,"70":1},"1":{"69":3,"70":1,"71":1},"2":{"70":1,"71":1}}],["where",{"1":{"19":1,"44":3,"46":1,"73":1,"76":1}}],["when",{"1":{"13":2,"19":1,"20":3,"22":1,"78":1,"81":1}}],["whenever",{"1":{"9":1}}],["whether",{"1":{"8":1,"20":1,"27":1}}],["works",{"1":{"66":2}}],["workspace",{"1":{"15":1}}],["work",{"1":{"44":1,"46":1,"64":1}}],["workaround",{"1":{"22":1}}],["working",{"1":{"10":1}}],["workflows",{"1":{"10":2}}],["workflow",{"1":{"4":1,"20":3,"25":1}}],["worldwide",{"1":{"46":1}}],["world",{"0":{"55":1},"1":{"8":1,"46":1,"47":1,"48":12,"52":1,"53":1,"55":2,"56":1,"59":1,"60":1,"64":1,"65":3,"67":1,"81":1}}],["warns",{"1":{"81":1}}],["warehouse",{"1":{"70":2,"79":1}}],["warehousing",{"1":{"3":1}}],["walker",{"1":{"70":1}}],["way",{"1":{"22":1}}],["was",{"1":{"17":1,"44":3}}],["want",{"1":{"9":1,"16":1}}],["wang",{"1":{"7":3}}],["widowx",{"1":{"48":1,"58":1}}],["widely",{"1":{"44":1,"55":1}}],["wide",{"1":{"8":1,"63":1}}],["wild",{"1":{"48":1,"52":1,"67":2,"68":1}}],["willing",{"1":{"76":1}}],["will",{"1":{"4":1,"9":2,"13":4,"16":1,"27":1,"80":1}}],["wish",{"1":{"28":1}}],["window",{"1":{"13":1,"17":1}}],["windows",{"1":{"12":2,"17":1}}],["without",{"1":{"44":1,"46":1,"65":1}}],["within",{"1":{"4":1,"46":1,"68":2,"80":1}}],["with",{"0":{"23":1,"44":1},"1":{"3":1,"9":2,"12":4,"13":2,"16":1,"17":1,"20":1,"21":1,"23":1,"24":1,"32":1,"35":1,"39":1,"42":2,"43":1,"44":3,"46":1,"48":15,"50":4,"52":1,"53":1,"55":1,"56":1,"57":2,"58":2,"60":1,"61":2,"63":1,"67":10,"68":5,"69":1,"70":15,"71":1,"73":1,"75":1,"77":1,"81":1,"83":1},"2":{"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1}}],["web",{"1":{"70":1}}],["website",{"1":{"48":14,"67":9,"68":9,"70":10}}],["week",{"1":{"68":2}}],["weeks",{"1":{"68":3}}],["well",{"1":{"48":1,"50":1,"55":1,"70":1}}],["welcome",{"1":{"0":1,"84":1}}],["were",{"1":{"44":1}}],["wenbo",{"1":{"7":1}}],["we",{"1":{"2":1,"4":1,"10":1,"12":2,"18":1,"20":3,"22":9,"27":1,"28":1,"29":2,"30":2,"32":2,"33":1,"34":1,"35":1,"37":2,"38":2,"39":1,"40":1,"41":1,"73":1,"76":1,"81":2,"82":1}}],["hybrid",{"1":{"81":1}}],["hyperparameters",{"1":{"42":1}}],["hri",{"1":{"73":1}}],["hsr",{"1":{"70":1}}],["h100",{"1":{"68":1}}],["hierarchy",{"1":{"81":1}}],["hierarchies",{"1":{"80":1}}],["history",{"1":{"67":1}}],["higher",{"1":{"46":1,"70":1}}],["highlighting",{"1":{"69":2}}],["highlights",{"1":{"44":1,"47":1}}],["highly",{"1":{"44":1,"48":1,"68":1}}],["high",{"1":{"44":1,"46":1,"48":5,"58":1,"59":2,"61":2,"64":1,"67":2,"68":7,"70":3,"76":1}}],["hospitals",{"1":{"73":1}}],["hosted",{"1":{"50":1}}],["horizon",{"1":{"48":2,"65":2,"67":1}}],["hony",{"1":{"48":1,"60":1}}],["homes",{"1":{"48":2,"60":1,"73":1}}],["home",{"0":{"84":1},"1":{"48":3,"60":2,"70":2}}],["household",{"1":{"48":3,"57":2,"60":1,"70":2}}],["hoursemphasizes",{"1":{"68":1}}],["hoursuses",{"1":{"68":1}}],["hours",{"1":{"48":4,"52":1,"60":1,"63":1,"67":1,"68":11,"70":1}}],["hoc",{"1":{"46":1}}],["however",{"1":{"22":2}}],["how",{"1":{"8":1,"9":1,"11":1,"18":2,"23":3,"73":1,"76":1,"77":1,"81":1}}],["htmldo",{"1":{"13":1}}],["https",{"1":{"9":1,"13":1,"18":1}}],["hence",{"1":{"76":1}}],["height",{"1":{"70":1}}],["heterogeneity",{"1":{"51":1}}],["heterogeneous",{"1":{"48":2}}],["held",{"1":{"46":1}}],["helps",{"1":{"32":1}}],["head",{"1":{"70":1}}],["headless",{"1":{"19":2,"20":2,"22":1}}],["heavy",{"1":{"56":1}}],["healthcare",{"1":{"0":1,"70":1}}],["here",{"1":{"8":1,"31":1,"39":1}}],["hallucinatory",{"1":{"46":1}}],["hallucinations",{"1":{"46":2}}],["hallucination",{"0":{"45":1,"46":1},"1":{"45":1,"46":2},"2":{"46":1}}],["hardware",{"0":{"68":1},"1":{"48":2,"52":1,"56":1,"58":1,"60":2,"66":2,"67":1,"68":6}}],["hard",{"1":{"23":1,"36":2,"42":1}}],["has",{"1":{"12":1,"20":1,"70":1}}],["have",{"1":{"12":1,"18":1,"24":1,"42":1,"70":3}}],["handle",{"1":{"70":1}}],["handling",{"1":{"50":1,"70":3}}],["handheld",{"1":{"67":1}}],["hand",{"1":{"9":2,"18":1,"44":5}}],["haoran",{"1":{"7":1}}],["haoyang",{"1":{"7":1}}],["hailu",{"1":{"7":1}}],["hundred",{"1":{"68":1}}],["hundreds",{"1":{"48":1,"53":1,"70":1}}],["hugging",{"1":{"23":1,"24":1,"50":1}}],["huining",{"1":{"7":1}}],["hu",{"1":{"7":1}}],["humanoid",{"0":{"69":1,"70":1},"1":{"69":4,"70":12,"71":2},"2":{"70":1,"71":1}}],["humans",{"1":{"44":1,"73":1,"75":1,"77":2,"81":1,"82":1}}],["human",{"0":{"72":1,"74":1,"81":1},"1":{"3":2,"44":12,"46":1,"48":3,"53":3,"54":1,"70":5,"71":1,"72":1,"73":2,"75":3,"77":1,"80":2},"2":{"73":1,"74":1,"75":2,"76":2,"77":2,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["lcd",{"1":{"70":1}}],["lts",{"1":{"12":1}}],["ldd",{"1":{"12":1}}],["llm",{"1":{"67":1,"68":1}}],["llms",{"0":{"45":1},"1":{"46":4},"2":{"46":1}}],["llama",{"1":{"67":1}}],["ll",{"1":{"9":1,"23":1}}],["lora",{"1":{"68":1}}],["loop",{"0":{"37":1},"1":{"48":1,"53":1}}],["logisticsmoves",{"1":{"70":1}}],["logistics",{"1":{"69":1,"70":3,"71":1}}],["logic",{"1":{"42":1}}],["logits",{"1":{"36":1,"37":2}}],["logged",{"1":{"9":1}}],["load",{"1":{"24":1,"29":1,"70":2}}],["loading",{"0":{"29":1,"30":1,"33":1},"1":{"23":1}}],["losses",{"1":{"36":1}}],["loss",{"0":{"36":1},"1":{"23":2,"35":1,"36":4,"37":1,"42":1}}],["located",{"1":{"20":1}}],["locate",{"1":{"19":1}}],["locomotion",{"1":{"10":1,"71":1}}],["longer",{"1":{"75":1,"81":1,"82":1}}],["long",{"1":{"7":1,"28":1,"48":2,"65":2,"67":1}}],["lowering",{"1":{"53":1}}],["lower",{"1":{"50":1}}],["low",{"1":{"3":1,"44":1,"53":1,"60":1,"67":2,"68":3}}],["likable",{"1":{"77":1}}],["like",{"1":{"8":1,"28":1,"70":1,"77":1,"80":1}}],["lifeawad",{"1":{"83":1}}],["life",{"1":{"70":1,"75":1,"77":1}}],["lightweight",{"1":{"67":1}}],["licensing",{"1":{"61":1}}],["license",{"0":{"5":1},"1":{"13":3}}],["limitations",{"1":{"70":2}}],["limit",{"1":{"48":1,"65":1,"70":1}}],["limits",{"1":{"48":1}}],["limited",{"1":{"20":1,"48":2,"52":1,"54":1,"55":1,"70":4}}],["libraries",{"1":{"23":1}}],["linguistics",{"1":{"46":2}}],["lines",{"1":{"20":1}}],["line",{"1":{"20":2}}],["linux",{"1":{"12":3}}],["list",{"1":{"10":2}}],["live",{"1":{"9":1}}],["li",{"1":{"7":3}}],["luck",{"1":{"42":1}}],["lu",{"1":{"7":1}}],["legal",{"1":{"82":1}}],["legibility",{"1":{"76":1}}],["leg",{"1":{"70":1}}],["legged",{"1":{"10":1}}],["lerobot",{"0":{"50":1},"1":{"47":1,"48":1,"50":1}}],["least",{"1":{"68":1}}],["lead",{"1":{"80":1}}],["leaders",{"1":{"46":1}}],["leading",{"1":{"44":1,"46":1}}],["learn",{"1":{"8":1,"11":1,"63":1}}],["learningexperience",{"1":{"79":1}}],["learning",{"0":{"44":1},"1":{"3":1,"8":1,"10":4,"16":1,"18":2,"20":2,"24":1,"39":1,"42":1,"43":1,"44":4,"48":17,"50":2,"51":1,"52":1,"53":1,"54":2,"55":2,"57":1,"58":1,"60":2,"61":2,"62":2,"63":1,"67":4,"68":3}}],["leibler",{"1":{"36":1}}],["less",{"1":{"32":1,"44":2,"48":4,"62":1,"70":1}}],["leverages",{"1":{"18":1,"48":1,"53":1,"64":1,"67":1}}],["leverage",{"1":{"10":1,"68":1}}],["level",{"1":{"9":1,"68":1,"70":1,"82":2}}],["left",{"1":{"9":2}}],["led",{"0":{"3":1},"1":{"3":1}}],["lack",{"1":{"80":1}}],["lacking",{"1":{"70":1}}],["layers",{"1":{"76":1}}],["layered",{"1":{"2":1}}],["landscape",{"1":{"71":1}}],["languages",{"1":{"70":1}}],["language",{"0":{"46":1},"1":{"28":1,"45":1,"46":4,"48":6,"57":3,"58":2,"59":1,"64":1,"65":1,"67":9,"68":1}}],["last",{"1":{"47":1,"66":1,"69":1,"81":1}}],["latency",{"1":{"44":2,"53":1}}],["latest",{"1":{"10":1,"12":1,"13":1}}],["larger",{"1":{"62":1,"68":1,"70":1}}],["largest",{"1":{"54":1}}],["largely",{"1":{"48":1,"64":1}}],["large",{"0":{"46":1},"1":{"19":1,"45":1,"46":2,"48":10,"51":1,"52":1,"62":2,"63":1,"67":5,"68":4,"70":1,"81":1}}],["launch",{"1":{"13":1,"17":1}}],["launching",{"1":{"3":1}}],["labelsmoothingcrossentropy",{"1":{"35":1}}],["labels",{"1":{"23":1,"42":2}}],["label",{"0":{"35":1},"1":{"23":1,"35":1,"36":2}}],["labeled",{"1":{"9":1}}],["lab",{"0":{"15":1,"17":1},"1":{"10":3,"11":1,"12":1,"15":1,"18":2,"20":4,"22":5}}],["labor",{"1":{"3":1}}],["error",{"1":{"80":1}}],["ecologymulti",{"1":{"79":1}}],["equationgoffman",{"1":{"83":1}}],["equation",{"1":{"77":1}}],["equipped",{"1":{"70":1}}],["either",{"1":{"77":1}}],["ethics",{"1":{"83":1}}],["ethically",{"1":{"83":1}}],["ethical",{"0":{"76":1},"1":{"76":2,"82":1}}],["et",{"1":{"83":2}}],["etc",{"1":{"31":1,"42":1}}],["elder",{"1":{"75":1}}],["elderly",{"1":{"70":2}}],["elephant",{"1":{"70":1}}],["elevators",{"1":{"67":1}}],["elevate",{"1":{"8":1}}],["eyes",{"1":{"70":1}}],["especially",{"1":{"48":1}}],["establish",{"0":{"3":1},"1":{"4":1}}],["episodes",{"1":{"48":1,"59":1}}],["epochs",{"1":{"37":1,"39":1,"42":1}}],["emerge",{"1":{"80":1}}],["emergent",{"1":{"79":1}}],["emergence",{"0":{"72":1,"78":1},"1":{"72":1,"73":1},"2":{"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":2,"80":2,"81":2,"82":1,"83":1}}],["embodied",{"1":{"70":1}}],["embodiments",{"1":{"48":1,"51":2}}],["embodiment",{"0":{"51":1},"1":{"47":1,"48":2,"67":2}}],["emotion",{"1":{"70":2}}],["emnlp",{"1":{"46":3}}],["emphasize",{"1":{"76":1}}],["emphasizes",{"1":{"65":1}}],["emphasis",{"1":{"56":1}}],["empirical",{"1":{"46":2}}],["empty",{"1":{"13":1}}],["efold",{"1":{"44":7}}],["efforts",{"1":{"76":1}}],["effort",{"1":{"44":1,"51":1}}],["effectively",{"1":{"65":1}}],["effectiveness",{"1":{"53":1,"70":1}}],["effective",{"1":{"48":2,"60":1,"63":1,"70":1}}],["effects",{"1":{"44":4}}],["effect",{"0":{"44":1},"1":{"43":1,"44":3}}],["efficiency",{"1":{"22":1,"64":1,"68":1,"69":1,"71":1}}],["efficiently",{"1":{"44":1}}],["efficient",{"1":{"4":1,"10":1,"44":2,"48":1,"67":3,"68":9}}],["eos",{"1":{"30":1}}],["evoke",{"1":{"76":1}}],["evolutionary",{"1":{"79":1}}],["evolution",{"0":{"76":1}}],["evolves",{"1":{"73":1}}],["evolve",{"1":{"71":1,"80":1}}],["evolving",{"1":{"3":1,"82":1}}],["everyday",{"1":{"75":1,"83":1}}],["eve",{"1":{"70":1}}],["even",{"1":{"68":1,"71":1,"77":2}}],["evaluates",{"1":{"46":1}}],["evaluated",{"1":{"44":1,"46":1}}],["evaluation",{"0":{"38":1}}],["evaluating",{"1":{"23":1,"48":1,"55":1,"62":1}}],["education",{"1":{"70":2,"83":1}}],["educational",{"1":{"70":2,"75":1}}],["editing",{"1":{"19":1}}],["editable",{"1":{"16":1}}],["edge",{"1":{"8":1,"44":1}}],["eula",{"1":{"13":3}}],["e",{"0":{"60":1},"1":{"9":1,"47":1,"48":2,"50":1,"53":1,"55":1,"58":1,"60":1,"67":4,"68":9,"76":1,"83":2}}],["exclusionary",{"1":{"81":1}}],["excellent",{"1":{"67":2}}],["exhibit",{"1":{"81":1}}],["exhibitions",{"1":{"70":1}}],["exhibits",{"1":{"67":1}}],["execution",{"1":{"67":3}}],["execute",{"1":{"19":1}}],["exact",{"1":{"67":2}}],["examples",{"1":{"19":1,"20":1,"32":1,"75":1}}],["example",{"1":{"9":2,"16":1}}],["existential",{"1":{"76":1}}],["existing",{"1":{"46":1}}],["exit",{"1":{"17":1}}],["extra",{"1":{"65":1}}],["extracted",{"1":{"46":1}}],["extraction",{"1":{"44":1,"46":1}}],["extremely",{"1":{"48":1,"61":1}}],["exterior",{"1":{"52":1}}],["external",{"1":{"9":1,"44":1,"46":1}}],["extension",{"1":{"20":1}}],["extensions",{"1":{"9":1,"13":3,"16":2}}],["extensively",{"1":{"62":1}}],["extensive",{"1":{"20":1,"48":1,"52":1,"59":1,"61":1,"68":1}}],["extend",{"1":{"9":1,"10":1}}],["expressions",{"1":{"75":1}}],["explicitly",{"1":{"67":1}}],["explanation",{"0":{"26":1},"2":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1}}],["explainability",{"1":{"76":1}}],["explains",{"1":{"23":1}}],["explained",{"0":{"22":1},"1":{"25":1}}],["exploring",{"1":{"72":1}}],["explores",{"1":{"77":1}}],["explore",{"1":{"8":1,"9":4}}],["exploration",{"1":{"8":1,"44":1,"65":1}}],["expedition",{"1":{"70":1}}],["expected",{"1":{"13":1,"71":1}}],["experts",{"1":{"53":1}}],["expert",{"1":{"48":2,"60":1,"67":1}}],["expertise",{"1":{"8":1,"50":1,"59":1}}],["experiments24",{"1":{"70":1}}],["experiment",{"1":{"42":1,"83":1}}],["experimental",{"1":{"12":1,"80":1}}],["experience",{"1":{"13":3,"48":2,"56":1,"63":1,"70":1}}],["expand",{"1":{"9":1}}],["early",{"1":{"78":1}}],["earned",{"1":{"76":1}}],["easy",{"1":{"67":1}}],["easily",{"1":{"10":1}}],["east",{"1":{"7":1}}],["each",{"1":{"4":1,"13":1,"22":3,"25":1,"37":1,"47":1}}],["encodes",{"1":{"67":1}}],["encoder",{"1":{"67":1}}],["encounters",{"1":{"83":1}}],["encounter",{"1":{"12":1}}],["enormous",{"1":{"61":1}}],["engineered",{"1":{"80":1}}],["engineering",{"1":{"46":1,"59":1,"82":1}}],["english",{"1":{"25":1}}],["ensuring",{"1":{"46":1}}],["ensures",{"1":{"27":1}}],["ensure",{"1":{"2":1,"3":1,"9":2,"12":3,"24":1,"30":1}}],["enhances",{"1":{"70":1}}],["enhance",{"1":{"44":1}}],["enhancing",{"1":{"4":1,"46":1}}],["end",{"0":{"44":1},"1":{"43":1,"44":7,"48":2,"50":2,"68":1}}],["enabling",{"0":{"20":1},"1":{"48":2,"53":1},"2":{"21":1,"22":1}}],["enables",{"1":{"44":1,"48":1,"53":1,"67":3}}],["enabled",{"1":{"12":1,"19":1,"20":1}}],["enable",{"1":{"9":2,"19":1,"20":2,"22":1,"52":1}}],["env",{"1":{"22":2}}],["envs",{"1":{"19":1,"22":1}}],["environment",{"1":{"12":2,"13":1,"19":1,"22":2,"23":1}}],["environmentscapable",{"1":{"70":1}}],["environments10",{"1":{"68":1}}],["environments",{"1":{"10":5,"19":2,"44":1,"48":5,"50":2,"55":2,"58":2,"60":1,"70":2}}],["enter",{"1":{"73":1}}],["enterprise",{"1":{"9":1}}],["enterprises",{"0":{"4":1},"1":{"70":1}}],["entropy",{"1":{"35":1}}],["entities",{"1":{"46":1}}],["entity",{"1":{"4":1}}],["entirely",{"1":{"65":2}}],["entire",{"1":{"23":1,"33":1}}],["2b",{"1":{"68":1}}],["2bpre",{"1":{"67":1}}],["2m",{"1":{"67":1}}],["25",{"1":{"67":1}}],["250",{"1":{"58":1}}],["27mocto",{"1":{"67":1}}],["249",{"1":{"67":1}}],["24",{"1":{"48":1,"58":1}}],["22",{"1":{"48":2,"51":1,"60":1,"68":1}}],["28",{"1":{"47":1,"48":1,"57":1,"66":1}}],["21",{"1":{"51":1}}],["214",{"1":{"20":1}}],["213",{"1":{"20":1}}],["2019",{"1":{"83":1}}],["2018",{"1":{"83":2}}],["200m",{"1":{"67":1}}],["2023",{"1":{"83":1}}],["2021",{"1":{"70":1,"83":1}}],["2025",{"1":{"47":1,"66":1,"69":1}}],["2024",{"1":{"20":1,"46":2}}],["20",{"1":{"12":1,"70":1}}],["26",{"1":{"10":1}}],["2",{"0":{"3":1,"28":1,"51":1},"1":{"12":3,"48":1,"67":2,"68":1,"70":1,"73":1}}],["rb",{"1":{"70":1}}],["rdt",{"1":{"67":1,"68":1}}],["rgb",{"1":{"48":6,"58":1,"60":1,"61":1,"65":4,"67":1}}],["richness",{"1":{"62":1}}],["rich",{"1":{"48":3,"52":1,"53":1,"57":1,"61":3,"68":1}}],["rh20t",{"0":{"61":1},"1":{"47":1,"48":1,"61":1}}],["rtx",{"1":{"68":1}}],["rtx4090",{"1":{"68":2}}],["rt",{"0":{"59":1},"1":{"47":1,"48":1,"59":1,"67":1,"68":1}}],["rsj",{"1":{"44":1}}],["rsl",{"1":{"16":1,"19":2,"20":3}}],["rapport",{"1":{"75":1}}],["rapid",{"1":{"48":1,"50":1,"60":1,"63":1}}],["rainbow",{"1":{"70":1}}],["rare",{"1":{"63":1}}],["rad",{"1":{"44":1}}],["rather",{"1":{"44":1,"46":1}}],["rates",{"1":{"42":1}}],["rate",{"1":{"39":1,"42":1,"67":1}}],["randomized",{"1":{"48":1}}],["randomization",{"1":{"10":1}}],["random",{"1":{"31":1}}],["range",{"1":{"8":1,"68":1}}],["rlbench",{"1":{"67":1}}],["rl",{"1":{"16":3,"18":1,"19":3,"20":6,"21":1,"22":2,"48":2,"55":1,"63":1}}],["rules",{"1":{"80":1}}],["runners",{"1":{"20":1}}],["runner",{"1":{"20":1}}],["running",{"0":{"39":1},"1":{"10":1,"12":1,"13":1,"19":2,"20":3}}],["runthe",{"1":{"16":1}}],["runs",{"1":{"13":2}}],["run",{"1":{"12":1,"13":5,"16":1,"17":1,"19":1,"20":1,"25":1,"37":1}}],["ruoxu",{"1":{"7":1}}],["rooted",{"1":{"77":1}}],["rochester",{"1":{"7":1}}],["role",{"1":{"4":1}}],["roles",{"1":{"4":1,"76":1}}],["roboset",{"0":{"57":1},"1":{"47":1,"48":1,"57":1}}],["robonet",{"0":{"56":1},"1":{"47":1,"48":1,"56":1}}],["robomimic",{"1":{"16":1}}],["roboturk",{"0":{"53":1},"1":{"47":1,"48":1,"53":1}}],["robot",{"0":{"3":1,"66":1,"67":1,"72":1,"74":1,"79":1},"1":{"2":1,"3":2,"4":3,"10":2,"44":4,"48":15,"50":1,"51":3,"52":1,"54":1,"56":2,"64":1,"66":2,"67":10,"68":3,"70":17,"71":1,"72":1,"73":1,"75":2,"76":4,"77":2,"79":1,"80":1,"81":2},"2":{"67":1,"68":1,"73":1,"74":1,"75":2,"76":2,"77":2,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["robots",{"0":{"69":1,"70":1,"82":1},"1":{"2":1,"3":2,"4":1,"10":1,"44":1,"48":5,"50":1,"51":1,"52":2,"59":1,"63":1,"67":1,"68":1,"69":3,"70":2,"71":2,"73":1,"75":3,"76":2,"77":1,"78":1,"80":1,"82":1,"83":1},"2":{"70":1,"71":1}}],["robotic",{"0":{"2":1,"4":1,"72":1,"78":1},"1":{"0":1,"2":1,"3":1,"8":2,"18":1,"44":4,"48":5,"53":1,"56":1,"57":1,"58":1,"59":1,"62":1,"63":1,"67":1,"73":1,"76":1,"81":2,"82":2},"2":{"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":2,"80":2,"81":2,"82":1,"83":1}}],["roboticsieee",{"1":{"83":1}}],["roboticsa",{"1":{"70":7}}],["robotics",{"0":{"47":1},"1":{"0":2,"8":5,"10":2,"44":2,"47":2,"48":2,"50":2,"60":1,"71":1,"84":1},"2":{"48":1,"49":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1}}],["robustness",{"1":{"2":1,"10":1,"46":1,"48":1,"52":1}}],["robust",{"0":{"2":1},"1":{"48":2,"52":1,"65":1}}],["review",{"1":{"83":1}}],["reward",{"1":{"80":1}}],["reeves",{"1":{"77":1,"83":1}}],["requiring",{"1":{"46":1,"70":2}}],["requirements8",{"1":{"68":1}}],["requirements",{"0":{"68":1},"1":{"48":2,"66":2,"68":3}}],["require",{"1":{"48":2,"68":2}}],["required",{"1":{"12":2,"13":1}}],["requires",{"1":{"12":1,"48":1,"56":1,"63":1,"68":3}}],["references",{"0":{"83":1}}],["reflex",{"1":{"70":2}}],["refrains",{"1":{"46":1}}],["refinement",{"1":{"9":1}}],["refine",{"1":{"9":1}}],["recent",{"1":{"66":2,"76":1}}],["recreate",{"1":{"44":2}}],["recognition",{"1":{"48":1,"70":3,"80":1}}],["recognized",{"1":{"44":1}}],["recommendation",{"1":{"83":1}}],["recommendations",{"1":{"8":1}}],["recommended",{"1":{"19":1}}],["recommend",{"1":{"12":2}}],["recorded",{"1":{"48":2}}],["record",{"1":{"4":1,"22":1}}],["recovery",{"1":{"2":1,"65":1}}],["reducing",{"1":{"44":1}}],["reduces",{"1":{"44":1,"70":1}}],["reduce",{"1":{"29":1,"68":1}}],["redefines",{"1":{"44":1}}],["rethink",{"1":{"82":1}}],["retail",{"1":{"70":5}}],["retaining",{"1":{"23":1}}],["retrieving",{"1":{"20":1}}],["retrieve",{"1":{"20":1,"22":1}}],["returns",{"1":{"31":1}}],["return",{"1":{"9":1}}],["regardless",{"1":{"20":1}}],["registration",{"1":{"19":1}}],["registry",{"1":{"13":1}}],["register",{"1":{"19":1}}],["registered",{"1":{"19":2}}],["reputation",{"1":{"80":1}}],["repertoire",{"1":{"63":1}}],["reposting",{"1":{"83":1}}],["repository",{"1":{"9":1,"15":1,"17":1,"19":2}}],["report",{"1":{"47":1}}],["representation",{"1":{"67":1}}],["represent",{"1":{"44":1,"71":1}}],["replicate",{"1":{"44":1}}],["replace",{"1":{"35":1}}],["replacements",{"1":{"31":1}}],["reply",{"1":{"13":1}}],["relationship",{"1":{"75":1}}],["relatively",{"1":{"67":2,"68":2}}],["related",{"1":{"44":1,"46":1}}],["release",{"1":{"12":1}}],["reliably",{"1":{"76":1}}],["reliable",{"1":{"2":1}}],["reliability",{"0":{"76":1},"1":{"3":1,"46":1,"70":1}}],["rendering",{"1":{"10":2}}],["remarks1",{"1":{"67":1,"68":1}}],["remarks",{"1":{"67":1}}],["remains",{"1":{"80":1}}],["remain",{"1":{"10":1}}],["remove",{"1":{"32":1}}],["remote",{"1":{"8":1,"44":1,"67":1,"70":2}}],["rescue",{"1":{"79":1}}],["result",{"1":{"70":1}}],["results",{"1":{"44":1}}],["responsibility",{"1":{"82":1}}],["responsible",{"1":{"81":1}}],["response",{"1":{"44":1}}],["responses",{"1":{"9":1,"46":1}}],["responds",{"1":{"70":1}}],["resolution",{"1":{"48":1,"61":1}}],["resolve",{"1":{"20":1}}],["resources",{"1":{"46":1,"48":1}}],["resource",{"0":{"46":1},"1":{"45":1,"46":2,"62":1,"67":1,"68":4}}],["resemble",{"1":{"78":1}}],["reset",{"1":{"20":1}}],["researchers",{"1":{"44":1,"46":1}}],["research",{"1":{"10":2,"44":2,"46":1,"50":2,"61":1,"69":1,"70":5,"71":1}}],["readings",{"0":{"83":1}}],["ready",{"1":{"9":1,"10":1}}],["reasoning",{"1":{"67":2,"68":1}}],["realistic",{"1":{"10":1,"48":1}}],["realize",{"0":{"4":1}}],["real",{"0":{"43":1,"44":1},"1":{"3":1,"8":1,"9":2,"43":1,"44":2,"46":1,"48":16,"50":1,"52":1,"53":2,"55":1,"56":1,"59":2,"60":1,"64":1,"65":4,"67":1,"81":2},"2":{"44":1}}],["reusable",{"1":{"8":1}}],["reinforcement",{"1":{"8":1,"10":1,"18":2,"20":2,"44":2,"48":3,"50":1,"55":1,"63":1}}],["re",{"1":{"8":1,"9":1}}],["d",{"1":{"67":1}}],["dynamically",{"1":{"70":1}}],["dynamic",{"1":{"67":1,"77":1}}],["dynamicsa",{"1":{"70":1}}],["dynamics",{"1":{"50":1,"55":1,"76":1,"80":1,"82":1}}],["daily",{"1":{"77":1}}],["dance",{"1":{"70":1}}],["daycombines",{"1":{"68":1}}],["daylarge",{"1":{"68":1}}],["day",{"1":{"68":4}}],["dayadaptable",{"1":{"68":1}}],["daysoffers",{"1":{"68":1}}],["days",{"1":{"67":1,"68":3}}],["date",{"1":{"47":1,"66":1,"69":1}}],["data4",{"1":{"68":1}}],["datadata",{"1":{"67":1}}],["dataprovides",{"1":{"67":1}}],["databased",{"1":{"67":1}}],["database",{"1":{"48":1,"56":1}}],["databases",{"1":{"9":1}}],["dataloaders",{"1":{"34":1}}],["dataloader",{"0":{"34":1}}],["datasetextends",{"1":{"67":1}}],["dataset",{"0":{"33":1,"47":1},"1":{"33":2,"46":1,"47":1,"48":5,"50":1,"52":2,"53":2,"57":1,"59":1,"60":2,"61":1,"62":1},"2":{"48":1,"49":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1}}],["datasets",{"1":{"24":2,"47":2,"48":4,"50":1,"51":1,"53":1,"54":1,"62":2,"67":2}}],["data",{"0":{"31":1,"32":1},"1":{"9":4,"22":1,"23":1,"42":1,"48":18,"50":1,"51":2,"53":1,"54":1,"56":4,"58":2,"59":1,"60":1,"61":3,"63":1,"66":1,"67":11,"68":11}}],["dual",{"1":{"70":2}}],["duration",{"1":{"68":1}}],["during",{"1":{"19":2,"20":1,"37":1,"44":3}}],["due",{"1":{"53":1,"68":1}}],["duplicating",{"1":{"22":1}}],["duplicated",{"1":{"22":1}}],["do",{"1":{"81":1,"82":1}}],["down",{"1":{"79":1}}],["downstream",{"1":{"67":1}}],["done",{"1":{"68":3}}],["dof",{"1":{"67":1,"68":1}}],["doors",{"1":{"67":1}}],["dominant",{"1":{"79":1}}],["domestic",{"1":{"48":2,"60":1}}],["domains",{"1":{"76":1}}],["domain",{"1":{"10":1,"48":3,"57":1,"60":1}}],["dobb",{"0":{"60":1},"1":{"47":1,"48":1,"60":1}}],["documented",{"1":{"55":1,"62":1}}],["documentation",{"1":{"13":1,"48":1}}],["docs",{"1":{"13":1}}],["doesn",{"1":{"22":1,"80":1}}],["does",{"1":{"13":1,"20":1,"22":1,"76":3}}],["dramaturgical",{"1":{"77":1}}],["drone",{"1":{"81":1}}],["droid",{"0":{"52":1},"1":{"47":1,"48":1,"52":1}}],["dropout",{"0":{"29":1},"1":{"29":1,"42":1}}],["drl",{"1":{"44":2}}],["dr",{"1":{"7":11}}],["driven",{"1":{"50":1,"79":1}}],["driver",{"1":{"12":1}}],["drive",{"1":{"0":1,"65":1}}],["dimensions",{"0":{"74":1},"1":{"72":1,"73":1},"2":{"75":1,"76":1,"77":1}}],["dialogue",{"1":{"70":1}}],["diagnostic",{"1":{"2":1}}],["dinov2",{"1":{"67":1}}],["ding",{"1":{"7":1}}],["diffusion",{"1":{"50":1,"67":3}}],["differences",{"1":{"53":1}}],["differently",{"1":{"80":1}}],["different",{"1":{"46":1,"51":2,"56":2,"67":1,"68":1,"70":1}}],["differ",{"1":{"20":1}}],["diverse",{"1":{"48":7,"50":1,"51":1,"52":1,"59":1,"61":2,"64":1}}],["diversitylow",{"1":{"67":1}}],["diversity",{"1":{"48":3,"51":1,"54":1,"58":1,"62":1}}],["divergence",{"1":{"36":1}}],["dictionary",{"1":{"40":1}}],["directly",{"1":{"22":1}}],["direct",{"1":{"20":2,"22":1,"23":1}}],["directory",{"1":{"16":1,"20":1}}],["disembodied",{"1":{"77":1}}],["discrete",{"1":{"68":1}}],["discretized",{"1":{"59":1,"67":1}}],["disclosedapproximately",{"1":{"67":1}}],["disclosedpre",{"1":{"67":1}}],["disclosedrapid",{"1":{"67":1}}],["disclosed",{"1":{"67":2}}],["discuss",{"1":{"44":1}}],["disabled",{"1":{"70":1}}],["disables",{"1":{"19":1}}],["disadvantages1",{"1":{"48":1}}],["disadvantages",{"1":{"47":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"69":2}}],["distinct",{"1":{"48":1,"55":1}}],["distilgpt2",{"1":{"23":2,"42":1}}],["distilled",{"1":{"23":1}}],["distillation",{"0":{"36":1,"68":1},"1":{"23":2,"25":1,"36":1,"37":1,"42":1,"66":2,"68":3}}],["distill",{"1":{"23":2,"25":1}}],["distilling",{"0":{"23":1},"1":{"42":2},"2":{"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1}}],["distributions",{"1":{"12":2}}],["distribution",{"1":{"4":1}}],["display",{"1":{"17":1}}],["diego",{"1":{"7":2}}],["delivery",{"1":{"81":1}}],["delivered",{"1":{"70":1}}],["delegate",{"1":{"76":1}}],["decision",{"1":{"76":1}}],["decisions",{"1":{"76":1}}],["decoder",{"1":{"65":1}}],["degrees",{"1":{"70":1}}],["derived",{"1":{"42":1}}],["deep",{"1":{"24":1,"44":2}}],["devices",{"1":{"68":1}}],["device",{"0":{"27":1},"1":{"20":1,"34":1}}],["develops",{"1":{"80":1}}],["developed",{"1":{"70":1}}],["developers",{"1":{"69":2}}],["developing",{"1":{"3":1}}],["develop",{"0":{"2":1},"1":{"4":1,"81":1}}],["debug",{"1":{"13":1}}],["depending",{"1":{"67":1,"68":2}}],["dependencies",{"1":{"16":1}}],["dependent",{"1":{"13":1}}],["depth",{"1":{"48":4,"58":1,"60":1,"61":1}}],["deployed",{"1":{"48":1,"65":1}}],["deployment",{"0":{"19":1},"1":{"64":1}}],["deploy",{"1":{"9":1}}],["defining",{"1":{"34":1}}],["defined6",{"1":{"68":1}}],["define",{"1":{"4":1,"9":1,"28":1,"37":1,"79":1}}],["default",{"1":{"12":1,"13":1,"16":1}}],["demand",{"1":{"50":1,"68":1}}],["demands",{"1":{"3":1,"48":1,"59":1}}],["democratic",{"1":{"80":1,"82":1}}],["demos",{"1":{"48":2,"67":1,"68":2}}],["demo",{"1":{"48":1,"67":1}}],["demonstration",{"1":{"48":4,"60":2,"61":1,"67":4,"68":2}}],["demonstrationslarge",{"1":{"67":1}}],["demonstrationsnot",{"1":{"67":1}}],["demonstrations",{"1":{"10":1,"48":3,"53":4,"54":1,"57":1,"58":1,"60":1,"67":5}}],["demonstrating",{"1":{"23":1}}],["demonstrates",{"1":{"59":1,"60":1,"63":1}}],["demonstrated",{"1":{"44":1,"48":2,"64":1}}],["demonstrate",{"1":{"18":2}}],["determine",{"1":{"46":1}}],["detecting",{"1":{"46":1}}],["detection10",{"1":{"67":1}}],["detection",{"1":{"2":1,"46":1,"65":1}}],["detect",{"1":{"27":1}}],["details",{"1":{"48":1,"62":1,"70":1}}],["detailed",{"0":{"49":1},"1":{"47":1,"48":1,"54":1,"61":1},"2":{"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1}}],["detail",{"1":{"9":1}}],["desk",{"1":{"70":2}}],["descriptive",{"1":{"67":1}}],["descriptions",{"1":{"47":1,"69":2}}],["description",{"1":{"9":1}}],["descriptionprovide",{"1":{"9":1}}],["despite",{"1":{"65":1}}],["desired",{"1":{"23":1,"39":1}}],["designunesco",{"1":{"83":1}}],["designed",{"1":{"48":2,"50":1,"58":1,"60":1,"63":1,"67":1,"70":2,"75":1}}],["design",{"1":{"19":1,"67":1,"68":1,"70":4,"76":1,"79":1,"81":1,"82":1}}],["designing",{"1":{"2":1}}],["dexterous",{"0":{"43":1,"44":1},"1":{"8":1,"10":1,"43":1,"44":2,"61":1},"2":{"44":1}}],["denver",{"1":{"7":1}}],["1959",{"1":{"83":1}}],["1996",{"1":{"83":1}}],["1x",{"1":{"70":2}}],["1m",{"1":{"67":1}}],["1m+",{"1":{"48":1,"51":1}}],["1b",{"1":{"67":1,"68":1}}],["16gb",{"1":{"68":1}}],["16",{"0":{"41":1,"65":1},"1":{"46":1,"47":2,"48":1,"68":1}}],["15m",{"1":{"56":1}}],["15",{"0":{"41":1,"64":1},"1":{"48":1,"67":1,"68":1,"70":1}}],["14",{"0":{"40":1,"63":1},"1":{"48":1}}],["130k",{"1":{"48":1,"59":1}}],["13",{"0":{"39":1,"62":1},"1":{"48":4,"58":1,"59":1,"60":1}}],["11s",{"1":{"44":1}}],["114",{"1":{"20":1}}],["11",{"0":{"37":1,"60":1},"1":{"20":1,"48":1,"70":1}}],["100",{"1":{"70":1}}],["10k+",{"1":{"67":1,"68":1}}],["10",{"0":{"36":1,"59":1},"1":{"12":1,"13":1,"32":1,"33":1,"48":1,"67":1,"70":1}}],["12b",{"1":{"68":1}}],["12bor",{"1":{"67":1}}],["12",{"0":{"38":1,"61":1},"1":{"12":1,"46":1,"48":2,"63":1}}],["1",{"0":{"2":1,"27":1,"50":1,"59":1},"1":{"47":1,"48":1,"59":1,"68":1,"70":1,"73":1}}],["b",{"1":{"83":1}}],["bias",{"1":{"81":1}}],["bipedal",{"1":{"70":1}}],["billions",{"1":{"67":1}}],["bimanual",{"1":{"67":3,"68":1}}],["bind",{"1":{"22":1}}],["binaries",{"1":{"12":1}}],["boundaries",{"1":{"82":1}}],["boundary",{"1":{"80":1}}],["bots",{"1":{"80":1}}],["botsbehavioral",{"1":{"79":1}}],["botsstructuralism",{"1":{"79":1}}],["both",{"1":{"29":1,"34":1,"38":1,"41":1,"48":1,"50":1,"53":1,"57":1,"58":1,"63":1,"68":1,"70":1}}],["boston",{"1":{"70":1}}],["body",{"1":{"67":1,"68":1,"69":1,"70":2}}],["boosting",{"1":{"63":1}}],["boost",{"1":{"58":1}}],["boosts",{"1":{"52":1}}],["bc",{"0":{"62":1},"1":{"47":1,"48":2,"62":2}}],["bridgedata",{"0":{"58":1},"1":{"47":1,"48":1,"58":1}}],["brief",{"1":{"9":1}}],["broader",{"1":{"46":1}}],["blocks",{"1":{"25":1}}],["blockchain",{"1":{"4":1}}],["black",{"1":{"17":1}}],["barrier",{"1":{"48":1,"50":1}}],["backpropagate",{"1":{"37":1}}],["backend",{"1":{"22":1}}],["batch",{"1":{"37":1,"42":1}}],["battery",{"1":{"10":1,"70":1}}],["base",{"0":{"28":1},"1":{"67":2,"70":3}}],["based",{"0":{"44":1,"69":1,"70":1},"1":{"4":1,"12":1,"20":1,"22":1,"43":1,"44":2,"48":1,"51":1,"59":1,"64":1,"65":1,"67":6,"69":3,"71":1},"2":{"70":1,"71":1}}],["basic",{"1":{"24":1,"70":1,"73":1}}],["balances",{"1":{"36":1,"42":1}}],["balance",{"1":{"23":1}}],["baicheng",{"1":{"7":1}}],["budget",{"1":{"70":1}}],["build",{"1":{"12":1,"75":1}}],["building",{"1":{"8":1,"24":1}}],["built",{"1":{"10":1,"50":1,"63":1}}],["buffalo",{"1":{"7":1}}],["button",{"1":{"9":1}}],["but",{"1":{"3":1,"12":1,"22":1,"25":1,"48":1,"68":1,"76":1,"80":1,"81":2}}],["business",{"0":{"3":1},"1":{"0":1,"3":1,"4":3}}],["by",{"1":{"2":1,"8":2,"9":1,"10":1,"12":1,"13":2,"16":1,"17":1,"19":3,"20":1,"22":1,"23":1,"36":1,"42":1,"44":4,"46":1,"50":1,"65":1,"70":1}}],["becoming",{"0":{"82":1},"1":{"82":1}}],["become",{"1":{"71":1,"76":1,"80":1}}],["bellow",{"1":{"66":1}}],["belonging",{"1":{"82":1}}],["belongs",{"1":{"22":1}}],["below",{"1":{"13":1,"25":2,"47":1,"67":1,"69":1}}],["beings",{"1":{"77":1}}],["being",{"1":{"52":1,"71":1}}],["benchmarking",{"1":{"48":1}}],["benchmark",{"1":{"44":1,"48":4,"55":2,"62":1,"64":1}}],["between",{"1":{"36":2,"42":1,"81":1,"82":1}}],["before",{"1":{"12":1,"24":1}}],["best",{"1":{"9":1,"20":1,"42":1}}],["behaviordrone",{"1":{"79":1}}],["behaviorally",{"1":{"76":1}}],["behaviors",{"1":{"54":1,"75":1,"81":1}}],["behavior",{"0":{"78":1},"1":{"9":1,"48":2,"62":2,"67":2,"70":1,"76":1,"81":1},"2":{"79":1,"80":1,"81":1}}],["behaviorcustomize",{"1":{"9":1}}],["behaves",{"1":{"9":2}}],["beach",{"1":{"7":1}}],["be",{"1":{"2":1,"9":2,"13":1,"19":1,"20":1,"22":2,"48":2,"52":1,"56":1,"64":1,"68":4,"70":2,"76":1,"81":1}}],["begin",{"1":{"2":1,"9":1,"78":1}}],["beyond",{"1":{"0":1}}],["fps",{"1":{"48":1,"60":1}}],["fp32",{"0":{"29":1},"1":{"29":1}}],["fn",{"1":{"34":1,"36":1}}],["fleets",{"1":{"81":1}}],["fleetssystems",{"1":{"79":1}}],["flexibility",{"1":{"70":1}}],["flexible",{"1":{"70":3}}],["flexible9",{"1":{"68":1}}],["flexibly",{"1":{"67":1}}],["flat",{"1":{"70":1}}],["flag",{"1":{"16":1}}],["florida",{"1":{"46":1}}],["fluid",{"0":{"20":1},"1":{"20":8,"21":1,"22":1},"2":{"21":1,"22":1}}],["fail",{"1":{"81":1}}],["failure",{"1":{"48":1,"65":1}}],["factors",{"1":{"76":1}}],["facial",{"1":{"70":1,"75":1}}],["facilitates",{"1":{"48":1,"50":1}}],["faced",{"1":{"44":1}}],["face",{"1":{"23":1,"24":1,"50":1,"70":1}}],["familiarity",{"1":{"24":1,"46":9}}],["fabric",{"1":{"20":1}}],["faster",{"1":{"22":1}}],["fast",{"1":{"10":2,"67":1,"68":1,"70":1}}],["fault",{"1":{"2":1}}],["frustration",{"1":{"77":1}}],["front",{"1":{"70":2}}],["from",{"0":{"75":1,"76":1,"80":1},"1":{"3":1,"8":1,"10":1,"12":1,"13":1,"17":2,"20":2,"22":1,"23":1,"38":1,"41":1,"44":1,"46":2,"48":6,"51":2,"53":1,"56":2,"59":1,"60":1,"63":1,"68":5,"75":1,"78":1,"82":2}}],["frequency",{"1":{"48":1}}],["freedom",{"1":{"70":1}}],["free",{"1":{"28":1,"42":1}}],["franka",{"1":{"48":1,"52":1}}],["frames",{"1":{"48":1,"56":1,"65":1}}],["frame",{"1":{"48":2,"50":1,"57":1}}],["frameworkscope",{"1":{"48":1}}],["frameworks",{"1":{"16":1,"47":2,"82":1}}],["framework",{"1":{"10":4,"16":3,"44":4,"46":1,"48":2,"50":1,"63":1,"67":1}}],["figures",{"1":{"67":1}}],["file",{"1":{"13":3,"20":2,"25":1,"41":1}}],["first",{"1":{"12":1,"13":3,"22":1,"47":1,"70":1}}],["fixed",{"1":{"10":1,"48":1}}],["final",{"0":{"40":1},"1":{"40":1}}],["fine",{"0":{"68":1},"1":{"9":1,"61":1,"63":1,"66":2,"67":2,"68":19}}],["findings",{"1":{"46":3}}],["find",{"1":{"9":1,"42":1}}],["fields",{"1":{"70":1}}],["field",{"1":{"0":2,"44":1,"46":1,"84":1}}],["featuring",{"1":{"70":1}}],["featuresplugins",{"1":{"9":1}}],["features",{"1":{"2":1,"8":1,"9":1,"10":1,"44":1,"47":1,"50":1,"51":1,"52":1,"53":2,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"67":2,"69":2,"70":1}}],["feet",{"1":{"70":1}}],["feedback",{"1":{"44":1}}],["feel",{"1":{"28":1,"42":1}}],["few",{"1":{"19":1,"38":1,"41":1,"67":3,"68":11}}],["fetching",{"1":{"9":1,"48":1}}],["fenglong",{"1":{"7":1}}],["further",{"1":{"71":1}}],["fuses",{"1":{"67":1}}],["fusion",{"1":{"61":1}}],["full",{"0":{"25":1},"1":{"48":1,"60":1,"64":1,"68":5}}],["fully",{"0":{"4":1},"1":{"4":1,"48":1,"55":1}}],["functional",{"0":{"75":1},"1":{"70":1,"76":1}}],["functionality",{"1":{"9":3}}],["functions",{"1":{"67":1,"70":1}}],["function",{"0":{"36":1},"1":{"20":1,"23":1,"31":1,"33":1,"36":1}}],["future",{"1":{"0":1,"70":2}}],["folding",{"1":{"70":1}}],["follows",{"1":{"20":2}}],["following",{"1":{"12":1,"13":1,"17":1,"19":1,"20":1,"44":1,"68":1}}],["follow",{"1":{"9":1,"75":1}}],["four",{"1":{"46":1}}],["found",{"1":{"20":2}}],["focused",{"1":{"52":1,"54":1,"57":1,"68":1}}],["focuses",{"1":{"8":1,"60":1,"65":1,"67":1,"70":1,"73":1}}],["focusing",{"1":{"44":2}}],["focus",{"1":{"2":1,"44":1,"48":1}}],["form",{"1":{"78":1}}],["forms",{"1":{"64":1,"78":1}}],["format",{"1":{"61":1}}],["formulation",{"1":{"48":1,"64":1}}],["formulated",{"1":{"44":1}}],["force",{"1":{"44":1,"48":1,"61":1}}],["forums",{"1":{"13":1}}],["for",{"0":{"46":1,"68":1,"81":1},"1":{"2":1,"4":2,"8":1,"9":5,"10":6,"12":5,"13":1,"16":1,"18":2,"20":3,"22":3,"24":2,"25":1,"29":2,"30":1,"34":1,"42":1,"44":4,"45":1,"46":6,"48":22,"50":2,"51":2,"52":1,"53":2,"54":2,"55":2,"56":1,"58":2,"59":1,"60":3,"61":1,"62":3,"63":1,"64":1,"66":2,"67":10,"68":11,"69":1,"70":18,"75":2,"82":1,"83":1}}],["swarms",{"1":{"79":1,"81":1}}],["swarm",{"0":{"79":1},"1":{"79":1}}],["switch",{"1":{"28":1}}],["skills",{"1":{"48":4,"53":1,"58":2,"61":1,"63":1,"67":1,"68":2}}],["skill",{"1":{"48":1,"67":3}}],["skrl",{"1":{"16":1}}],["speed",{"1":{"70":2}}],["speech",{"1":{"70":1}}],["speaks",{"1":{"70":1}}],["specifies",{"1":{"19":1}}],["specifics",{"1":{"68":1}}],["specification",{"1":{"48":2,"64":1}}],["specifically",{"1":{"48":1,"67":1}}],["specific",{"1":{"13":1,"16":1,"48":4,"52":1,"57":1,"60":1,"67":1,"68":5,"70":1,"71":1}}],["specializing",{"1":{"8":2}}],["space",{"1":{"77":1}}],["spaces",{"1":{"70":1}}],["span",{"1":{"68":1}}],["spans",{"1":{"58":1}}],["spanning",{"1":{"48":2,"63":1}}],["sparser",{"1":{"48":1}}],["spoc",{"0":{"65":1},"1":{"47":1,"48":1,"65":1}}],["split",{"1":{"33":1}}],["splitting",{"0":{"33":1}}],["synthetic",{"1":{"81":1}}],["synchronization",{"1":{"61":1}}],["synonym",{"1":{"31":1}}],["system",{"1":{"2":1,"9":3,"11":1,"12":2,"22":5,"48":1,"53":1,"59":1,"67":1,"77":1,"80":1}}],["systems",{"0":{"79":1},"1":{"0":1,"2":1,"3":2,"8":2,"44":2,"72":1,"73":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":2,"81":3,"82":1}}],["smart",{"1":{"75":1}}],["small",{"1":{"67":1,"68":2}}],["smallerutilizes",{"1":{"67":1}}],["smaller",{"1":{"23":1,"42":1,"48":1,"54":1,"68":1}}],["smoothing",{"0":{"35":1},"1":{"23":1,"35":1,"36":2}}],["slow",{"1":{"22":1}}],["siri",{"1":{"77":1}}],["single",{"1":{"68":8}}],["since",{"1":{"20":1,"22":1}}],["siglip",{"1":{"67":1}}],["significant",{"1":{"48":1,"50":1,"71":1}}],["significantly",{"1":{"22":1,"44":1,"52":1,"63":1}}],["sites",{"1":{"48":1}}],["sizes",{"1":{"68":1}}],["size",{"1":{"42":2,"70":1}}],["simultaneous",{"1":{"48":1}}],["simulated",{"1":{"48":2,"50":1,"53":1,"55":1,"64":1}}],["simulator",{"1":{"13":2,"17":1,"20":1}}],["simulation",{"0":{"20":1},"1":{"10":3,"20":5,"21":1,"22":1,"48":6,"50":1,"55":1,"65":2},"2":{"21":1,"22":1}}],["simulations",{"1":{"8":1}}],["sim",{"0":{"12":1,"13":1,"14":1},"1":{"10":1,"11":1,"12":7,"13":3,"20":1,"48":1,"59":1,"65":1},"2":{"13":1,"14":1,"15":2,"16":2,"17":2}}],["simplify",{"1":{"10":2}}],["simple",{"1":{"3":1}}],["similar",{"1":{"9":2}}],["sb3",{"1":{"16":1}}],["science",{"1":{"83":1}}],["screen",{"1":{"70":1}}],["scripts",{"1":{"77":1}}],["scripted",{"1":{"58":1}}],["script",{"1":{"17":1}}],["scenario",{"1":{"70":1}}],["scenariosfeaturesadvantagesdisadvantages1",{"1":{"70":1}}],["scenarios2",{"1":{"67":1}}],["scenarios",{"1":{"48":2,"52":1,"57":1,"65":1,"67":1,"68":2,"70":6}}],["scene",{"1":{"22":1}}],["scenes",{"1":{"10":1,"52":1,"57":1}}],["scoring",{"1":{"67":1}}],["scores",{"1":{"46":1,"80":1}}],["scope",{"1":{"47":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1}}],["scalable",{"1":{"48":3,"53":1,"63":1,"64":1}}],["scalability",{"1":{"2":1,"59":1}}],["scales",{"1":{"78":1}}],["scaletraining",{"1":{"67":1}}],["scale",{"1":{"48":11,"51":1,"54":1,"62":1,"63":1,"66":1,"67":4,"68":6,"81":1}}],["scaled",{"1":{"36":1}}],["schema",{"1":{"9":1}}],["snippets",{"1":{"8":1}}],["sociological",{"1":{"75":1}}],["sociology",{"0":{"72":1},"1":{"73":1,"81":1,"82":1},"2":{"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["society",{"1":{"73":2,"80":1,"82":2}}],["societies",{"0":{"78":1},"1":{"72":1,"73":1,"81":1},"2":{"79":1,"80":1,"81":1}}],["sociality",{"1":{"81":1}}],["social",{"0":{"72":1,"74":1,"75":1,"77":1,"80":1,"81":1,"82":1},"1":{"70":3,"72":1,"73":2,"75":2,"77":5,"78":1,"80":2,"81":2,"82":1,"83":1},"2":{"73":1,"74":1,"75":2,"76":2,"77":2,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["sophisticated",{"1":{"63":1}}],["softbank",{"1":{"70":1}}],["soft",{"1":{"36":2,"42":1}}],["so",{"1":{"20":1,"22":1,"80":1}}],["some",{"1":{"9":1,"12":2,"20":2,"23":1,"48":2,"54":1,"58":1,"62":1,"65":1,"67":1,"80":1}}],["something",{"1":{"9":1,"13":1}}],["source",{"1":{"16":1,"20":1,"83":1}}],["sourced",{"1":{"10":1,"18":1}}],["sources",{"1":{"9":1,"48":1}}],["southeast",{"1":{"7":1}}],["solution",{"1":{"20":1}}],["solutions",{"1":{"8":1,"71":1}}],["solving",{"1":{"8":1}}],["s",{"1":{"8":2,"9":4,"20":1,"22":2,"40":1,"44":1,"46":1,"47":1,"67":1,"70":1,"77":3,"81":1,"82":1}}],["shipment",{"1":{"70":1}}],["shift",{"1":{"46":1,"75":1}}],["shelves",{"1":{"70":1}}],["shot",{"1":{"48":1,"61":1,"63":1,"64":1,"67":6,"68":1}}],["show",{"1":{"44":1}}],["showcasing",{"1":{"44":1,"46":1}}],["short2",{"1":{"68":1}}],["shortest",{"1":{"48":1,"65":1}}],["shortcomings",{"1":{"44":1}}],["short",{"1":{"32":1,"68":1}}],["should",{"1":{"17":1,"19":1}}],["share",{"1":{"80":1}}],["shared",{"1":{"48":1}}],["sharing",{"1":{"44":1,"48":1,"63":1}}],["shadow",{"1":{"44":1}}],["shaoyu",{"1":{"7":1}}],["shape",{"1":{"0":1,"76":1}}],["shuting",{"1":{"7":1}}],["suggested",{"0":{"83":1}}],["suggests",{"1":{"77":1}}],["suitable",{"1":{"67":1,"68":2,"69":1,"70":11}}],["suited",{"1":{"48":1,"50":1}}],["summarizing",{"1":{"67":1}}],["summary",{"0":{"48":1},"1":{"47":1}}],["substantial",{"1":{"48":1}}],["supplemented",{"1":{"67":1}}],["supporting",{"1":{"67":1}}],["supports",{"1":{"48":3,"50":1,"51":1,"57":1,"61":1,"67":2,"70":1}}],["support",{"1":{"10":1,"20":2,"22":1,"48":2,"50":1,"58":1,"70":2}}],["supported",{"1":{"9":1}}],["superior",{"1":{"59":1}}],["supervision",{"1":{"23":1}}],["surgery",{"1":{"76":1}}],["surface",{"1":{"22":1}}],["sure",{"1":{"9":1,"13":1}}],["success",{"1":{"67":1}}],["successfully",{"1":{"70":1}}],["successful",{"1":{"17":1,"53":1}}],["such",{"1":{"0":1,"3":1,"10":1,"44":2,"48":1,"66":1,"67":1,"68":1,"69":1}}],["suny",{"1":{"7":1}}],["saycan",{"1":{"67":1,"68":1}}],["sampling",{"1":{"50":1}}],["samples",{"1":{"38":1,"41":1}}],["sample",{"1":{"21":1,"48":1,"64":1}}],["same",{"1":{"13":1,"30":1}}],["saving",{"0":{"40":1,"41":1},"1":{"9":1}}],["saves",{"1":{"44":1}}],["save",{"1":{"9":2,"25":1,"40":1}}],["san",{"1":{"7":2}}],["safety",{"1":{"2":1,"70":1}}],["safe",{"1":{"0":1}}],["seal",{"1":{"75":1}}],["series",{"1":{"68":1}}],["servants",{"1":{"82":1}}],["servo",{"1":{"70":1}}],["serviceswheeled",{"1":{"70":1}}],["service",{"1":{"69":1,"70":6,"71":1,"75":1}}],["serving",{"1":{"44":1}}],["serves",{"1":{"46":1,"62":1}}],["semantic",{"1":{"67":2,"68":1}}],["semantically",{"1":{"57":1}}],["sequential",{"1":{"65":1}}],["sequencing",{"1":{"48":1}}],["sequences",{"1":{"30":1}}],["sessions",{"1":{"48":1}}],["seek",{"1":{"75":1}}],["see",{"1":{"23":1}}],["seem",{"1":{"22":1}}],["separate",{"1":{"22":1,"44":1}}],["sensing",{"1":{"48":1,"61":1}}],["sensitive",{"1":{"9":1}}],["sensory",{"1":{"65":1}}],["sensor",{"1":{"48":1,"50":1,"55":1,"61":2,"67":1}}],["sensors",{"1":{"10":2,"61":1,"67":1,"68":1}}],["sets",{"1":{"44":1}}],["setups",{"1":{"68":1}}],["setup",{"0":{"27":1},"1":{"48":3,"58":2,"65":1,"68":1}}],["setting",{"1":{"23":1}}],["settings",{"1":{"9":1,"20":1,"42":1,"48":3,"55":1,"60":1,"64":1}}],["settingsadjust",{"1":{"9":1}}],["set",{"1":{"9":1,"22":2,"30":1,"38":1}}],["several",{"1":{"9":1,"48":1,"66":1,"68":6}}],["select",{"1":{"9":2}}],["self",{"1":{"2":2,"3":1,"46":5,"83":1}}],["sectors",{"1":{"70":2,"71":1}}],["section",{"1":{"9":2,"10":1,"22":1,"25":1}}],["seconds",{"1":{"67":1}}],["second",{"1":{"47":1}}],["security",{"1":{"9":1,"70":3}}],["secure",{"0":{"2":1},"1":{"2":2}}],["still",{"1":{"82":1}}],["stick",{"1":{"48":1,"60":1}}],["store",{"1":{"61":1}}],["storage",{"1":{"48":2,"56":1}}],["study",{"1":{"56":1}}],["studying",{"1":{"51":1}}],["studies",{"1":{"54":1}}],["student",{"1":{"23":2,"28":1,"29":2,"36":1,"37":2,"38":1,"39":1,"40":1,"41":1,"42":1}}],["styles",{"1":{"46":1}}],["stakes",{"1":{"76":1}}],["stance",{"1":{"70":1}}],["standardizing",{"1":{"51":1}}],["standardized",{"1":{"48":2,"55":1,"62":1}}],["standardization",{"1":{"48":1}}],["stability",{"1":{"69":1}}],["stable",{"0":{"28":1},"1":{"3":1,"23":1,"29":1,"70":2}}],["stages",{"1":{"68":1}}],["stack",{"1":{"60":1}}],["started",{"0":{"18":1},"2":{"19":1}}],["start",{"1":{"8":1}}],["static",{"1":{"67":1,"68":1}}],["states",{"1":{"22":2,"48":1}}],["state",{"1":{"7":6,"40":1,"48":1,"54":1,"59":1}}],["statuses",{"1":{"4":1}}],["structures",{"0":{"72":1},"1":{"78":1,"80":1},"2":{"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["structure",{"1":{"70":1}}],["structured",{"1":{"48":1,"55":1}}],["strong",{"1":{"58":1,"60":1,"64":1,"67":1,"70":1}}],["streaming",{"1":{"67":1}}],["streams",{"1":{"50":1}}],["streamline",{"1":{"0":1}}],["strategies",{"1":{"46":1,"68":2}}],["strategic",{"0":{"1":1},"1":{"79":1},"2":{"2":1,"3":1,"4":1}}],["strategy",{"1":{"44":2,"67":1,"68":1}}],["steps",{"0":{"26":1},"1":{"9":1,"20":1,"23":1},"2":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1}}],["step",{"0":{"1":1,"2":1,"3":1,"4":1},"1":{"12":1,"23":2,"42":2,"46":1,"67":2},"2":{"2":1,"3":1,"4":1}}],["psychology",{"1":{"77":1}}],["penalty",{"1":{"80":1}}],["pennsylvania",{"1":{"7":1}}],["people",{"1":{"77":1}}],["pepper",{"1":{"70":1,"75":1}}],["periodfocuses",{"1":{"68":1}}],["perceive",{"1":{"77":1}}],["perceiver",{"1":{"67":2,"68":1}}],["perception",{"1":{"48":1,"65":1}}],["persist",{"1":{"48":1,"65":1}}],["per",{"1":{"48":1,"57":1,"67":2,"70":1}}],["performative",{"1":{"77":1}}],["performances",{"1":{"70":1}}],["performance",{"1":{"41":1,"42":1,"46":1,"48":2,"52":1,"59":1,"63":1,"67":2,"68":1,"70":3,"77":1}}],["performs",{"1":{"70":2}}],["perform",{"1":{"32":1,"44":1,"48":1}}],["py",{"1":{"20":1,"25":1}}],["pytorch",{"0":{"23":1},"1":{"12":2,"23":1,"24":1,"34":1,"50":1},"2":{"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1}}],["python",{"1":{"12":2,"20":2,"24":1}}],["power",{"1":{"80":1}}],["politeness",{"1":{"77":1}}],["policies",{"1":{"50":1,"51":1}}],["policy",{"1":{"20":1,"44":1,"48":1,"52":1,"58":1,"67":3,"68":1}}],["portable",{"1":{"67":1,"68":1}}],["potentially",{"1":{"70":1}}],["potential",{"1":{"48":2,"51":1,"72":1,"73":1}}],["pooling",{"1":{"48":1,"51":1}}],["points",{"1":{"22":2}}],["possibly",{"1":{"68":1}}],["possible",{"1":{"12":1,"20":1}}],["positioned",{"1":{"62":1}}],["positions",{"1":{"20":2,"22":2,"55":1}}],["positive",{"1":{"48":1}}],["post",{"1":{"46":1}}],["poses",{"1":{"82":1}}],["pose",{"1":{"12":1}}],["punishment",{"1":{"80":1}}],["published",{"1":{"46":1}}],["pulled",{"1":{"13":2}}],["purpose",{"0":{"66":1},"1":{"9":1,"66":2},"2":{"67":1,"68":1}}],["phase",{"1":{"44":1}}],["physical",{"1":{"22":2,"44":2,"48":1,"70":1,"75":1,"77":1}}],["physics",{"1":{"10":1}}],["physx",{"1":{"10":1,"22":2}}],["photo",{"1":{"10":1}}],["patrols",{"1":{"70":1}}],["patrolsflexible",{"1":{"70":1}}],["paths",{"1":{"65":1}}],["path",{"1":{"48":1}}],["pal",{"1":{"70":1}}],["pali",{"1":{"67":1}}],["palm",{"1":{"67":2,"68":1}}],["pairs",{"1":{"48":1,"61":1}}],["paid",{"1":{"9":1}}],["panda",{"1":{"48":1,"52":1}}],["papers",{"1":{"46":1}}],["paper",{"1":{"44":3,"46":3}}],["padded",{"1":{"30":1}}],["pad",{"1":{"30":1}}],["pass",{"1":{"16":1}}],["packages",{"1":{"12":1,"24":1}}],["paro",{"1":{"75":1}}],["paradigmfeaturesexamplesphilosophical",{"1":{"79":1}}],["paradigms",{"1":{"79":1}}],["parallel",{"1":{"19":1}}],["parameter",{"1":{"19":1,"23":1,"36":1,"66":1,"67":2,"68":7}}],["parameters",{"1":{"9":1,"39":1,"42":1,"67":1,"68":2}}],["partly",{"1":{"25":1}}],["parts",{"1":{"20":1,"47":1}}],["participants",{"1":{"82":1}}],["particular",{"1":{"58":1}}],["particularly",{"1":{"19":1}}],["particleutils",{"1":{"22":2}}],["particle",{"1":{"22":12}}],["particleset",{"1":{"22":1}}],["particles",{"1":{"20":2,"22":4}}],["party",{"1":{"9":2}}],["please",{"1":{"13":1,"17":1,"83":1}}],["plus",{"1":{"9":1,"48":1}}],["plugins",{"1":{"9":2}}],["play",{"1":{"77":1}}],["platforms6",{"1":{"67":1}}],["platforms",{"1":{"48":2,"50":1,"56":1,"67":1}}],["platform",{"1":{"4":2,"8":2,"9":2,"44":1,"46":2,"48":1,"52":1,"53":1,"56":1}}],["plans",{"1":{"70":1}}],["planned",{"1":{"70":2}}],["planningbased",{"1":{"67":1}}],["planning",{"1":{"10":1,"48":1,"65":1,"67":2,"79":1}}],["plane",{"1":{"17":1}}],["plan",{"0":{"1":1},"2":{"2":1,"3":1,"4":1}}],["picking",{"1":{"70":2}}],["pipelines",{"1":{"63":1}}],["pipeline",{"1":{"23":1,"48":1}}],["pip",{"1":{"12":5,"16":1}}],["pilot",{"1":{"3":1,"48":1,"53":1}}],["pioneering",{"1":{"0":2,"84":1}}],["practitioners",{"1":{"44":1,"46":1}}],["practices",{"1":{"81":1}}],["practicesversion",{"1":{"9":1}}],["practical",{"1":{"0":1,"2":1,"8":1}}],["predictable",{"1":{"76":1}}],["prediction",{"1":{"68":1}}],["predictionnot",{"1":{"67":1}}],["predictions",{"1":{"35":1}}],["previous",{"1":{"46":1}}],["preventative",{"1":{"46":1}}],["prevent",{"1":{"46":1}}],["prevention",{"0":{"45":1,"46":1},"1":{"45":1,"46":1},"2":{"46":1}}],["prevents",{"1":{"20":1}}],["pre",{"1":{"46":1,"67":5,"68":11}}],["premier",{"1":{"46":1}}],["precision",{"1":{"44":2}}],["precise",{"1":{"44":1}}],["presence",{"0":{"77":1},"1":{"75":1,"77":2}}],["presentation",{"1":{"83":1}}],["presenting",{"1":{"46":1}}],["presented",{"1":{"44":1}}],["presents",{"1":{"44":1,"64":1}}],["prestigious",{"1":{"44":1}}],["pressing",{"1":{"17":1,"19":1}}],["prefer",{"1":{"25":1}}],["pretrained",{"1":{"24":1,"48":1,"50":2}}],["prerequisites",{"0":{"24":1}}],["preprocessing",{"0":{"32":1},"1":{"23":1,"58":1}}],["prioritizes",{"1":{"70":1}}],["prioritizing",{"1":{"2":1}}],["privileged",{"1":{"48":1}}],["private",{"1":{"9":1}}],["primarily",{"1":{"48":2,"70":3}}],["profound",{"1":{"82":1}}],["protocols",{"1":{"80":1}}],["prototyping",{"1":{"50":1}}],["production",{"1":{"70":4}}],["produced",{"1":{"70":1}}],["produce",{"1":{"42":1,"46":1,"59":1}}],["probabilities",{"1":{"67":1}}],["problem",{"1":{"44":1}}],["programmatically",{"1":{"67":1}}],["project",{"1":{"67":1,"68":1}}],["projects",{"1":{"3":1,"8":1,"67":2}}],["proven",{"1":{"53":1}}],["providing",{"1":{"50":1,"60":1,"62":1}}],["provided",{"1":{"10":1,"18":1,"67":1}}],["provides",{"1":{"8":1,"9":1,"10":1,"46":1,"48":1,"53":1,"57":1,"66":1,"70":1}}],["proactive",{"1":{"46":1}}],["proactively",{"1":{"46":1}}],["procedurally",{"1":{"48":1,"64":1}}],["proceeding",{"1":{"24":1}}],["processing",{"1":{"46":2,"48":2,"56":1}}],["processes",{"1":{"4":1}}],["process",{"1":{"4":1,"13":1,"17":1,"24":1,"44":2,"61":1}}],["proposes",{"1":{"46":1}}],["proposed",{"1":{"20":1,"44":1,"46":1}}],["properties",{"1":{"22":1}}],["promptrobot",{"0":{"85":1}}],["prompts",{"1":{"48":2,"64":1,"67":1}}],["prompt",{"1":{"9":2,"13":1,"17":1,"46":1,"75":1}}],["prompted",{"1":{"9":1,"13":1,"64":1}}],["ii",{"0":{"78":1},"2":{"79":1,"80":1,"81":1}}],["imitating",{"1":{"65":1}}],["imitation",{"1":{"48":11,"50":1,"52":1,"53":1,"54":2,"61":1,"62":2,"67":1,"68":1}}],["image",{"1":{"64":1,"67":1}}],["images",{"1":{"52":1,"67":1}}],["impact",{"1":{"81":1}}],["impacting",{"1":{"22":1}}],["improvements",{"1":{"68":1}}],["improves",{"1":{"48":2,"67":1}}],["improved",{"0":{"32":1,"36":1},"1":{"23":1}}],["improving",{"1":{"10":1}}],["important",{"1":{"22":1}}],["implement",{"1":{"80":1}}],["implemented",{"1":{"35":1}}],["implementation",{"1":{"8":1,"20":1,"22":1,"44":1,"46":1}}],["implementing",{"1":{"2":1,"23":1}}],["identity",{"1":{"80":1,"82":1}}],["identifies",{"1":{"46":1}}],["identify",{"1":{"9":1}}],["ideal",{"1":{"48":1,"51":1,"54":1,"61":1}}],["ideas",{"1":{"44":1}}],["iros",{"1":{"44":2}}],["ieee",{"1":{"44":1}}],["i",{"0":{"74":1},"1":{"13":1},"2":{"75":1,"76":1,"77":1}}],["if",{"1":{"9":2,"12":1,"13":2,"16":1,"19":3,"23":1,"27":1,"28":1,"46":1,"80":1,"83":1}}],["iterates",{"1":{"16":1}}],["iteratively",{"1":{"9":1}}],["iterative",{"1":{"9":1}}],["itself",{"1":{"73":1}}],["its",{"1":{"9":1,"44":1,"52":1,"70":2,"76":1}}],["it",{"1":{"9":3,"10":1,"12":1,"13":1,"19":2,"20":1,"22":2,"25":2,"46":1,"50":1,"51":1,"54":1,"61":1,"65":1,"66":1,"73":1,"76":2,"80":1,"82":1}}],["issues",{"1":{"12":3,"48":1}}],["isaaclab",{"0":{"19":1},"1":{"18":1,"19":1,"20":2}}],["isaacsim",{"1":{"13":1}}],["isaac",{"0":{"12":1,"13":1,"14":1,"15":1,"17":1},"1":{"10":4,"11":2,"12":8,"13":3,"15":1,"18":2,"20":5,"22":5},"2":{"13":1,"14":1,"15":2,"16":2,"17":2}}],["is",{"1":{"0":1,"2":1,"8":2,"10":3,"12":7,"13":3,"18":1,"19":2,"20":5,"21":1,"22":7,"23":1,"25":2,"27":2,"33":1,"35":1,"44":3,"46":1,"47":3,"48":1,"50":2,"51":3,"53":1,"55":1,"56":1,"59":2,"61":1,"62":3,"63":1,"65":1,"66":1,"67":1,"68":4,"69":2,"73":1,"76":2,"77":2,"81":3,"82":2}}],["inaccurate",{"1":{"46":1}}],["inputs",{"1":{"48":2,"52":1,"54":1,"59":1,"65":1,"68":1}}],["input",{"1":{"44":1,"65":1,"67":1}}],["innovative",{"1":{"44":1,"46":1}}],["innovations",{"1":{"66":1}}],["innovation",{"1":{"0":1}}],["info",{"1":{"48":1}}],["information",{"1":{"9":1,"46":1,"57":1,"61":1,"70":1}}],["infrastructure",{"1":{"48":1,"63":1}}],["influential",{"1":{"44":1}}],["involved",{"1":{"44":1}}],["involves",{"1":{"3":1}}],["indicating",{"1":{"77":1}}],["indicators",{"1":{"67":1}}],["individual",{"1":{"22":1,"78":1}}],["industry",{"1":{"46":1}}],["industrial",{"1":{"8":1,"57":1,"70":2}}],["industries",{"1":{"0":1,"3":1}}],["increasing",{"1":{"81":1}}],["increasingly",{"1":{"71":1,"73":1}}],["increases",{"1":{"51":1}}],["increase",{"1":{"29":1}}],["inconsistencies",{"1":{"51":1}}],["incorrectly",{"1":{"13":1}}],["includes",{"1":{"23":1,"48":2,"53":1,"58":1,"60":2,"64":1}}],["include",{"1":{"10":3,"31":1,"48":1,"75":1,"76":1}}],["included",{"1":{"10":1}}],["including",{"1":{"9":1,"44":1,"46":1,"47":1,"48":1,"52":1,"54":1,"59":1,"61":1,"67":1,"71":1}}],["inspectionsfaster",{"1":{"70":1}}],["inspection",{"1":{"70":1}}],["inspire",{"1":{"8":1}}],["insertions",{"1":{"31":1}}],["instinctively",{"1":{"77":1}}],["institutionalization",{"1":{"80":1}}],["institutions",{"1":{"48":1,"51":1,"70":2,"81":1}}],["institute",{"1":{"7":1}}],["instruction",{"1":{"46":4}}],["instructions",{"1":{"9":3,"13":1,"46":1,"48":1,"57":1,"64":1,"65":1}}],["instead",{"1":{"20":1,"22":1,"67":1}}],["instances",{"1":{"46":1,"48":1,"64":1}}],["instance",{"1":{"12":1}}],["installs",{"1":{"16":1}}],["installed",{"1":{"12":2,"24":1}}],["installing",{"0":{"12":1,"14":1},"1":{"12":2,"13":1},"2":{"13":1,"14":1,"15":2,"16":2,"17":2}}],["install",{"1":{"11":1,"12":3,"16":5,"19":2}}],["installation",{"0":{"11":1,"13":1,"16":1,"17":1,"19":1},"1":{"12":2,"17":1,"19":1},"2":{"12":1,"13":1,"14":1,"15":1,"16":1,"17":1}}],["inside",{"1":{"9":1}}],["into",{"1":{"15":1,"22":3,"23":1,"33":1,"42":1,"47":1,"71":1,"75":1,"76":1}}],["introduce",{"1":{"51":1,"60":1}}],["introduces",{"1":{"46":1}}],["introduction",{"0":{"10":1,"73":1}}],["introducing",{"1":{"3":1}}],["intent",{"1":{"80":1}}],["intensive3",{"1":{"68":1}}],["intensive",{"1":{"67":1}}],["intended",{"1":{"9":2,"55":1}}],["interdependence",{"1":{"81":1}}],["interconnected",{"1":{"78":1}}],["internet",{"1":{"67":4,"68":2}}],["internal",{"1":{"44":1}}],["international",{"1":{"44":2}}],["interleaved",{"1":{"64":1}}],["interventions",{"1":{"53":1}}],["interpretability",{"1":{"44":1,"46":1}}],["interpret",{"1":{"44":1}}],["interactive",{"1":{"75":1,"77":1}}],["interactionwheeled",{"1":{"70":1}}],["interactions",{"1":{"44":2,"70":1,"82":1}}],["interaction",{"0":{"72":1,"74":1,"77":1},"1":{"2":1,"70":12,"71":1,"72":1,"73":1,"75":1,"77":1,"78":1},"2":{"73":1,"74":1,"75":2,"76":2,"77":2,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["interact",{"1":{"9":1}}],["interface",{"1":{"9":2,"19":4,"70":1}}],["integrating",{"1":{"56":1,"67":1}}],["integration",{"1":{"9":1,"44":1,"48":1,"64":1,"75":1}}],["integrates",{"1":{"67":1,"68":1}}],["integrated",{"1":{"48":1,"50":1,"71":1}}],["integrate",{"1":{"4":1,"9":2}}],["integrity",{"1":{"2":1}}],["intelligent",{"0":{"2":1},"1":{"0":1,"2":1,"3":1,"8":2,"44":2,"70":1,"73":1,"77":1}}],["intelligencedecentralized",{"1":{"79":1}}],["intelligence",{"1":{"0":2,"84":1}}],["in",{"0":{"29":1,"45":1},"1":{"3":2,"8":2,"9":6,"10":5,"13":2,"16":1,"19":3,"20":12,"22":4,"25":4,"29":1,"35":1,"42":1,"44":5,"46":9,"48":15,"50":3,"52":1,"53":3,"54":1,"58":2,"60":2,"61":1,"64":2,"65":5,"67":3,"68":4,"70":9,"71":1,"73":1,"76":2,"77":3,"82":1,"83":1},"2":{"46":1}}],["initiatives",{"1":{"8":1}}],["initiative",{"1":{"0":2,"84":1}}],["m",{"1":{"70":1}}],["mph",{"1":{"70":1}}],["mt",{"0":{"63":1},"1":{"47":1,"48":1,"63":1}}],["mse",{"1":{"44":1}}],["much",{"1":{"22":1,"62":1,"76":1}}],["must",{"1":{"22":1,"44":1,"81":1,"82":1}}],["multilingual",{"1":{"67":1,"70":1}}],["multimodal",{"1":{"48":1,"64":1,"67":1}}],["multiple",{"1":{"37":1,"48":2,"56":1,"61":1,"67":1,"68":2}}],["multi",{"0":{"79":1},"1":{"2":1,"48":16,"50":1,"52":1,"54":1,"55":1,"56":1,"57":1,"58":2,"61":1,"62":1,"63":2,"67":5,"68":3,"70":2,"72":1,"73":1,"79":1}}],["macro",{"1":{"82":1}}],["machine",{"0":{"72":1,"78":1,"81":1},"1":{"72":1,"73":1,"83":2},"2":{"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":2,"80":2,"81":2,"82":1,"83":1}}],["machines",{"1":{"17":1,"76":1,"81":1,"82":1}}],["mass",{"1":{"70":4}}],["massive",{"1":{"48":1,"59":1}}],["major",{"1":{"66":1}}],["mar",{"1":{"47":1,"66":1}}],["market",{"1":{"70":2}}],["marks",{"1":{"46":1}}],["markov",{"1":{"44":3}}],["map",{"1":{"33":1,"44":1}}],["mature",{"1":{"70":1}}],["material",{"1":{"70":2}}],["materials",{"1":{"22":1,"44":1,"46":1}}],["mathematical",{"1":{"44":1}}],["match",{"1":{"28":1}}],["maintenance",{"1":{"70":1}}],["mainstream",{"1":{"47":2}}],["main",{"1":{"18":1}}],["may",{"1":{"9":1,"12":2,"19":1,"20":1,"48":7,"52":1,"53":1,"57":1,"60":1,"62":1,"64":1,"68":5,"70":7,"81":1}}],["makes",{"1":{"61":1,"77":1}}],["make",{"1":{"9":2,"13":1,"20":1,"76":1}}],["making",{"1":{"8":1,"54":1,"68":1,"69":1,"76":1}}],["ma",{"1":{"7":1}}],["manipulator",{"1":{"70":1}}],["manipulating",{"1":{"70":1}}],["manipulation1",{"1":{"67":1}}],["manipulation",{"0":{"19":1},"1":{"10":1,"18":1,"44":4,"48":18,"52":1,"54":3,"55":1,"56":1,"57":1,"60":1,"61":2,"62":1,"63":1,"64":1,"65":1,"67":4,"68":1}}],["many",{"1":{"48":2}}],["manager",{"1":{"20":1}}],["manage",{"1":{"4":1}}],["management",{"1":{"4":1}}],["manufacturing",{"1":{"3":1}}],["mechanical",{"1":{"82":1}}],["mechanism",{"1":{"46":2}}],["mechanisms",{"1":{"2":1,"4":1,"80":1}}],["media",{"1":{"77":1,"83":1}}],["meet",{"1":{"71":1}}],["meets",{"1":{"9":1}}],["merely",{"1":{"73":1}}],["merging",{"1":{"71":1}}],["mercuryx1",{"1":{"70":1}}],["member",{"1":{"73":1}}],["members",{"0":{"6":1,"82":1}}],["memory",{"1":{"68":3}}],["methodparameter",{"1":{"67":1}}],["method",{"1":{"63":1,"67":1}}],["methods",{"1":{"44":1,"46":3,"68":2}}],["meta",{"0":{"55":1},"1":{"47":1,"48":3,"55":3}}],["means",{"1":{"13":1}}],["message",{"1":{"13":1}}],["menu",{"1":{"9":2}}],["mengmeng",{"1":{"7":1}}],["micro",{"1":{"82":1}}],["mirror",{"1":{"80":1}}],["misbehavior",{"1":{"80":1}}],["mission",{"1":{"0":1}}],["mile",{"1":{"81":1}}],["miles",{"1":{"70":1}}],["million",{"1":{"68":2}}],["millions",{"1":{"48":1,"61":1}}],["might",{"1":{"54":1}}],["mix",{"1":{"48":1}}],["mime",{"0":{"54":1},"1":{"47":1,"48":1,"54":1}}],["mimic",{"1":{"75":1}}],["mimics",{"1":{"46":1}}],["mimicking",{"1":{"44":1}}],["miami",{"1":{"46":1}}],["mindbelpaeme",{"1":{"83":1}}],["minutes",{"1":{"13":1}}],["minimalist",{"1":{"65":1}}],["minimal",{"1":{"32":1,"48":1,"60":1,"65":1}}],["minimum",{"1":{"22":1}}],["mini",{"1":{"13":1}}],["mingjie",{"1":{"7":1}}],["mitigation",{"1":{"46":1}}],["mitigating",{"1":{"46":1}}],["mitigate",{"1":{"35":1}}],["mit",{"1":{"5":1}}],["moral",{"1":{"82":1,"83":1}}],["morally",{"1":{"76":1}}],["more",{"1":{"8":1,"10":1,"29":1,"42":1,"59":1,"62":1,"70":2,"71":1}}],["moving",{"1":{"73":1}}],["movement",{"1":{"44":1,"70":7}}],["moves",{"1":{"34":1}}],["mobility",{"1":{"70":5}}],["mobile",{"1":{"67":4,"68":2}}],["mounted",{"1":{"67":1,"70":1}}],["mostly",{"1":{"48":1}}],["most",{"1":{"44":1}}],["motions",{"1":{"44":1}}],["motion",{"1":{"10":1,"20":1}}],["monitoring",{"1":{"3":1}}],["modalities",{"1":{"48":1,"61":1,"65":1}}],["modalitieskey",{"1":{"48":1}}],["modal",{"1":{"48":5,"54":1,"57":1,"61":1,"62":1,"70":1}}],["modified",{"1":{"47":1,"66":1,"69":1}}],["modifications",{"1":{"20":1}}],["modify",{"1":{"19":1,"20":1,"42":1}}],["modules",{"1":{"19":1,"67":1}}],["modularity",{"1":{"10":1}}],["modular",{"1":{"2":1,"10":2,"50":1}}],["moderate",{"1":{"48":1}}],["modern",{"1":{"0":2,"79":1,"84":1}}],["mode",{"1":{"19":1,"20":5,"22":1}}],["modeling",{"1":{"28":1,"44":1}}],["model",{"0":{"38":1,"40":1},"1":{"8":2,"23":3,"27":1,"29":1,"30":1,"37":2,"40":1,"42":3,"44":2,"46":1,"48":1,"59":1,"64":1,"66":1,"67":6,"68":4,"70":1}}],["models",{"0":{"28":1,"29":1,"46":1,"66":1,"67":1},"1":{"3":1,"23":2,"24":1,"28":2,"38":1,"45":1,"46":2,"48":2,"50":1,"59":1,"60":1,"66":2,"67":1,"68":1},"2":{"67":1,"68":1}}],["octo",{"1":{"67":1,"68":1}}],["out",{"1":{"68":1}}],["outlines",{"1":{"66":1,"68":1}}],["outdoor",{"1":{"57":1}}],["outside",{"1":{"48":1}}],["outstanding",{"1":{"48":1,"70":2}}],["outperforms",{"1":{"46":1}}],["outputs",{"0":{"41":1},"1":{"23":1,"38":1}}],["outcomes",{"1":{"44":1}}],["our",{"0":{"1":1},"1":{"0":1,"2":1,"20":1,"27":1,"30":1,"33":1,"73":1},"2":{"2":1,"3":1,"4":1}}],["observations",{"1":{"48":1}}],["obtaining",{"1":{"53":1}}],["obtain",{"1":{"22":1}}],["object",{"1":{"48":2,"65":1}}],["objects",{"1":{"22":2,"44":1,"70":2}}],["objectives",{"1":{"10":1}}],["omitting",{"1":{"19":1}}],["omniverse",{"1":{"13":4}}],["oversight",{"1":{"82":1}}],["overview",{"0":{"70":1},"1":{"47":2,"66":2,"69":2}}],["overall",{"1":{"46":1}}],["overburdening",{"1":{"44":1}}],["overcome",{"1":{"44":1}}],["overconfidence",{"1":{"35":1}}],["overfitting",{"1":{"29":1}}],["over",{"1":{"10":1,"16":1,"48":2,"56":1,"59":1,"63":1,"67":2,"68":1,"70":1}}],["own",{"1":{"9":2,"19":1}}],["oklahoma",{"1":{"7":2}}],["otherwise",{"1":{"27":1}}],["others",{"1":{"9":1,"80":1}}],["other",{"1":{"4":1,"9":1,"22":1,"28":1,"42":1,"48":1,"52":1,"60":1,"62":1,"70":2,"83":1}}],["opt",{"0":{"63":1},"1":{"47":1,"48":1,"63":1}}],["options",{"1":{"16":1,"68":1}}],["optionally",{"1":{"31":1}}],["optional",{"1":{"9":2,"12":1}}],["option",{"1":{"9":1}}],["optionlook",{"1":{"9":1}}],["optimization",{"1":{"3":1}}],["opening",{"1":{"67":1,"70":1}}],["openpi",{"1":{"67":1,"68":1}}],["openvla",{"1":{"67":1,"68":1}}],["openwebtext",{"0":{"33":1}}],["open",{"0":{"51":1},"1":{"10":1,"18":1,"47":1,"48":2,"56":1,"67":2}}],["openness",{"1":{"10":1}}],["openly",{"1":{"9":1}}],["openai",{"1":{"8":2,"9":2}}],["operate",{"1":{"81":1}}],["operates",{"1":{"70":1}}],["operated",{"1":{"4":1}}],["operator",{"1":{"44":3}}],["operational",{"1":{"70":1}}],["operationnot",{"1":{"67":1}}],["operation",{"1":{"2":1,"70":1}}],["operationsreportedly",{"1":{"70":1}}],["operations",{"0":{"3":1},"1":{"0":1,"2":1,"3":2}}],["organically",{"1":{"80":1}}],["organized",{"1":{"46":1,"47":1}}],["order",{"1":{"68":1}}],["oriented",{"0":{"44":1},"1":{"43":1,"44":1}}],["original",{"1":{"31":1,"42":1}}],["or",{"0":{"68":1},"1":{"3":1,"8":1,"9":9,"13":2,"17":1,"19":1,"25":1,"28":1,"39":1,"46":2,"48":1,"57":1,"62":1,"64":1,"65":1,"66":2,"67":1,"68":6,"76":1,"77":3,"80":4,"81":1,"82":1,"83":1}}],["online",{"1":{"44":1,"48":1,"62":1}}],["only",{"1":{"9":1,"16":2,"19":1,"20":1,"22":3,"44":1,"48":3,"65":3}}],["onto",{"1":{"44":1}}],["one",{"1":{"20":1,"22":3,"44":1,"46":1,"48":1,"61":1,"68":7}}],["once",{"1":{"9":1,"13":1}}],["on",{"1":{"2":1,"8":3,"9":2,"10":1,"11":1,"12":4,"13":1,"16":1,"17":2,"19":1,"20":1,"22":1,"27":2,"38":1,"44":5,"46":2,"48":4,"50":2,"52":1,"53":2,"54":1,"56":1,"57":1,"59":1,"60":1,"61":1,"63":2,"65":2,"66":2,"67":11,"68":17,"70":2,"73":1,"76":1,"81":1,"83":1}}],["often",{"1":{"44":1,"48":1,"58":1,"64":1,"68":3,"77":1,"80":1}}],["offering",{"1":{"54":1,"70":1,"71":1}}],["offers",{"1":{"50":1,"52":1,"56":1}}],["offer",{"1":{"48":1,"54":1,"62":1}}],["offline",{"1":{"44":3}}],["off",{"1":{"19":1,"42":1}}],["of",{"0":{"9":1,"19":1,"26":1,"67":1,"70":1,"72":1,"74":1,"76":1,"78":1},"1":{"0":3,"3":1,"7":5,"8":1,"9":4,"10":3,"12":2,"13":3,"16":1,"17":1,"19":1,"20":7,"21":1,"22":5,"37":1,"44":10,"46":6,"47":4,"48":9,"51":1,"52":1,"53":3,"54":1,"56":2,"59":2,"60":1,"61":1,"62":1,"63":1,"64":3,"66":3,"67":4,"68":4,"69":5,"70":7,"71":3,"72":2,"73":3,"76":1,"77":2,"78":2,"80":1,"82":4,"83":2,"84":1},"2":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"73":1,"74":1,"75":2,"76":2,"77":2,"78":1,"79":2,"80":2,"81":2,"82":1,"83":1}}],["tpu",{"1":{"68":1}}],["tpus",{"1":{"68":1}}],["tdmpc",{"1":{"50":1}}],["types",{"1":{"48":1}}],["typical",{"1":{"35":1,"66":1,"68":1}}],["typically",{"1":{"22":1,"68":9}}],["two",{"1":{"44":1,"47":1,"70":2,"73":1}}],["t",{"1":{"22":1,"80":1,"83":1}}],["tied",{"1":{"58":1}}],["tiled",{"1":{"10":1}}],["timemodel",{"1":{"68":1}}],["times",{"1":{"68":2,"70":1}}],["time",{"0":{"43":1,"44":1,"68":1},"1":{"3":1,"9":2,"13":1,"43":1,"44":3,"60":1,"66":2,"68":12},"2":{"44":1}}],["tuning",{"0":{"68":1},"1":{"63":1,"66":2,"67":2,"68":19}}],["tune",{"1":{"9":1}}],["turn",{"1":{"19":1}}],["tutorial",{"0":{"9":1},"1":{"23":3}}],["tailored",{"1":{"71":1}}],["taking",{"1":{"68":1}}],["takes",{"1":{"68":1}}],["take",{"1":{"13":1,"68":2,"76":1}}],["target",{"1":{"67":1}}],["targeted",{"1":{"62":1,"70":1}}],["targets",{"1":{"54":1}}],["tabletop",{"1":{"48":1,"64":2}}],["table",{"0":{"48":1},"1":{"47":1,"67":1,"68":1}}],["tactile",{"1":{"44":1,"48":1,"61":1}}],["tangible",{"1":{"8":1}}],["tao",{"1":{"7":1}}],["taskingmanufacturing",{"1":{"79":1}}],["task",{"1":{"4":2,"19":3,"44":1,"48":12,"55":2,"60":1,"63":2,"64":3,"65":1,"67":8,"68":2}}],["tasksengages",{"1":{"70":1}}],["tasksnot",{"1":{"67":1}}],["tasks",{"1":{"2":1,"10":5,"19":1,"44":1,"48":12,"51":1,"52":1,"53":2,"54":1,"57":2,"58":1,"59":2,"60":1,"63":3,"64":1,"65":1,"67":4,"68":3,"70":6,"76":1}}],["tsinghua",{"1":{"7":1}}],["terrains",{"1":{"70":1}}],["terrain",{"1":{"70":1}}],["terminate",{"1":{"17":1}}],["terminal",{"1":{"17":1}}],["terms",{"1":{"13":1,"44":1}}],["tens",{"1":{"67":1}}],["tensors",{"1":{"22":1,"34":1}}],["temporal",{"1":{"48":1,"50":2}}],["temperature",{"1":{"36":1,"42":1}}],["template",{"1":{"18":4}}],["technical",{"1":{"47":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"66":2,"79":1,"81":1}}],["techniques",{"1":{"31":1}}],["technological",{"1":{"73":1}}],["technologiesthe",{"1":{"70":1}}],["technologies",{"1":{"4":2,"70":1,"77":1}}],["technology",{"1":{"7":1,"71":1}}],["texts",{"1":{"32":1}}],["text",{"1":{"31":2,"32":1,"38":1,"41":1,"64":1,"67":2}}],["teacher",{"1":{"23":2,"28":1,"29":1,"30":1,"36":1,"37":1,"38":1,"41":1,"42":1}}],["team",{"0":{"6":1}}],["testing",{"1":{"19":1,"20":1,"33":1,"34":1,"44":3}}],["test",{"1":{"9":1,"38":1,"55":1}}],["testonce",{"1":{"9":1}}],["teleop",{"1":{"48":1}}],["teleoperated",{"1":{"48":1,"57":1,"58":1}}],["teleoperation",{"1":{"48":2,"53":3,"54":1}}],["telesurgery",{"1":{"8":1,"44":1}}],["telemanipulation",{"0":{"43":1,"44":1},"1":{"8":1,"43":1,"44":5},"2":{"44":1}}],["treat",{"1":{"77":1}}],["treating",{"1":{"44":1}}],["tree",{"1":{"18":1}}],["trivial",{"1":{"32":1}}],["trust",{"0":{"76":1},"1":{"76":7,"82":1}}],["trustworthiness",{"1":{"4":1}}],["truth",{"1":{"23":1,"42":1}}],["troubleshoot",{"1":{"13":1}}],["traffic",{"1":{"79":1}}],["trajectory",{"1":{"67":1}}],["trajectories",{"1":{"48":8,"51":1,"52":1,"54":1,"57":1,"58":1,"60":1}}],["traditional",{"1":{"44":1,"67":1,"70":1}}],["trade",{"1":{"42":1}}],["trains",{"1":{"65":1}}],["trained",{"1":{"44":1,"48":2,"59":1,"65":1,"67":8,"68":1}}],["train",{"1":{"23":1,"27":1,"37":1,"39":1,"68":1}}],["training5",{"1":{"68":1}}],["training",{"0":{"37":1,"39":1,"68":1},"1":{"18":2,"20":2,"21":1,"22":1,"23":2,"24":1,"29":1,"32":1,"33":1,"34":1,"37":1,"44":5,"48":1,"51":1,"63":1,"66":3,"67":4,"68":28}}],["transition",{"1":{"78":1}}],["transitioning",{"1":{"3":1}}],["transparent",{"1":{"76":1}}],["transparency",{"1":{"4":1}}],["translate",{"1":{"60":1}}],["transfers",{"1":{"65":1}}],["transfer",{"1":{"48":3,"51":1,"59":1}}],["transformation",{"1":{"73":1}}],["transforming",{"1":{"71":1}}],["transformer",{"1":{"24":1,"48":3,"51":1,"59":2,"64":1,"65":1,"67":4}}],["transformers",{"0":{"23":1},"1":{"23":1,"24":1},"2":{"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1}}],["transform",{"1":{"8":1}}],["tracking",{"1":{"44":1}}],["track",{"1":{"3":1}}],["thousands",{"1":{"48":2,"53":1,"64":1}}],["those",{"1":{"20":1}}],["than",{"1":{"32":1,"44":3,"46":1,"48":1,"59":1,"70":1}}],["that",{"1":{"0":1,"2":2,"3":1,"10":3,"12":1,"13":3,"16":1,"17":1,"20":1,"22":1,"32":1,"34":1,"44":4,"46":1,"47":1,"48":3,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"62":1,"64":2,"67":2,"70":1,"75":2,"76":1,"77":1,"78":1}}],["through",{"1":{"37":1,"48":1,"54":1,"59":1,"67":1,"70":1,"72":1,"73":1,"75":1,"76":2}}],["throughout",{"1":{"23":1}}],["three",{"0":{"1":1},"1":{"46":1,"70":1,"76":1,"79":1},"2":{"2":1,"3":1,"4":1}}],["third",{"1":{"9":2,"70":1}}],["this",{"1":{"9":2,"12":3,"13":2,"16":1,"18":1,"19":1,"20":3,"21":1,"22":3,"23":2,"27":1,"31":1,"32":1,"42":1,"44":3,"46":3,"47":1,"66":1,"69":1,"73":2,"77":2,"82":1,"83":1}}],["theory",{"1":{"77":2,"79":1}}],["theatrical",{"0":{"77":1}}],["therapeutic",{"1":{"75":1}}],["therefore",{"1":{"22":1}}],["there",{"1":{"22":1}}],["their",{"1":{"38":1,"46":1,"67":1,"69":2,"81":2}}],["they",{"1":{"19":1,"28":1,"71":1,"75":1,"78":1,"80":1,"81":1,"82":2}}],["them",{"1":{"16":1,"22":1,"28":1,"41":1,"46":1,"69":1,"80":1}}],["then",{"1":{"12":1,"33":1}}],["these",{"1":{"9":1,"10":1,"19":1,"24":1,"42":1,"44":1,"71":1,"75":2,"76":1,"80":1,"81":1}}],["the",{"0":{"13":1,"17":1,"21":1,"22":1,"30":1,"33":1,"39":1,"40":1,"72":1,"74":1,"76":1,"78":1,"81":1},"1":{"0":3,"4":1,"9":18,"10":10,"12":9,"13":16,"15":1,"16":6,"17":8,"18":1,"19":12,"20":15,"22":20,"23":5,"25":4,"28":1,"29":2,"30":1,"31":1,"33":2,"34":1,"35":1,"36":2,"37":3,"38":1,"39":1,"40":1,"42":6,"44":29,"46":15,"47":2,"48":6,"50":1,"51":2,"52":1,"53":3,"54":1,"58":1,"59":1,"62":1,"65":1,"66":2,"67":2,"68":3,"69":3,"70":1,"71":3,"72":2,"73":2,"75":1,"76":4,"77":1,"78":1,"80":1,"81":1,"82":4,"83":6,"84":1},"2":{"73":1,"74":1,"75":2,"76":2,"77":2,"78":1,"79":2,"80":2,"81":2,"82":1,"83":1}}],["today",{"1":{"81":1}}],["tour",{"1":{"70":1}}],["touchscreen",{"1":{"70":1}}],["toyotaa",{"1":{"70":1}}],["torque",{"1":{"48":1,"61":1}}],["torch",{"1":{"27":1}}],["toward",{"0":{"78":1},"1":{"46":1,"73":1},"2":{"79":1,"80":1,"81":1}}],["too",{"1":{"32":1}}],["tool",{"1":{"9":1}}],["tools",{"0":{"75":1},"1":{"9":3,"75":1,"82":1}}],["toolclick",{"1":{"9":1}}],["tokens7bpre",{"1":{"67":1}}],["tokens",{"1":{"59":1,"64":1,"67":1}}],["tokenize",{"1":{"33":2}}],["tokenizer",{"0":{"30":1},"1":{"30":1}}],["tokenization",{"1":{"32":1}}],["token",{"1":{"30":2}}],["top",{"1":{"17":1,"44":1,"70":1,"79":1}}],["topics",{"1":{"8":1,"73":1}}],["tone",{"1":{"9":1}}],["to",{"0":{"75":1,"76":1,"80":1},"1":{"0":4,"2":2,"3":3,"4":3,"8":3,"9":18,"10":8,"11":1,"12":5,"13":5,"16":2,"17":1,"18":4,"19":5,"20":9,"22":12,"23":3,"24":1,"28":2,"29":1,"30":2,"33":1,"34":1,"35":1,"37":1,"38":1,"41":2,"42":3,"44":10,"46":3,"48":11,"50":2,"52":1,"53":2,"54":1,"55":2,"56":1,"57":2,"58":2,"59":2,"60":1,"61":1,"63":1,"65":2,"67":5,"68":13,"70":8,"71":3,"75":2,"76":3,"77":1,"78":2,"80":1,"81":1,"82":2,"84":2}}],["c",{"1":{"83":1}}],["citing",{"1":{"83":1}}],["cities",{"1":{"73":1}}],["city",{"1":{"60":1}}],["cylindrical",{"1":{"70":1}}],["cybernachos",{"1":{"18":1,"83":1}}],["cybersecurity",{"1":{"0":2,"84":1}}],["cyber",{"0":{"0":1,"8":1},"1":{"0":1,"8":6,"9":2,"84":1},"2":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"9":1}}],["ceased",{"1":{"70":1}}],["cpu",{"1":{"20":4,"27":1}}],["ctrl+f",{"1":{"19":1}}],["ctrl+fn+b",{"1":{"17":1}}],["ctrl+break",{"1":{"17":1}}],["ctrl+c",{"1":{"17":1}}],["cues",{"1":{"75":1}}],["curtains",{"1":{"70":1}}],["currently",{"1":{"20":1,"22":1,"31":1}}],["cuda",{"1":{"12":4,"27":1}}],["customizable",{"1":{"70":1}}],["customize",{"1":{"10":1}}],["customized",{"1":{"9":2}}],["customer",{"1":{"69":1,"70":2,"71":1,"75":1}}],["custom",{"0":{"9":1},"1":{"9":7,"23":1,"34":1,"35":1}}],["cutting",{"1":{"8":1,"44":1}}],["clusters",{"1":{"68":2}}],["cluster",{"1":{"68":1}}],["cluttered",{"1":{"65":1}}],["classrooms",{"1":{"73":1}}],["classes",{"1":{"50":1}}],["class",{"1":{"35":1}}],["classic",{"1":{"10":1}}],["cleaning",{"1":{"32":1}}],["clearly",{"1":{"68":1}}],["clear",{"1":{"4":1}}],["closed",{"1":{"48":1}}],["clone",{"1":{"15":1,"19":1}}],["cloning",{"0":{"15":1},"1":{"48":2,"62":2,"67":2}}],["cloud",{"1":{"10":1}}],["click",{"1":{"8":1,"9":2}}],["credit",{"1":{"83":1}}],["creation",{"1":{"9":1,"20":1}}],["creating",{"0":{"9":1},"1":{"2":1,"9":1,"12":1,"22":1}}],["createandbindmdlmaterialfromlibrary",{"1":{"22":1}}],["createmdlmaterialprim",{"1":{"22":2}}],["created",{"1":{"9":1,"22":1}}],["create",{"1":{"0":1,"9":5,"22":4,"34":1}}],["crowdsourcing",{"1":{"53":1}}],["crowdsourced",{"1":{"48":1}}],["cross",{"1":{"35":1,"48":3,"51":1,"67":2}}],["critical",{"1":{"44":1,"76":1}}],["crashes",{"1":{"13":1}}],["crafted",{"1":{"8":2}}],["choosing",{"0":{"28":1}}],["choose",{"1":{"19":1}}],["chinese",{"1":{"25":1}}],["china",{"1":{"7":1}}],["checkpoints",{"1":{"67":1}}],["check",{"1":{"12":1,"13":2}}],["chen",{"1":{"7":4}}],["chenhan",{"1":{"7":1}}],["charge",{"1":{"70":1}}],["characteristics",{"1":{"47":1}}],["characters",{"1":{"32":1}}],["challenge",{"1":{"80":1}}],["challenges",{"1":{"8":1,"44":1,"48":1,"73":1}}],["challenging",{"1":{"48":1,"51":1,"53":1,"56":1,"61":1}}],["changing",{"1":{"10":1}}],["chat",{"1":{"9":2}}],["chatgpt",{"1":{"9":5}}],["cases",{"1":{"48":1,"65":1}}],["care",{"1":{"75":1}}],["carecapable",{"1":{"70":1}}],["careful",{"1":{"48":1}}],["carried",{"1":{"68":1}}],["card",{"1":{"68":1}}],["carolina",{"1":{"7":2}}],["capacity",{"1":{"59":1,"70":2}}],["capability",{"1":{"44":1,"67":2}}],["capabilities",{"1":{"9":1,"10":1,"63":1,"70":6}}],["capable",{"1":{"3":1,"42":1,"70":1,"71":1,"76":1}}],["captured",{"1":{"55":1,"57":1}}],["capture",{"1":{"48":1,"54":1,"67":1,"68":1}}],["camera",{"1":{"48":3,"52":1,"56":1,"57":1,"67":1}}],["categories",{"1":{"44":1}}],["categorization",{"1":{"44":1}}],["calibration",{"1":{"48":1,"61":1,"67":1}}],["california",{"1":{"7":3}}],["calligraphy",{"1":{"70":1}}],["call",{"1":{"39":1}}],["calculates",{"1":{"36":1}}],["causal",{"1":{"28":1}}],["cached",{"1":{"13":1}}],["can",{"1":{"2":1,"8":1,"9":1,"13":1,"16":2,"17":1,"19":3,"20":1,"25":1,"31":1,"44":1,"48":2,"50":1,"51":2,"56":1,"58":1,"60":1,"65":1,"68":6,"76":3,"80":1,"81":1}}],["cooperationurban",{"1":{"79":1}}],["coordination",{"0":{"79":1,"80":1},"1":{"48":1}}],["coordinated",{"1":{"78":1}}],["coordinate",{"1":{"4":1}}],["cognitive",{"1":{"77":1}}],["co",{"0":{"81":1},"1":{"77":1,"82":1}}],["coexist",{"1":{"73":1}}],["coherent",{"1":{"67":1}}],["counts",{"1":{"67":2,"73":1}}],["costs",{"1":{"70":3}}],["cost",{"1":{"48":1,"53":1,"60":2,"67":2,"68":1,"70":1}}],["coverage",{"1":{"52":1}}],["covering",{"1":{"48":1,"59":1}}],["covers",{"1":{"8":1,"22":1}}],["correcting",{"1":{"46":1,"80":1}}],["correct",{"1":{"34":1}}],["correctly",{"1":{"20":1}}],["core",{"1":{"10":1,"73":1}}],["codebase",{"1":{"50":1}}],["code",{"0":{"21":1,"22":1,"25":1},"1":{"8":2,"20":2,"21":1,"25":3,"44":1,"46":1}}],["comfort",{"1":{"76":1}}],["combine",{"1":{"69":1}}],["combined",{"1":{"67":1,"68":1}}],["combines",{"1":{"46":1}}],["combining",{"1":{"48":1,"67":2,"70":2}}],["components",{"1":{"80":1}}],["composes",{"1":{"67":1}}],["complicate",{"1":{"58":1}}],["complements",{"1":{"77":1}}],["complexities",{"1":{"55":1}}],["complexity",{"1":{"48":2,"50":1,"59":1,"61":1}}],["complex",{"1":{"44":1,"48":5,"54":1,"65":1,"67":1,"70":8,"82":1}}],["completion",{"1":{"65":1}}],["completing",{"1":{"19":1,"68":1}}],["completes",{"1":{"68":2}}],["completed",{"1":{"42":1,"68":1}}],["complete",{"1":{"10":1,"20":1,"25":1,"76":1}}],["comprises",{"1":{"55":1}}],["comprehensive",{"1":{"8":1,"47":2,"48":1,"61":1,"62":1,"69":1}}],["computing",{"1":{"48":1}}],["computational",{"1":{"46":2,"48":2}}],["compute",{"1":{"37":1,"50":1,"59":1}}],["computed",{"1":{"36":1}}],["companionship",{"1":{"76":1}}],["company",{"1":{"70":1}}],["compact",{"1":{"42":1,"70":1}}],["comparing",{"1":{"66":1}}],["comparison",{"0":{"41":1,"47":1,"49":1,"67":1},"2":{"48":1,"49":1,"50":2,"51":2,"52":2,"53":2,"54":2,"55":2,"56":2,"57":2,"58":2,"59":2,"60":2,"61":2,"62":2,"63":2,"64":2,"65":2}}],["comparative",{"1":{"47":2}}],["compares",{"1":{"66":1}}],["compared",{"1":{"48":2,"54":1}}],["compare",{"1":{"38":1,"41":1}}],["compatible",{"1":{"12":1}}],["compatibility",{"1":{"12":4}}],["com",{"1":{"9":1,"13":1,"18":1}}],["communication",{"1":{"80":1}}],["community",{"0":{"7":1},"1":{"10":2,"48":1,"50":1}}],["commercial",{"1":{"70":2}}],["comments",{"1":{"25":1}}],["commands",{"1":{"44":1,"75":1}}],["command",{"1":{"12":1,"16":1,"17":3,"22":3,"44":1}}],["common",{"1":{"10":2,"13":1,"75":1}}],["committed",{"1":{"0":2,"84":1}}],["collectives",{"1":{"78":1,"80":1,"81":1,"82":1}}],["collective",{"0":{"78":1},"2":{"79":1,"80":1,"81":1}}],["collecting",{"1":{"53":1}}],["collection4",{"1":{"67":1}}],["collection",{"1":{"48":3,"53":1,"60":1,"67":1,"68":1}}],["collected",{"1":{"48":4,"52":1,"54":1,"56":1,"59":1,"63":1}}],["collect",{"1":{"38":1}}],["collaborative",{"1":{"48":1,"51":1}}],["collaboration",{"1":{"3":1,"4":2,"71":1}}],["collate",{"1":{"34":1}}],["colorado",{"1":{"7":1}}],["conditioned",{"1":{"58":1,"65":1}}],["conditioningocto",{"1":{"67":1}}],["conditioning",{"1":{"58":1}}],["conducting",{"1":{"20":1}}],["confined",{"1":{"70":1}}],["configuration",{"0":{"34":1},"1":{"9":1,"20":1}}],["configured",{"1":{"9":1,"13":1,"23":1}}],["configure",{"1":{"9":2,"22":1}}],["conferences",{"1":{"44":1,"46":1}}],["conference",{"1":{"44":2,"46":1}}],["concurrently",{"1":{"63":1}}],["concept",{"1":{"46":4}}],["concepts",{"1":{"24":1,"46":4}}],["conclusion",{"0":{"42":1,"71":1,"82":1}}],["convert",{"1":{"22":1}}],["converting",{"1":{"22":2}}],["conversations",{"1":{"9":1}}],["construction",{"1":{"82":1}}],["constitution",{"0":{"81":1}}],["consists",{"1":{"67":1}}],["consistent",{"1":{"46":1}}],["consistently",{"1":{"30":1}}],["consistency",{"1":{"3":1,"30":1,"46":1,"48":2}}],["considered",{"1":{"44":1}}],["consequences",{"1":{"44":1}}],["consecutive",{"1":{"13":1}}],["connections",{"1":{"9":1}}],["connect",{"1":{"9":2}}],["continues",{"1":{"71":1}}],["continuous",{"1":{"2":1,"48":1,"63":1}}],["contact",{"1":{"48":1,"61":2}}],["contains",{"1":{"22":1,"52":1,"56":1,"61":1}}],["context",{"1":{"48":1,"76":1}}],["contracts",{"1":{"81":1}}],["contributions",{"1":{"44":1,"46":2,"50":1}}],["contribute",{"1":{"10":1}}],["controlcentralized",{"1":{"79":1}}],["controlled",{"1":{"64":1}}],["control",{"1":{"2":1,"10":1,"44":1,"48":1,"59":1,"67":2,"68":1,"70":2,"76":1}}],["await",{"1":{"70":1}}],["a2",{"1":{"70":1}}],["aesthetics",{"1":{"70":1}}],["affective",{"1":{"76":1}}],["affecting",{"1":{"70":1}}],["affect",{"1":{"70":1}}],["after",{"1":{"19":1,"20":1}}],["a100",{"1":{"67":1,"68":5}}],["amounts",{"1":{"56":1,"67":1}}],["author",{"1":{"83":1}}],["autonomy",{"1":{"70":1,"81":1}}],["autonomously",{"1":{"44":1}}],["autonomous",{"0":{"4":1},"1":{"76":1,"79":1,"80":1,"81":1}}],["autoregressive",{"1":{"67":1}}],["automated",{"1":{"48":1}}],["automation",{"1":{"8":2,"44":1}}],["auditable",{"1":{"76":1}}],["audio",{"1":{"48":1,"61":1}}],["augmentation",{"0":{"31":1},"1":{"23":1,"31":1,"42":1}}],["axis",{"1":{"22":1}}],["abilities",{"1":{"70":1}}],["ability5",{"1":{"67":1}}],["about",{"1":{"68":1}}],["above",{"1":{"13":1,"17":1}}],["able",{"1":{"19":1}}],["agency",{"0":{"76":1},"1":{"76":1,"77":1}}],["agent",{"1":{"67":1,"72":1,"73":1,"79":1}}],["agents",{"1":{"44":2,"73":1,"78":1}}],["agile",{"1":{"70":1}}],["agility",{"1":{"10":1}}],["aggregates",{"1":{"51":1}}],["aggregation",{"1":{"46":1}}],["agree",{"1":{"13":1}}],["agreement",{"1":{"13":3}}],["avoid",{"1":{"9":1,"32":1}}],["available",{"1":{"9":3,"10":2,"12":1,"18":1,"22":1,"27":3,"44":1,"46":1}}],["aprl",{"1":{"69":1}}],["apt",{"1":{"16":1}}],["api",{"1":{"9":1,"22":1}}],["apis",{"1":{"9":2,"10":1}}],["approximate",{"1":{"68":1}}],["approximately",{"1":{"58":1,"70":1}}],["approx",{"1":{"67":2}}],["approaches",{"1":{"44":1,"62":1}}],["approach",{"0":{"44":1},"1":{"12":3,"42":1,"43":1,"44":2,"46":2,"64":1}}],["applying",{"1":{"23":1}}],["application",{"1":{"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":2,"61":1,"62":1,"63":1,"64":1,"65":1,"70":2}}],["applicationscale",{"1":{"48":1}}],["applications",{"1":{"8":2,"46":1,"69":3,"70":5}}],["applicability",{"1":{"44":1,"52":1,"60":1}}],["applicable",{"1":{"13":1,"70":1}}],["applied",{"1":{"2":1}}],["apps",{"1":{"20":1}}],["appearance",{"1":{"70":1}}],["appear",{"1":{"9":1}}],["aligned",{"1":{"83":1}}],["al",{"1":{"83":2}}],["already",{"1":{"80":1,"81":1}}],["alexa",{"1":{"77":1}}],["alone",{"1":{"82":1}}],["alongside",{"1":{"48":1,"62":1}}],["along",{"1":{"22":1,"77":1}}],["aloha",{"1":{"67":3,"68":2}}],["although",{"1":{"62":1}}],["alpha",{"1":{"23":1,"36":1,"42":1}}],["algorithm",{"1":{"19":1}}],["algorithms",{"0":{"2":1},"1":{"2":3,"19":1,"48":1,"55":1,"62":1}}],["all",{"1":{"13":1,"16":2,"30":1,"46":1}}],["allowing",{"1":{"44":2}}],["allow",{"1":{"9":1,"10":1}}],["allows",{"1":{"9":1,"64":1}}],["also",{"1":{"9":1,"22":1,"23":1,"29":1,"48":1,"78":1}}],["ari",{"1":{"70":1}}],["article",{"1":{"73":1,"83":1}}],["artificial",{"1":{"0":2,"84":1}}],["art",{"1":{"59":1}}],["architectures",{"1":{"48":1,"51":1}}],["architecture",{"1":{"28":1,"66":1,"67":2}}],["array",{"1":{"22":1}}],["arrays",{"1":{"22":1}}],["argument",{"1":{"16":1}}],["arms",{"1":{"48":1,"70":3,"79":1}}],["arm",{"1":{"10":1,"18":1,"70":2}}],["areas",{"1":{"60":1}}],["are",{"0":{"82":1},"1":{"9":2,"10":3,"13":1,"16":1,"19":3,"20":1,"22":1,"25":1,"30":1,"32":1,"44":3,"46":2,"48":1,"55":1,"57":1,"62":1,"64":1,"67":4,"68":2,"71":2,"73":1,"75":3,"76":1,"77":1,"80":1,"82":3}}],["acl",{"1":{"46":1}}],["achieving",{"1":{"44":1}}],["achieved",{"1":{"70":1}}],["achieves",{"1":{"46":1,"64":1,"65":1,"67":1}}],["achieve",{"1":{"4":1,"44":1}}],["across",{"1":{"44":1,"46":2,"48":5,"51":2,"52":1,"56":1,"61":1,"63":1}}],["acts",{"1":{"77":1}}],["actors",{"0":{"75":1},"1":{"82":1}}],["actor",{"1":{"67":1,"68":1}}],["act",{"1":{"50":1}}],["actual",{"1":{"22":1,"68":1}}],["action",{"1":{"54":1,"59":1,"65":1,"67":5,"68":1}}],["actions",{"1":{"44":1,"48":1,"67":2,"70":1,"76":1}}],["actionable",{"1":{"8":1}}],["activities",{"1":{"70":1}}],["active",{"1":{"50":1}}],["actively",{"1":{"10":1}}],["activated",{"1":{"13":1}}],["according",{"1":{"77":1}}],["accountability",{"1":{"76":1}}],["accuracy",{"1":{"46":1,"65":1}}],["accurate",{"1":{"10":1,"44":1,"47":1,"66":1,"69":1}}],["accidentally",{"1":{"19":1}}],["acceptable",{"1":{"76":1,"77":1}}],["acceptance",{"1":{"70":1}}],["accept",{"1":{"13":3}}],["accessible",{"1":{"50":1,"71":1}}],["accessdata",{"1":{"46":1}}],["access",{"1":{"9":3,"70":1}}],["annotation",{"1":{"48":1}}],["annotations",{"1":{"48":1,"58":1}}],["analyze",{"1":{"61":1}}],["analyzing",{"1":{"46":1}}],["analysis",{"0":{"66":1},"1":{"47":3,"48":1,"66":1,"69":1},"2":{"67":1,"68":1}}],["any",{"1":{"25":1}}],["an",{"0":{"44":1},"1":{"8":2,"13":1,"16":1,"22":1,"43":1,"44":2,"46":2,"50":2,"56":2,"66":1,"69":1,"75":1,"77":1}}],["and",{"0":{"2":1,"19":1,"23":1,"41":1,"68":1,"72":1,"77":1,"79":1},"1":{"0":5,"2":8,"3":3,"4":6,"8":5,"9":9,"10":15,"11":1,"12":1,"13":3,"16":1,"17":1,"18":2,"19":2,"20":2,"22":7,"23":3,"24":3,"25":1,"28":1,"29":1,"32":1,"33":1,"34":1,"36":2,"37":1,"38":1,"41":2,"42":2,"44":18,"46":10,"47":7,"48":34,"50":8,"51":1,"52":3,"53":3,"54":1,"55":3,"56":2,"57":2,"58":5,"59":3,"60":2,"61":7,"63":2,"64":2,"65":5,"66":4,"67":18,"68":12,"69":4,"70":30,"71":2,"72":1,"73":3,"75":3,"76":3,"77":1,"79":1,"80":3,"81":3,"82":4,"83":1,"84":1},"2":{"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1,"34":1,"35":1,"36":1,"37":1,"38":1,"39":1,"40":1,"41":1,"42":1,"73":1,"74":1,"75":1,"76":1,"77":1,"78":1,"79":1,"80":1,"81":1,"82":1,"83":1}}],["attribution",{"1":{"77":1}}],["attracting",{"1":{"46":1}}],["at",{"1":{"7":1,"18":1,"44":1,"48":3,"51":1,"60":1,"61":1,"62":1,"63":1,"68":1,"70":3}}],["adopting",{"1":{"70":1}}],["adopts",{"1":{"44":1}}],["adept",{"1":{"70":1}}],["advantageskey",{"1":{"48":1}}],["advantages",{"1":{"47":1,"50":1,"51":1,"52":1,"53":1,"54":1,"55":1,"56":1,"57":1,"58":1,"59":1,"60":1,"61":1,"62":1,"63":1,"64":1,"65":1,"69":2}}],["advancement",{"1":{"71":1}}],["advances",{"1":{"44":1}}],["advanced",{"1":{"4":1,"8":1,"9":2}}],["advancing",{"1":{"0":2,"61":1,"84":1}}],["adapts",{"1":{"70":1}}],["adapt",{"1":{"10":1}}],["adaptable",{"1":{"67":2}}],["adaptability9",{"1":{"67":1}}],["adaptability",{"1":{"2":1,"10":1,"76":1,"81":1}}],["adaptation",{"1":{"3":1,"48":1,"65":1}}],["addressed",{"1":{"77":1}}],["addresses",{"1":{"44":1}}],["address",{"1":{"20":1}}],["additional",{"1":{"48":1,"64":1,"67":1,"68":1}}],["additionally",{"1":{"10":1,"20":1}}],["addition",{"1":{"13":1}}],["adding",{"1":{"10":1}}],["add",{"1":{"9":2,"10":1,"20":1,"22":2}}],["adjustable",{"1":{"68":1}}],["adjusting",{"0":{"29":1},"1":{"70":1}}],["adjustments",{"1":{"9":1}}],["adjust",{"1":{"3":1,"9":1,"39":1,"76":1}}],["ask",{"1":{"81":1}}],["assembly",{"1":{"70":1}}],["assesses",{"1":{"46":1}}],["assessment",{"1":{"46":1}}],["associated",{"1":{"46":1}}],["association",{"1":{"46":1}}],["assist",{"1":{"70":1}}],["assistance",{"1":{"70":1}}],["assistanceunderstands",{"1":{"70":1}}],["assistant",{"1":{"9":1,"75":1}}],["assisted",{"1":{"44":1}}],["assignments",{"1":{"4":1}}],["aspects",{"1":{"9":1,"66":2}}],["as",{"1":{"0":1,"3":1,"9":1,"10":1,"13":1,"16":1,"20":2,"22":2,"28":2,"30":1,"39":1,"44":6,"46":1,"47":1,"48":1,"62":4,"66":2,"67":2,"68":1,"69":2,"70":1,"71":1,"73":2,"75":1,"76":1,"77":1,"82":1}}],["aimed",{"1":{"48":1,"51":1,"61":1}}],["aims",{"1":{"10":2,"44":1}}],["ai",{"1":{"0":2,"4":1,"8":2,"76":1,"83":1,"84":1}}],["a",{"1":{"0":2,"4":2,"8":1,"9":8,"10":4,"12":3,"13":1,"16":1,"17":2,"18":3,"19":2,"20":2,"21":1,"22":6,"23":5,"25":1,"27":1,"28":1,"34":1,"35":1,"36":2,"38":1,"41":2,"42":4,"44":10,"46":6,"47":3,"48":5,"51":1,"52":2,"53":1,"55":1,"57":1,"58":1,"59":2,"60":2,"61":1,"62":3,"63":3,"64":1,"65":2,"67":8,"68":26,"69":2,"70":11,"71":1,"73":2,"75":1,"77":2,"80":2,"82":2,"83":1}}]],"serializationVersion":2}